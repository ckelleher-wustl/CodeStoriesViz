begin,end,matches,target code,comp code
1831,1893,0,['import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport csv\n'],"['imagenet_classes = []\nwith open(""imagenet1000_clsidx_to_labels.txt"", “rb"") as f:\n   imagenet_classes.append(f.readlines())\n']"
1893,1901,3,"['imagenet_classes = []\nwith open(""imagenet1000_clsidx_to_labels.txt"", “rb"") as f:\n   imagenet_classes.append(f.readlines())\n']","['imagenet_classes = []\nwith open(""imagenet1000_clsidx_to_labels.txt"", ""r"") as f:\n   imagenet_classes.append(f.readlines())\n\nimagenet_classes\n']"
1901,1928,2,"['imagenet_classes = []\nwith open(""imagenet1000_clsidx_to_labels.txt"", ""r"") as f:\n   imagenet_classes.append(f.readlines())\n\nimagenet_classes\n']","['with open(""imagenet1000_clsidx_to_labels.txt"", “r"") as f:\n   imagenet_classes = f.readlines()\n\nimagenet_classes\n']"
1928,2009,2,"['with open(""imagenet1000_clsidx_to_labels.txt"", “r"") as f:\n   imagenet_classes = f.readlines()\n\nimagenet_classes\n']","['import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport csv\nimport ast\n\nwith open(""imagenet1000_clsidx_to_labels.txt"", ""r"") as f:\n   imagenet_classes = ast.literal_eval(f.read())\n\nimagenet_classes\n']"
2009,2120,0,"['import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport csv\nimport ast\n\nwith open(""imagenet1000_clsidx_to_labels.txt"", ""r"") as f:\n   imagenet_classes = ast.literal_eval(f.read())\n\nimagenet_classes\n']","['for k, v in imagenet_classes.items():\n   if v.contains(""banana""):|\n      print(k)\n']"
2120,2157,2,"['for k, v in imagenet_classes.items():\n   if v.contains(""banana""):|\n      print(k)\n']","['for k, v in imagenet_classes.items():\n   if ""banana"" in v:\n      print(k)\n']"
2157,2744,0,"['for k, v in imagenet_classes.items():\n   if ""banana"" in v:\n      print(k)\n']",['import nltk\n']
2744,2751,0,['import nltk\n'],"['from nltk.corpus import wordnet as wn\nfood = wn.synset(\'food.n.02"")\nlist(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))\n']"
2751,3028,3,"['from nltk.corpus import wordnet as wn\nfood = wn.synset(\'food.n.02"")\nlist(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))\n']","[""import nltk\n\nfrom nltk.corpus import wordnet as wn\nfood = wn.synset('food.n.02')\nfood_list = list(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))\n\nfood_list\n""]"
3028,3291,0,"[""import nltk\n\nfrom nltk.corpus import wordnet as wn\nfood = wn.synset('food.n.02')\nfood_list = list(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))\n\nfood_list\n""]","['for food_item in food_list:\n   print((food_item.lower().strip(""_"")) .\n']"
3291,3373,1,"['for food_item in food_list:\n   print((food_item.lower().strip(""_"")) .\n']","['for food_item in food_list:\n   print(food_item.lower().split(""_""))']"
3373,3420,0,"['for food_item in food_list:\n   print(food_item.lower().split(""_""))']","['# Remove punctuation and lower\nfood_list = [food_item.lower().split(""_"") for food_item in food_list]\nfood_list\n']"
3420,3458,2,"['# Remove punctuation and lower\nfood_list = [food_item.lower().split(""_"") for food_item in food_list]\nfood_list\n']","['# Remove punctuation and lower\nfood_list = [food for sublist in food_item.lower().split(""_"") for food_item in food_list]\nfood_list\n']"
3458,3612,0,"['# Remove punctuation and lower\nfood_list = [food for sublist in food_item.lower().split(""_"") for food_item in food_list]\nfood_list\n']",['# flat_list = [item for sublist in t for item in sublist] \nflat_food_list = [food for food_sub_list in food_list for food in food_sub_list]\nflat_food_list\n']
3612,3703,0,['# flat_list = [item for sublist in t for item in sublist] \nflat_food_list = [food for food_sub_list in food_list for food in food_sub_list]\nflat_food_list\n'],"['for k, v in imagenet_classes:\n   if v.lower() in flat_food_list:\n      print(k)\n']"
3703,3711,2,"['for k, v in imagenet_classes:\n   if v.lower() in flat_food_list:\n      print(k)\n']","['for k, v in imagenet_classes.items():\n   if v.lower() in flat_food_list:\n      print(k)\n']"
3711,3795,2,"['for k, v in imagenet_classes.items():\n   if v.lower() in flat_food_list:\n      print(k)\n']","['# Check ImageNet classes for foods\nfor k, v in imagenet_classes.items():\n   print(v.lower().split("",""))\n   if v.lower() in flat_food_list:\n      print(k, v)\n\n']"
3795,3821,4,"['# Check ImageNet classes for foods\nfor k, v in imagenet_classes.items():\n   print(v.lower().split("",""))\n   if v.lower() in flat_food_list:\n      print(k, v)\n\n']","['# Check ImageNet classes for foods\nfor k, v in imagenet_classes.items():\n   print(v.lower().split("",""))\n   if v.lower().split("","") in flat_food_list:\n      print(k, v)\n']"
3821,4193,0,"['# Check ImageNet classes for foods\nfor k, v in imagenet_classes.items():\n   print(v.lower().split("",""))\n   if v.lower().split("","") in flat_food_list:\n      print(k, v)\n']","['[""string_1"", ""string_2""] in ""string_ 1""\n']"
4193,4273,0,"['[""string_1"", ""string_2""] in ""string_ 1""\n']","['# Check ImageNet classes for foods\n\n# Look at imagenet classes\n\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   print(v.lower().split("","").strip("" ""))\n   # See if value appears s flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k,v)\n']"
4273,4354,7,"['# Check ImageNet classes for foods\n\n# Look at imagenet classes\n\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   print(v.lower().split("","").strip("" ""))\n   # See if value appears s flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k,v)\n']","['# Check ImageNet classes for foods\n\n# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   # print(v.lower().split("",""))\n   print([space_word.strip("" "") for space_word in v.lower().split("","")])\n   # See if value appears in flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k, v)\n']"
4354,4355,9,"['# Check ImageNet classes for foods\n\n# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   # print(v.lower().split("",""))\n   print([space_word.strip("" "") for space_word in v.lower().split("","")])\n   # See if value appears in flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k, v)\n']","['# Check ImageNet classes for foods\n\n# Look at imagenet classes\nfor k,v in imagenet_classes.item()\n   # Get value from imagenet classes (string)\n   # print(v. lower().split(*,""))]|\n   print([space_word.strip("" "") for space_word in v.lower().split("","")])\n   # See if value appears in flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k, v)\n']"
4355,4409,0,"['# Check ImageNet classes for foods\n\n# Look at imagenet classes\nfor k,v in imagenet_classes.item()\n   # Get value from imagenet classes (string)\n   # print(v. lower().split(*,""))]|\n   print([space_word.strip("" "") for space_word in v.lower().split("","")])\n   # See if value appears in flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k, v)\n']","['set([""string_1"", ""string_2""]).intersection(""string_1"")]\n']"
4409,4422,1,"['set([""string_1"", ""string_2""]).intersection(""string_1"")]\n']","['set([""string_1"", ""string_2""]).intersection((set[""string_1""])\n']"
4422,4429,1,"['set([""string_1"", ""string_2""]).intersection((set[""string_1""])\n']","['set([""string_1"", ""string_2""]).intersect(set[""string_1""])\n']"
4429,4494,0,"['set([""string_1"", ""string_2""]).intersect(set[""string_1""])\n']","['intersect_str = set([""string_1"", ""string_2""]).intersection(set(""string_1""))\nintersect_str\n']"
4494,4497,2,"['intersect_str = set([""string_1"", ""string_2""]).intersection(set(""string_1""))\nintersect_str\n']","['intersect_str = set([""string_1"", ""string_2""]).intersection(set(""string_1""))\nintersect_str\n']"
4497,4515,2,"['intersect_str = set([""string_1"", ""string_2""]).intersection(set(""string_1""))\nintersect_str\n']","['intersect_str = set([""string_1"", ""string_2""]).intersection(set([""string_1""])) \nintersect_str\n']"
4515,4569,0,"['intersect_str = set([""string_1"", ""string_2""]).intersection(set([""string_1""])) \nintersect_str\n']","['# Check ImageNet classes for foods\n\n# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet_classes (string) \n   # print(v.lower().split(*,""))\n   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])\n   print([imagenet_class_set])\n   # See if value appears in flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k, v)\n']"
4569,4574,9,"['# Check ImageNet classes for foods\n\n# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet_classes (string) \n   # print(v.lower().split(*,""))\n   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])\n   print([imagenet_class_set])\n   # See if value appears in flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k, v)\n']","['# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   # print(v.lower(),split("",""))\n   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])\n   print([imagenet_class_set])\n   # See if value appears in flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k, v) I\n']"
4574,4596,8,"['# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   # print(v.lower(),split("",""))\n   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])\n   print([imagenet_class_set])\n   # See if value appears in flat_food_list\n   if v.lower().split("","") in flat_food_list:\n      print(k, v) I\n']","['# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   # print(v.lower().split("",""))\n   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])\n   print([imagenet_class_set]) |\n   # See if value appears jin flat_food_list\n   if imagenet_class_set.intersection(flat_food_list):\n      print(k, v)\n']"
4596,4606,9,"['# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   # print(v.lower().split("",""))\n   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])\n   print([imagenet_class_set]) |\n   # See if value appears jin flat_food_list\n   if imagenet_class_set.intersection(flat_food_list):\n      print(k, v)\n']","['# Check ImageNet classes for foods\n\n# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   # print(v.lower().split("",""))\n   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])\n   # print([imagenet_class_set])\n   # See if value appears in flat_food_list\n   if imagenet_class_set.intersection(flat_food_list):\n      print(k, v)\n']"
4606,5527,0,"['# Check ImageNet classes for foods\n\n# Look at imagenet classes\nfor k, v in imagenet_classes.items():\n   # Get value from imagenet classes (string)\n   # print(v.lower().split("",""))\n   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])\n   # print([imagenet_class_set])\n   # See if value appears in flat_food_list\n   if imagenet_class_set.intersection(flat_food_list):\n      print(k, v)\n']","[""len(imagenet_food_classes)\n\n\n# What classes shouldn't be there? — Going through the imagenet_food_classes\nnon_food_classes_manual_sort = [457, 494, 567, 626, 723, 738, 760, 923, 972,\n\nimagenet_classes\n""]"
5527,5583,2,"[""len(imagenet_food_classes)\n\n\n# What classes shouldn't be there? — Going through the imagenet_food_classes\nnon_food_classes_manual_sort = [457, 494, 567, 626, 723, 738, 760, 923, 972,\n\nimagenet_classes\n""]","[""# What classes shouldn't be there? — Going through the imagenet_food_classes\nnon_food_classes_manual_sort = [457, 494, 567, 626, 723, 738, 760, 923, 972,\n\nlist(imagenet_food_classes) [:5]\n\nimagenet_manual_fitlered_food_classes = {}\n""]"
5583,5696,1,"[""# What classes shouldn't be there? — Going through the imagenet_food_classes\nnon_food_classes_manual_sort = [457, 494, 567, 626, 723, 738, 760, 923, 972,\n\nlist(imagenet_food_classes) [:5]\n\nimagenet_manual_fitlered_food_classes = {}\n""]","[""imagenet_manual_fitlered_food_classes = {}\nfor k, v in imagenet_food_classes.items():\n   if k not in non_food_classes_manual_sort: # don't won't keys that aren't food (from the manual sort)\n      imagenet_manual_fitlered_food_classes[k] = v\nimagenet_manual_fitlered_food_classes\n""]"
5696,5861,0,"[""imagenet_manual_fitlered_food_classes = {}\nfor k, v in imagenet_food_classes.items():\n   if k not in non_food_classes_manual_sort: # don't won't keys that aren't food (from the manual sort)\n      imagenet_manual_fitlered_food_classes[k] = v\nimagenet_manual_fitlered_food_classes\n""]",['# Get food class keys\nfood_class_keys = list(imagenet_manual_fitlered_food_classes.keys())\nfood_class_keys [:10]\n\nimagenet_non_food_classes = {}\n']
5861,5890,1,['# Get food class keys\nfood_class_keys = list(imagenet_manual_fitlered_food_classes.keys())\nfood_class_keys [:10]\n\nimagenet_non_food_classes = {}\n'],['# How many classes do we have?\nlen(imagenet_classes)\n\nimagenet_non_food_classes = {}\n']
5890,5939,1,['# How many classes do we have?\nlen(imagenet_classes)\n\nimagenet_non_food_classes = {}\n'],"['imagenet_non_food_classes = {}\nfor k, v in imagenet_classes.items():\n   if k not in food_class_keys:\n      imagenet_non_food_classes[k] = v\nimagenet_non_food_classes\n']"
5939,6699,0,"['imagenet_non_food_classes = {}\nfor k, v in imagenet_classes.items():\n   if k not in food_class_keys:\n      imagenet_non_food_classes[k] = v\nimagenet_non_food_classes\n']","['import pandas as csv\n\ndf = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet—Datasets—Downloader/master/classes_in_imagenet.csv"")\ndf.head()\n']"
6699,6702,3,"['import pandas as csv\n\ndf = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet—Datasets—Downloader/master/classes_in_imagenet.csv"")\ndf.head()\n']","['import pandas as csv \n\ndf = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv)\ndf.head()\n']"
6702,6743,0,"['import pandas as csv \n\ndf = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv)\ndf.head()\n']","['df[""class_name""]\n']"
6743,6758,0,"['df[""class_name""]\n']","['import pandas as pd\n\ndf = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv"")\ndf.head() |\n']"
6758,6770,0,"['import pandas as pd\n\ndf = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv"")\ndf.head() |\n']","['df[""class_name""].lower()\n\n']"
6770,6771,1,"['df[""class_name""].lower()\n\n']","['df[""class_name""].lower()\n']"
6771,6774,1,"['df[""class_name""].lower()\n']","['df[""class_name""].str.lower()\n']"
6774,6775,1,"['df[""class_name""].str.lower()\n']","['df[""class_name""].str.lower()\n']"
6775,6914,0,"['df[""class_name""].str.lower()\n']","['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str().contains(""food"")]\ndf_non_food\n\nflat_food_list[:5]\n']"
6914,6924,3,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str().contains(""food"")]\ndf_non_food\n\nflat_food_list[:5]\n']","['len(df)\n\n# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']"
6924,6927,3,"['len(df)\n\n# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']","['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']"
6927,6944,3,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']","['# Filter dataframe from food classes\ndf_non_food = df [~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']"
6944,6947,0,"['# Filter dataframe from food classes\ndf_non_food = df [~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']","['len(df)\n\nlen(df[""class_name""].unique())\n']"
6947,6959,2,"['len(df)\n\nlen(df[""class_name""].unique())\n']","['len(df)\n\nlen(df.drop_duplicates())\n\nlen(df[""class_name""].unique())\n']"
6959,6979,0,"['len(df)\n\nlen(df.drop_duplicates())\n\nlen(df[""class_name""].unique())\n']",['df.info()\n']
6979,6995,0,['df.info()\n'],"['# Filter dataframe from food classes\ndf_non_food = df[df[""class_name""].str.contains(""food"")]\ndf_non_food\n']"
6995,6996,3,"['# Filter dataframe from food classes\ndf_non_food = df[df[""class_name""].str.contains(""food"")]\ndf_non_food\n']","['# Filter dataframe from food classes\ndf_non_food = df[df[""class name""].str.contains(""food"")]\ndf_non_food\n']"
6996,6996,0,"['# Filter dataframe from food classes\ndf_non_food = df[df[""class name""].str.contains(""food"")]\ndf_non_food\n']",['flat_food_list[:5]\n']
6996,7007,0,['flat_food_list[:5]\n'],['len(df)\n\ndf.isna()\n']
7007,7016,1,['len(df)\n\ndf.isna()\n'],['len(df)\n\ndf.dropna()']
7016,7020,1,['len(df)\n\ndf.dropna()'],"['len(df)\n\nlen(df.dropna())\n\nlen(df[""class_name""].unique())\n\ndf.info()\n']"
7020,7041,3,"['len(df)\n\nlen(df.dropna())\n\nlen(df[""class_name""].unique())\n\ndf.info()\n']","['len(df)\n\n# Remove NaN\'s\ndf.dropna(inplace=True)\n\nlen(df[""class_name""].unique())\n\ndf.info()\n']"
7041,7072,0,"['len(df)\n\n# Remove NaN\'s\ndf.dropna(inplace=True)\n\nlen(df[""class_name""].unique())\n\ndf.info()\n']","['# Filter dataframe from food classes\ndf_non_food = df[df[""class_name""].str.lower().contains(""food"")]\ndf_non_food\n']"
7072,7072,3,"['# Filter dataframe from food classes\ndf_non_food = df[df[""class_name""].str.lower().contains(""food"")]\ndf_non_food\n']","['# Filter dataframe from food classes\ndf_non_food = df[df[""class_naMe""].str.lower().contains(""food"")]\ndf_non_food\n']"
7072,7118,0,"['# Filter dataframe from food classes\ndf_non_food = df[df[""class_naMe""].str.lower().contains(""food"")]\ndf_non_food\n']","['import pandas as pd \n\ndf = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv"")\n# lower strings\ndf[""class_name""] = df[""class_name""].str.lower()\ndf.head()\n']"
7118,7133,0,"['import pandas as pd \n\ndf = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv"")\n# lower strings\ndf[""class_name""] = df[""class_name""].str.lower()\ndf.head()\n']","['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']"
7133,7133,3,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']","['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']"
7133,7187,2,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.contains(""food"")]\ndf_non_food\n']","['# Filter dataframe from food classes \ndf_non_food = df[~df[""class_name""].str.isin(flat_food_list)]\ndf_non_food']"
7187,7190,3,"['# Filter dataframe from food classes \ndf_non_food = df[~df[""class_name""].str.isin(flat_food_list)]\ndf_non_food']","['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.isin(flat_food_list)]\ndf_nan_food\n\nlen(df_non_food)\n\n""food"" in flat_food_list\n']"
7190,7193,3,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].str.isin(flat_food_list)]\ndf_nan_food\n\nlen(df_non_food)\n\n""food"" in flat_food_list\n']","['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_non_food\n']"
7193,7193,0,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_non_food\n']",['']
7193,7456,0,[''],"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\nlen(df_non_food), len(df_food)\n\nlist(df[""class_name""])\n']"
7456,7470,4,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\nlen(df_non_food), len(df_food)\n\nlist(df[""class_name""])\n']","['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\nlen(df_non_food), len(df_food)\n\nlist(df_food.class_name) \n']"
7470,7518,4,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\nlen(df_non_food), len(df_food)\n\nlist(df_food.class_name) \n']","['# Filter dataframe from food classes\ndf_non_food = df [~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\nlen(df_non_food), len(df_food)\n']"
7518,7618,0,"['# Filter dataframe from food classes\ndf_non_food = df [~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\nlen(df_non_food), len(df_food)\n']",['flat_food_list[:10]\n']
7618,8351,0,['flat_food_list[:10]\n'],"['# Manually removing not foods from flat_food_list\nnot_food_list = [""ball"",\n   \'puppy\',\n   \'dog\',\n   \'bar\',\n   \'blade\',\n   \'garden\',\n   \'hand\', \n   \'head\',\n   \'jacket\',\n   \'junk\',\n   \'key\',\n   \'leg\',\n   \'oven\',\n   \'pin\',\n\n']"
8351,8351,0,"['# Manually removing not foods from flat_food_list\nnot_food_list = [""ball"",\n   \'puppy\',\n   \'dog\',\n   \'bar\',\n   \'blade\',\n   \'garden\',\n   \'hand\', \n   \'head\',\n   \'jacket\',\n   \'junk\',\n   \'key\',\n   \'leg\',\n   \'oven\',\n   \'pin\',\n\n']","[""'pilot',\n'runner',\n'smith',\n'ash',\n'sand']\n""]"
8351,8351,5,"[""'pilot',\n'runner',\n'smith',\n'ash',\n'sand']\n""]","[""'plate',\n'pot',\n'rack',\n'refrigerator',\n'saddle',\n'shank',\n'spring',\n'steamer',\n'stick',\n'temple',\n'truck',\n'turban',\n'ring',\n'cup',\n'rock',\n'shell',\n'pilot',\n'runner',\n'smith',\n'ash',\n'sand']\n""]"
8351,9278,6,"[""'plate',\n'pot',\n'rack',\n'refrigerator',\n'saddle',\n'shank',\n'spring',\n'steamer',\n'stick',\n'temple',\n'truck',\n'turban',\n'ring',\n'cup',\n'rock',\n'shell',\n'pilot',\n'runner',\n'smith',\n'ash',\n'sand']\n""]","[""'shell',\n'pilot',\n'runner',\n'smith',\n'ash',\n'sand']\n\n\nnot_food_list[:5]\n""]"
9278,9353,0,"[""'shell',\n'pilot',\n'runner',\n'smith',\n'ash',\n'sand']\n\n\nnot_food_list[:5]\n""]","['# Next\n# Filter out non-food items from dataframe (manually sorted)\n# Donwload ImageNet Food & Non—food class images\n# Make dataset of food and not food\n\n# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\ndf_food = df[~df[""class_name""].isin(not_food_list)] # remove even more not food items\nlen(df_non_food), len(df_food) |\n']"
9353,9372,0,"['# Next\n# Filter out non-food items from dataframe (manually sorted)\n# Donwload ImageNet Food & Non—food class images\n# Make dataset of food and not food\n\n# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\ndf_food = df[~df[""class_name""].isin(not_food_list)] # remove even more not food items\nlen(df_non_food), len(df_food) |\n']",['len(df_food)\n\nlist(df_food.class_name) [:5]\n\nlist(df_food.class_name)\n']
9372,9447,3,['len(df_food)\n\nlist(df_food.class_name) [:5]\n\nlist(df_food.class_name)\n'],"['#Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\ndf_food = df_food[~df[""class_name""].isin(not_food_list)] # remove even more not food items\nlen(df_non_food), len(df_food)\n\nlen(df_food)\n\nlist(df_food.class_name)[:5]\n']"
9447,9459,7,"['#Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(flat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\ndf_food = df_food[~df[""class_name""].isin(not_food_list)] # remove even more not food items\nlen(df_non_food), len(df_food)\n\nlen(df_food)\n\nlist(df_food.class_name)[:5]\n']","['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(ﬂat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\ndf_food = df_food[~df[""class_name""].isin(not_food list)] # remove even more not food items\nlen(df_non_food), len(df_food)\n\nlen(df_food)\n\nlist(df_food.class_name) [:5]\n']"
9459,9636,0,"['# Filter dataframe from food classes\ndf_non_food = df[~df[""class_name""].isin(ﬂat_food_list)]\ndf_food = df[df[""class_name""].isin(flat_food_list)]\ndf_food = df_food[~df[""class_name""].isin(not_food list)] # remove even more not food items\nlen(df_non_food), len(df_food)\n\nlen(df_food)\n\nlist(df_food.class_name) [:5]\n']","['imagenet_food_class_ids = df_food[[""synid"", ""class_name""]].to_dict()\nimagenet_food_class_ids\n']"
9636,9672,1,"['imagenet_food_class_ids = df_food[[""synid"", ""class_name""]].to_dict()\nimagenet_food_class_ids\n']","['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_ids\n']"
9672,9704,1,"['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_ids\n']","['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df[""class_names""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nimagenet_food_class_ids_and_names_dict\n']"
9704,9712,4,"['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df[""class_names""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nimagenet_food_class_ids_and_names_dict\n']","['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df[""class_name""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nimagenet_food_class_ids_and_names_dict\n']"
9712,9735,4,"['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df[""class_name""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nimagenet_food_class_ids_and_names_dict\n']","['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df[""class_name""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nimagenet_food_class_ids_and_names_dict\n']"
9735,9762,3,"['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df[""class_name""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nimagenet_food_class_ids_and_names_dict\n']","['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df_food[""class_name""].tolist()\nimagenet_food_class_ids_and_names_d \nimagenet_food_class_ids_and_names_d \n\n']"
9762,9767,4,"['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df_food[""class_name""].tolist()\nimagenet_food_class_ids_and_names_d \nimagenet_food_class_ids_and_names_d \n\n']","['imagenet_non_food_class_ids = df_non_food[""synid""].tolist()\nimagenet_non_food_class_names = df_non_food[""class_name""].tolist()\nimagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))\nimagenet_non_food_class_ids_and_names_dict\n']"
9767,9791,4,"['imagenet_non_food_class_ids = df_non_food[""synid""].tolist()\nimagenet_non_food_class_names = df_non_food[""class_name""].tolist()\nimagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))\nimagenet_non_food_class_ids_and_names_dict\n']","['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df_food[""class_name""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nlen(imagenet_food_class_ids_and_names_dict)\n\n\nimagenet_non_food_class_ids = df_non_food[""synid""].tolist()\nimagenet_non_food_class_names = df_non_food[""class_name""].tolist()\nimagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))\nlen(imagenet_non_food_class_ids_and_names_dict) \n']"
9791,9791,8,"['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df_food[""class_name""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nlen(imagenet_food_class_ids_and_names_dict)\n\n\nimagenet_non_food_class_ids = df_non_food[""synid""].tolist()\nimagenet_non_food_class_names = df_non_food[""class_name""].tolist()\nimagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))\nlen(imagenet_non_food_class_ids_and_names_dict) \n']","['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df_food[""class_name""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nlen(imagenet_food_class_ids_and_names_dict)\n\nimagenet_non_food_class_ids = df_non_food[""synid""].tolist()\nimagenet_non_food_class_names = df_non_food[""class_name""].tolist()\nimagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))\nlen(imagenet_non_food_class_ids_and_names_dict) |\n']"
9791,10917,2,"['imagenet_food_class_ids = df_food[""synid""].tolist()\nimagenet_food_class_names = df_food[""class_name""].tolist()\nimagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))\nlen(imagenet_food_class_ids_and_names_dict)\n\nimagenet_non_food_class_ids = df_non_food[""synid""].tolist()\nimagenet_non_food_class_names = df_non_food[""class_name""].tolist()\nimagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))\nlen(imagenet_non_food_class_ids_and_names_dict) |\n']",['len(imagenet_non_food_class_ids_and_names_dict)\n\nlist(imagenet_food_class_ids_and_names_dict.keys())\n']
10917,11142,0,['len(imagenet_non_food_class_ids_and_names_dict)\n\nlist(imagenet_food_class_ids_and_names_dict.keys())\n'],"[""test_list_images = ['n13918387',\n 'n13919547']\n\n!python ImageNet-Datasets-Downloader/downloader.py \\\n   -data_root test_images \\ \n   -use_class_list=True \\\n   -number_of_classes test_list_images \\\n   -images_per_class 10|\n""]"
11142,11241,5,"[""test_list_images = ['n13918387',\n 'n13919547']\n\n!python ImageNet-Datasets-Downloader/downloader.py \\\n   -data_root test_images \\ \n   -use_class_list=True \\\n   -number_of_classes test_list_images \\\n   -images_per_class 10|\n""]","['test_list_images = [\'n13918387\', \'n13919547\']\nempty_string = """"\nfor item in test_list_images:\n   empty_string += "" "" + item\nempty_string\n\n!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -number_of_classes test_list_images \\\n   -images_per_class 10\n']"
11241,11294,4,"['test_list_images = [\'n13918387\', \'n13919547\']\nempty_string = """"\nfor item in test_list_images:\n   empty_string += "" "" + item\nempty_string\n\n!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -number_of_classes test_list_images \\\n   -images_per_class 10\n']",['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -number_of_classes empty_string \\\n   -images_per_class 10\n']
11294,11568,4,['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -number_of_classes empty_string \\\n   -images_per_class 10\n'],['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -number_of_classes n13918387 n13919547 \\\n   -images_per_class 10\n']
11568,11585,4,['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -number_of_classes n13918387 n13919547 \\\n   -images_per_class 10\n'],['!python ImageNet-Datasets-Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -class_list empty_string[1:] \\\n   -images_per_class 10\n']
11585,11599,4,['!python ImageNet-Datasets-Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -class_list empty_string[1:] \\\n   -images_per_class 10\n'],['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -class_list n13918387 n13919547 \\|\n   -images_per_class 10\n']
11599,11624,4,['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -class_list n13918387 n13919547 \\|\n   -images_per_class 10\n'],['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -class_list $empty_string[1:] \\\n   -images_per_class 10\n']
11624,11661,5,['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -class_list $empty_string[1:] \\\n   -images_per_class 10\n'],['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -class_list $empty_string \\\n   -images_per_class 10\n']
11661,11867,0,['!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root test_images \\\n   -use_class_list=True \\\n   -class_list $empty_string \\\n   -images_per_class 10\n'],['# Get food string class IDs\nfood_class_id_list = list(imagenet_food_class_ids_and_names_dict.keys())\nfood_class_id_list[:10]\n']
11867,11909,1,['# Get food string class IDs\nfood_class_id_list = list(imagenet_food_class_ids_and_names_dict.keys())\nfood_class_id_list[:10]\n'],"['# Get food and non-food string class IDs\nfood_class_id_list = list(imagenet_food_class_ids_and_names_dict.keys()) |\nnon_food_class_id_list = list(imagenet_non_food_class_ids_and_names_dict.keys())\nfood_class_id_list[:5], non_food_class_id_list[:5]\n']"
11909,12044,0,"['# Get food and non-food string class IDs\nfood_class_id_list = list(imagenet_food_class_ids_and_names_dict.keys()) |\nnon_food_class_id_list = list(imagenet_non_food_class_ids_and_names_dict.keys())\nfood_class_id_list[:5], non_food_class_id_list[:5]\n']","['def convert_list_to_long_string(targ_list):\n   long_string = """"\n   for item in targ_list:\n   long_string += "" "" + item\n   long_string = long_string[1:]\n   return long_string\n\nfood_class_id_string = convert_list_to_long_string(food_class_id_list)\nnon_food_class_id_string = convert_list_to_long_string(non_food_class_id_list)\nfood_class_id_string[:10], non_food_class_id_string[:10]\n']"
12044,12044,9,"['def convert_list_to_long_string(targ_list):\n   long_string = """"\n   for item in targ_list:\n   long_string += "" "" + item\n   long_string = long_string[1:]\n   return long_string\n\nfood_class_id_string = convert_list_to_long_string(food_class_id_list)\nnon_food_class_id_string = convert_list_to_long_string(non_food_class_id_list)\nfood_class_id_string[:10], non_food_class_id_string[:10]\n']","['def convert_list_to_long_string(targ_list):\n   long_string = """"\n   for item in targ_list:\n      long_string += "" "" + item\n   long_string = long_string[1:]\n   return long_string\n\nfood_class_id_string = convert_list_to_long_string(food_class_id_list)\nnon_food_class_id_string = convert_list_to_long_string(non_food_class_id_list)\nfood_class_id_string[:10], non_food_class_id_string[:10]\n\nfood_class_id_string|\n']"
12044,12325,0,"['def convert_list_to_long_string(targ_list):\n   long_string = """"\n   for item in targ_list:\n      long_string += "" "" + item\n   long_string = long_string[1:]\n   return long_string\n\nfood_class_id_string = convert_list_to_long_string(food_class_id_list)\nnon_food_class_id_string = convert_list_to_long_string(non_food_class_id_list)\nfood_class_id_string[:10], non_food_class_id_string[:10]\n\nfood_class_id_string|\n']",['!mkdir data/non_food_images/\n\n\nlen(food_class_id_list) \n\n!python ImageNet-Datasets-Downloader/downloader.py \\\n   -data_root data/food_images \\\n   -use_class_list=True \\\n   ~class_list $food_class_id_string \\\n   -images_per_class 100\n']
12325,12424,7,['!mkdir data/non_food_images/\n\n\nlen(food_class_id_list) \n\n!python ImageNet-Datasets-Downloader/downloader.py \\\n   -data_root data/food_images \\\n   -use_class_list=True \\\n   ~class_list $food_class_id_string \\\n   -images_per_class 100\n'],['!mkdir data/non_food_images/\n\nlen(non_food_class_id_list)\n\n!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root data/non_food_images \\\n   -use_class_list=True \\\n   -class_list $non_food_class_id_string \\ \n   -images_per_class 10\n']
12424,13226,0,['!mkdir data/non_food_images/\n\nlen(non_food_class_id_list)\n\n!python ImageNet-Datasets—Downloader/downloader.py \\\n   -data_root data/non_food_images \\\n   -use_class_list=True \\\n   -class_list $non_food_class_id_string \\ \n   -images_per_class 10\n'],['import tensorflow as tf']
13226,13232,1,['import tensorflow as tf'],['import tensorflow as tf\n\ntf.config.list_physical_devices()\n']
13232,13232,2,['import tensorflow as tf\n\ntf.config.list_physical_devices()\n'],['import tensorflow as tf\n\ntf.config.list_physical_devices()\n']
13232,13259,0,['import tensorflow as tf\n\ntf.config.list_physical_devices()\n'],['import gradio as gr\n']
13259,13371,0,['import gradio as gr\n'],"[""import tensorflow as tf\ntf.get_logger().setLevel('INFO')\n\ntf.config.list_physical_devices()\n""]"
13371,13389,0,"[""import tensorflow as tf\ntf.get_logger().setLevel('INFO')\n\ntf.config.list_physical_devices()\n""]",['import tflite model_maker\n']
13389,13927,0,['import tflite model_maker\n'],['!ls data/model_test_images/\n']
13927,13946,0,['!ls data/model_test_images/\n'],['import os\nos.walk(data/model_test_images/)\n']
13946,13999,0,['import os\nos.walk(data/model_test_images/)\n'],['# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n#mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Image folders\ndata/imagenet_images/*\ndata/food_images/*\ndata/non_food_images/*\n']
13999,14065,0,['# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n#mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Image folders\ndata/imagenet_images/*\ndata/food_images/*\ndata/non_food_images/*\n'],"['import os\nfor dirs, sub_dirs, files in os.walk(""data/model_test_images/""):\n   print(files)\n']"
14065,14091,0,"['import os\nfor dirs, sub_dirs, files in os.walk(""data/model_test_images/""):\n   print(files)\n']","['os.listdir(""data/model_test_images/anvil"")\n']"
14091,14121,0,"['os.listdir(""data/model_test_images/anvil"")\n']","['import os\nfor dirs, sub_dirs, files in os.walk(""data/model_test_images/""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n']"
14121,14267,5,"['import os\nfor dirs, sub_dirs, files in os.walk(""data/model_test_images/""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n']","['!mkdir data/model_test_images/train\n!mkdir data/model_test_images/test\n\nimport os\nfor dirs, sub_dirs, files in os.walk(""data/model_test_images/""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n']"
14267,14365,0,"['!mkdir data/model_test_images/train\n!mkdir data/model_test_images/test\n\nimport os\nfor dirs, sub_dirs, files in os.walk(""data/model_test_images/""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n']","['aircraft_images = os.listdir(""data/model_test_images/aircraft"")\naircraft_images\n']"
14365,14373,2,"['aircraft_images = os.listdir(""data/model_test_images/aircraft"")\naircraft_images\n']","['aircraft_images = os.listdir(""data/model_test_images/aircraft"")\naircraft_images\n']"
14373,14395,1,"['aircraft_images = os.listdir(""data/model_test_images/aircraft"")\naircraft_images\n']","['aircraft_images = os.listdir(""data/model_test_images/aircraft"")\nlen(aircraft_images)\n\ntrain_split = int(0.8 * len(aircraft_images))\ntrain_split\n']"
14395,14449,0,"['aircraft_images = os.listdir(""data/model_test_images/aircraft"")\nlen(aircraft_images)\n\ntrain_split = int(0.8 * len(aircraft_images))\ntrain_split\n']",['import numpy as np\n\ntrain_idx = np.range(len(aircraft_images))\ntrain_idx\n']
14449,14478,3,['import numpy as np\n\ntrain_idx = np.range(len(aircraft_images))\ntrain_idx\n'],['import numpy as np\n\ntrain_idx = np.arange(len(aircraft_images))\ntrain_idx\n']
14478,14603,0,['import numpy as np\n\ntrain_idx = np.arange(len(aircraft_images))\ntrain_idx\n'],"['import random\nrandom.sample(aircraft_images, 10)\n']"
14603,14608,2,"['import random\nrandom.sample(aircraft_images, 10)\n']","['import random\nrandom.seed(42)\nrandom.sample(aircraft_images, 10)\n']"
14608,14608,3,"['import random\nrandom.seed(42)\nrandom.sample(aircraft_images, 10)\n']","['import random\nrandom.seed(42)\nrandom.sample(aircraft_images, 10)\n']"
14608,14730,2,"['import random\nrandom.seed(42)\nrandom.sample(aircraft_images, 10)\n']","['import random\nrandom.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = aircraft_images not in train_image_list\n']"
14730,14769,4,"['import random\nrandom.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = aircraft_images not in train_image_list\n']","['import random\nrandom. seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = set([train_image_list]).difference(set([aircraft_images]))\ntest_image_list\n']"
14769,14769,4,"['import random\nrandom. seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = set([train_image_list]).difference(set([aircraft_images]))\ntest_image_list\n']","['train_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = set([train_image_list]).difference(set([aircraft_images]))\ntest_image_list\n']"
14769,14784,4,"['train_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = set([train_image_list]).difference(set([aircraft_images]))\ntest_image_list\n']","['train_sptit = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = set(train_image_list).difference(set(aircraft_images))\ntest_image_list\n']"
14784,14784,4,"['train_sptit = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = set(train_image_list).difference(set(aircraft_images))\ntest_image_list\n']","['train_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = set(train_image_list).difference(set(aircraft_images))\ntest_image_list\n\ntest_image_list\n']"
14784,14827,4,"['train_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = set(train_image_list).difference(set(aircraft_images))\ntest_image_list\n\ntest_image_list\n']","['random.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = list(set(aircraft_images).difference(set(train_image_list)))\ntest_image_list\n']"
14827,14827,5,"['random.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = list(set(aircraft_images).difference(set(train_image_list)))\ntest_image_list\n']","['random.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = list(set(aircraft_images).difference(set(train_image_list)))\ntest_image_list\n']"
14827,14845,4,"['random.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = list(set(aircraft_images).difference(set(train_image_list)))\ntest_image_list\n']","['import random\nrandom.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = list(set(aircraft_images).difference(set(train_image_list)))\nlen(train_image_list), len(test_image_list)']"
14845,14845,6,"['import random\nrandom.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = list(set(aircraft_images).difference(set(train_image_list)))\nlen(train_image_list), len(test_image_list)']","['import random\nrandom.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = list(set(aircraft_images).difference(set(train_image_list)))\nlen(train_image_list), len(test_image_list)\n']"
14845,14944,3,"['import random\nrandom.seed(42)\n\ntrain_split = int(0.8 * len(aircraft_images))\n\ntrain_image_list = random.sample(aircraft_images, train_split)\ntest_image_list = list(set(aircraft_images).difference(set(train_image_list)))\nlen(train_image_list), len(test_image_list)\n']","['import random\n\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n']"
14944,14979,3,"['import random\n\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n']","['   train_image_List = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']"
14979,14979,5,"['   train_image_List = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']","['import random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']"
14979,15040,7,"['import random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']","['target_dirs = os.listdir(""data/model_test_images"")\ntarget_dirs\n\nimport random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n']"
15040,15040,9,"['target_dirs = os.listdir(""data/model_test_images"")\ntarget_dirs\n\nimport random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n']","['target_dirs = os.listdir(""data/model_test_images"")\ntarget_dirs\n\nimport random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test image list = list(set(image_list).difference(set(train_image_list)))\n']"
15040,15156,9,"['target_dirs = os.listdir(""data/model_test_images"")\ntarget_dirs\n\nimport random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test image list = list(set(image_list).difference(set(train_image_list)))\n']","['target_dirs = os.listdir(""data/model_test_images_split/)\ntarget_dirs\n\nimport random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test image list = list(set(image_list).difference(set(train_image_list)))\n']"
15156,15182,0,"['target_dirs = os.listdir(""data/model_test_images_split/)\ntarget_dirs\n\nimport random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = os.listdir(target_dir)\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test image list = list(set(image_list).difference(set(train_image_list)))\n']","['# Create a function to move images\nfor image_dir in os.listdir(""model_test_images""):\n   print(image_dir)\n']"
15182,15226,2,"['# Create a function to move images\nfor image_dir in os.listdir(""model_test_images""):\n   print(image_dir)\n']","['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n\ntest_image_list\n']"
15226,15273,6,"['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n\ntest_image_list\n']","['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir): \n   print(image_dir)\n   train_image_list, test_image_list = create \n   len(train_image_list), len(test_image_list)\n\ntest_image_list\n']"
15273,15307,6,"['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir): \n   print(image_dir)\n   train_image_list, test_image_list = create \n   len(train_image_list), len(test_image_list)\n\ntest_image_list\n']","['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   len(train_image_list), len(test_image_list)\n']"
15307,15352,4,"['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   len(train_image_list), len(test_image_list)\n']","['for image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n']"
15352,15352,5,"['for image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n']","['for image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n']"
15352,15376,5,"['for image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n']","['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n   print(train_image_list[:5])\n']"
15376,15376,9,"['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n   print(train_image_list[:5])\n']","['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n   print(train_image_list[:5])\n']"
15376,15421,1,"['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n   print(train_image_list[:5])\n']","['import random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = (os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir))\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']"
15421,15532,1,"['import random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = (os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir))\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']","['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n   print(train_image_list[:5])\n   for image_path in train_image_list[:]:\n      dest_dir = os.path.join(target_dir, image_dir)\n      print(dest_dir)\n']"
15532,15536,12,"['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n   print(train_image_list[:5])\n   for image_path in train_image_list[:]:\n      dest_dir = os.path.join(target_dir, image_dir)\n      print(dest_dir)\n']","['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n   print(train_image_list[:5])\n   for image_path in train_image_list[:5]:\n      dest_dir = os.path.join(target_dir, image_dir)\n      print(dest_dir)\n']"
15536,15577,7,"['# Create a function to move images\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   print(image_dir)\n   print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   print(len(train_image_list), len(test_image_list))\n   print(train_image_list[:5])\n   for image_path in train_image_list[:5]:\n      dest_dir = os.path.join(target_dir, image_dir)\n      print(dest_dir)\n']","['print(image_dir)\nprint(os.path.join(data_dir, image_dir))\ntrain_image_list, test_image_list = create_train_ \nprint(len(train_image_list), len(test_image_list)\nprint(train_image_list[:5]) \n\n# Copy training images \nfor image_path in train_image_list[:5]: \n   dest_dir = os.path.join(target_dir, ""train"", image_dir)\n   print(dest_dir)\n\n# Copy testing images\n']"
15577,15620,8,"['print(image_dir)\nprint(os.path.join(data_dir, image_dir))\ntrain_image_list, test_image_list = create_train_ \nprint(len(train_image_list), len(test_image_list)\nprint(train_image_list[:5]) \n\n# Copy training images \nfor image_path in train_image_list[:5]: \n   dest_dir = os.path.join(target_dir, ""train"", image_dir)\n   print(dest_dir)\n\n# Copy testing images\n']","['print(image_dir)\nprint(os.path.join(data_dir, image_dir))\ntrain_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\nprint(len(train_image_list), len(test_image_list))\nprint(train_image_list[:5])\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n\n# Copy testing images\n']"
15620,15635,10,"['print(image_dir)\nprint(os.path.join(data_dir, image_dir))\ntrain_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\nprint(len(train_image_list), len(test_image_list))\nprint(train_image_list[:5])\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n\n# Copy testing images\n']","['print(os.path.join(data_dir, image_dir))\ntrain_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\nprint(len(train_image_list), len(test_image_list))\nprint(train_image_list[:5])\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n']"
15635,15636,14,"['print(os.path.join(data_dir, image_dir))\ntrain_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\nprint(len(train_image_list), len(test_image_list))\nprint(train_image_list[:5])\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n']","['print(os.path.join(data_dir, image_dir))\ntrain_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\nprint(len(train_image_list), len(test_image_list))\nprint(train_image_list[:5])\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n']"
15636,15643,9,"['print(os.path.join(data_dir, image_dir))\ntrain_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\nprint(len(train_image_list), len(test_image_list))\nprint(train_image_list[:5])\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n']","['# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(dest_dir)\n']"
15643,15656,5,"['# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(dest_dir)\n']","['data_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n# Copy training images \nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest dir = os.path.ioin(target_dir, ""test"", image_dir, image_file_name)\n']"
15656,15679,15,"['data_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n# Copy training images \nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(dest_dir)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest dir = os.path.ioin(target_dir, ""test"", image_dir, image_file_name)\n']","['data_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(f""Moving: {image_path} to {dest_dir}"")\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest dir = os.path.ioin(target_dir, ""test"", image_dir, image_file_name)\n']"
15679,15687,8,"['data_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(f""Moving: {image_path} to {dest_dir}"")\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest dir = os.path.ioin(target_dir, ""test"", image_dir, image_file_name)\n']","['# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print{(f""Moving: {image_path} to {dest_dir}"")]\n']"
15687,15705,5,"['# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print{(f""Moving: {image_path} to {dest_dir}"")]\n']","['print(f""Moving: {image_path} to {dest_dir}"")\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(f""Moving: \\n{image_path} to \\n{dest_dir}"")\n']"
15705,15719,6,"['print(f""Moving: {image_path} to {dest_dir}"")\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(f""Moving: \\n{image_path} to \\n{dest_dir}"")\n']","['train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n# print(len(train_image_list), len(test_image_list))\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print{(f“Copying: {image_path} to {dest_dir}"")\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print{(f""Copying: \\n{image_path} to \\n{dest_dir}"")]\n']"
15719,15863,8,"['train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n# print(len(train_image_list), len(test_image_list))\n\n# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print{(f“Copying: {image_path} to {dest_dir}"")\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print{(f""Copying: \\n{image_path} to \\n{dest_dir}"")]\n']","['# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(f""Copying: {image_path} to {dest_path}"") \n\n# Copy testing images \nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(f""Copying: \\n{image_path} to \\n{dest_path} ]\n   copy2(image_path, dest_path)\n']"
15863,15866,11,"['# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(f""Copying: {image_path} to {dest_path}"") \n\n# Copy testing images \nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path) [-1]\n   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(f""Copying: \\n{image_path} to \\n{dest_path} ]\n   copy2(image_path, dest_path)\n']","['# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(f""Copying: {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(f""Copying: \\n{image_path} to \\n{dest_path}"")\n   copy2(image_path, dest_path)\n']"
15866,15938,12,"['# Copy training images\nfor image_path in train_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n   print(f""Copying: {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(f""Copying: \\n{image_path} to \\n{dest_path}"")\n   copy2(image_path, dest_path)\n']","['for image_dir in os.listdir(data_dir): \n   # Make target directory\n   os.makdirs(os.path.join(target_dir, image_dir), exists_ok=True)\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   for image_path in train_image_list[:5]:\n      image_file_name = os.path.split(image_path)[-1] \n      dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"") :\n      copy2(image_path, dest_path) }\n\n   # Copy testing images \n']"
15938,15947,6,"['for image_dir in os.listdir(data_dir): \n   # Make target directory\n   os.makdirs(os.path.join(target_dir, image_dir), exists_ok=True)\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   for image_path in train_image_list[:5]:\n      image_file_name = os.path.split(image_path)[-1] \n      dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"") :\n      copy2(image_path, dest_path) }\n\n   # Copy testing images \n']","['# Create a function to move images\nfrom shutil import copy2\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # Make target directory\n   os.makedirs(os.path.join(target_dir, image dir), exists_ok=True)\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n\n   # Make training and test lists of target images\n']"
15947,15954,6,"['# Create a function to move images\nfrom shutil import copy2\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # Make target directory\n   os.makedirs(os.path.join(target_dir, image dir), exists_ok=True)\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n\n   # Make training and test lists of target images\n']","['for image_dir in os.listdir(data_dir):\n   # Make target directory\n   os.makedirs(os.path.join(target_dir, image_dir), exist_ok=True)\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   for image_path in train_image_list[:5]:\n      image_file_name = os.path.split(image_path) [-1]\n      dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\n   # Copy testing images\n']"
15954,16172,7,"['for image_dir in os.listdir(data_dir):\n   # Make target directory\n   os.makedirs(os.path.join(target_dir, image_dir), exist_ok=True)\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   for image_path in train_image_list[:5]:\n      image_file_name = os.path.split(image_path) [-1]\n      dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\n   # Copy testing images\n']","['def copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      # Make target directory\n      os.makedirs(os.path.join(target_dir, ""train""), exist_ok=True)\n   else:\n      os.makedirs(os.path.join(target_dir, ""test""), exist_ok=True)\n\n   # Copy images\n   for image_path in train_image_list[:5]:\n      image_file_name = os.path.split(image_path) [-1]\n      dest_path = os.path.join(target_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n']"
16172,16246,10,"['def copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      # Make target directory\n      os.makedirs(os.path.join(target_dir, ""train""), exist_ok=True)\n   else:\n      os.makedirs(os.path.join(target_dir, ""test""), exist_ok=True)\n\n   # Copy images\n   for image_path in train_image_list[:5]:\n      image_file_name = os.path.split(image_path) [-1]\n      dest_path = os.path.join(target_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n']","['      # Make target directory\n      split_dir = ""train""\n      os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n   else:\n      split_dir = ""test""\n      os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n\n   # Copy images\n   for image_path in train_image_list[:5]:\n      image_file_name = os.path.split(image_path) [-1]\n      dest_path = os.path.join(target_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to (dest_path}"")\n      copy2(image_path, dest_path)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n']"
16246,16250,14,"['      # Make target directory\n      split_dir = ""train""\n      os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n   else:\n      split_dir = ""test""\n      os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n\n   # Copy images\n   for image_path in train_image_list[:5]:\n      image_file_name = os.path.split(image_path) [-1]\n      dest_path = os.path.join(target_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to (dest_path}"")\n      copy2(image_path, dest_path)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n']","['         # Make target directory\n         split_dir = ""train""\n         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n      else:\n         split_dir = ""test""\n         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n\n      # Copy images\n      for image_path in train_image_list[:5]:\n         image_file_name = os.path.split(image_path) [-1]\n         dest_path = os.path.join(target_dir, image_dir, split_dir, image_file_name)\n         print(f""Copying: {image_path} to {dest_path}"")\n         copy2(image_path, dest_path)I\n\n   # Copy testing images\n   for image path in test_image_list[:5]:\n']"
16250,16283,5,"['         # Make target directory\n         split_dir = ""train""\n         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n      else:\n         split_dir = ""test""\n         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n\n      # Copy images\n      for image_path in train_image_list[:5]:\n         image_file_name = os.path.split(image_path) [-1]\n         dest_path = os.path.join(target_dir, image_dir, split_dir, image_file_name)\n         print(f""Copying: {image_path} to {dest_path}"")\n         copy2(image_path, dest_path)I\n\n   # Copy testing images\n   for image path in test_image_list[:5]:\n']","['      # Copy images\n      for image_path in img_path_list[:5]:\n         image_file_name = os.path.split(image_path) [-1]\n         dest_path = os.path.join(target_dir, image_dir, split_dir, image_file_name)\n         print(f""Copying: {image_path} to {dest_path}"")\n         copy2(image_path, dest_path)\n\n# Create a function to move images\nfrom shutil import copy2\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n']"
16283,16412,2,"['      # Copy images\n      for image_path in img_path_list[:5]:\n         image_file_name = os.path.split(image_path) [-1]\n         dest_path = os.path.join(target_dir, image_dir, split_dir, image_file_name)\n         print(f""Copying: {image_path} to {dest_path}"")\n         copy2(image_path, dest_path)\n\n# Create a function to move images\nfrom shutil import copy2\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n']","['# print(len(train_image_list), len(test_image_list))\n\n# Copy training images\ncopy_images_to_file(img_path_list=train_image_list,\n   target_dir=target_dir,\n   train=True)\n\n# Copy testing images\ncopy_images_to_file(img_path_list=train_image_list,\n   target_dir=target_dir,\n   train=True)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(f""Copying \\n{image_path} to \\n{dest_path})\n']"
16412,16422,9,"['# print(len(train_image_list), len(test_image_list))\n\n# Copy training images\ncopy_images_to_file(img_path_list=train_image_list,\n   target_dir=target_dir,\n   train=True)\n\n# Copy testing images\ncopy_images_to_file(img_path_list=train_image_list,\n   target_dir=target_dir,\n   train=True)\n\n# Copy testing images\nfor image_path in test_image_list[:5]:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)\n   print(f""Copying \\n{image_path} to \\n{dest_path})\n']","['# Copy training images\ncopy_images_to_file(img_path_list=train_image_list,\n   target_dir=target_dir,\n   train=True)\n\n# Copy testing images\ncopy_images_to_file(img_path_list=test_image_list,\n   target_dir=target_dir,\n   train=False)\n']"
16422,16424,6,"['# Copy training images\ncopy_images_to_file(img_path_list=train_image_list,\n   target_dir=target_dir,\n   train=True)\n\n# Copy testing images\ncopy_images_to_file(img_path_list=test_image_list,\n   target_dir=target_dir,\n   train=False)\n']","['   # Copy testing images\n   copy_images_to_file(img_path_list=test_image_list,\n      target_dir=target_dir,\n      train=False)\n']"
16424,16463,0,"['   # Copy testing images\n   copy_images_to_file(img_path_list=test_image_list,\n      target_dir=target_dir,\n      train=False)\n']","['def copy_images_to_file(img_path_list, target_dir, train=True):\n      if train:\n         # Make target directory\n         split_dir = ""train""\n         dir_to_make = os.path.join(target_dir, split_dir) \n         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n      else:\n         split_dir = ""test""\n         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n\n      # Copy images\n      for image_path in img_path_list[:5]:\n']"
16463,16587,0,"['def copy_images_to_file(img_path_list, target_dir, train=True):\n      if train:\n         # Make target directory\n         split_dir = ""train""\n         dir_to_make = os.path.join(target_dir, split_dir) \n         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n      else:\n         split_dir = ""test""\n         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)\n\n      # Copy images\n      for image_path in img_path_list[:5]:\n']",['test_image_list']
16587,16587,0,['test_image_list'],['']
16587,16688,0,[''],"['data_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n   for split_dir in [""train"", ""test""]:\n      os.makedirs(os.path.join(target_dir, image_dir, split_dir))\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list)) \n\n   # Copy training images\n   copy_images_to_file(img_path_list=train_image_list,\n      target_dir=target_dir,\n      train=True)\n\n# Copy testing images\n']"
16688,16695,13,"['data_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n   for split_dir in [""train"", ""test""]:\n      os.makedirs(os.path.join(target_dir, image_dir, split_dir))\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list)) \n\n   # Copy training images\n   copy_images_to_file(img_path_list=train_image_list,\n      target_dir=target_dir,\n      train=True)\n\n# Copy testing images\n']","['data_dir = ""data/model_test_images"" \ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir) \n   # print(os.path.join(data_dir, image_dir))\n   for split_dir in [""train"", ""test""]: \n      os.makedirs(os.path.join(target_dir, image_dir, split_dir), exist_ok=True)\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   copy_images_to_file(img_path_list=train_image_list,\n      target_dir=target_dir,\n      train=True)\n']"
16695,16752,11,"['data_dir = ""data/model_test_images"" \ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir) \n   # print(os.path.join(data_dir, image_dir))\n   for split_dir in [""train"", ""test""]: \n      os.makedirs(os.path.join(target_dir, image_dir, split_dir), exist_ok=True)\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   copy_images_to_file(img_path_list=train_image_list,\n      target_dir=target_dir,\n      train=True)\n']","['# Create a function to move images\nfrom shutil import copy2\ndata_dir = ""data/model_test_images""\ntarget_dir = “data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n   for split_dir in [""train"", ""test""]: \n      os.makedirs(os.path.join(target_dir, split_dir, jmage_dir), exist_ok=True)\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   copy_images_to_file(img_path_list=train_image_list,\n']"
16752,16829,0,"['# Create a function to move images\nfrom shutil import copy2\ndata_dir = ""data/model_test_images""\ntarget_dir = “data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   # print(image_dir)\n   # print(os.path.join(data_dir, image_dir))\n   for split_dir in [""train"", ""test""]: \n      os.makedirs(os.path.join(target_dir, split_dir, jmage_dir), exist_ok=True)\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   copy_images_to_file(img_path_list=train_image_list,\n']","['def copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      print(target_dir)\n      os.makedirs(os.p \nelse:\n   split_dir = ""tes\n   os.makedirs(os.p\n\n   #Copy images\n   for image_path in im \n      image_file_name \n      dest_path = os.p\n      print(f""Copying: \n      copy2(image_path, dest_path)\n']"
16829,16922,6,"['def copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      print(target_dir)\n      os.makedirs(os.p \nelse:\n   split_dir = ""tes\n   os.makedirs(os.p\n\n   #Copy images\n   for image_path in im \n      image_file_name \n      dest_path = os.p\n      print(f""Copying: \n      copy2(image_path, dest_path)\n']","['def copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      split_dir = ""train""\n   else:\n      split_dir = ""test"" \n\n   # Copy images\n   for image_path in img_path_list[:5]:\n      image_file_name = os.path.split(image_path) [-1]\n      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n']"
16922,16963,0,"['def copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      split_dir = ""train""\n   else:\n      split_dir = ""test"" \n\n   # Copy images\n   for image_path in img_path_list[:5]:\n      image_file_name = os.path.split(image_path) [-1]\n      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n']","['target_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   for split_dir in [""train"", ""test""]:\n      os.makedirs(os.path.join(target_dir, split_dir, image_dir), exist_ok=True)\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   copy_images_to_file(img_path_list=train_image_list,\n      target_dir=target_dir,\n      train=True)\n\n   # Copy testing images\n      copy_images_to_file(img_path_list=test_image_list,\n         target_dir=target_dir,\n         train=False)\n']"
16963,16988,4,"['target_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   for split_dir in [""train"", ""test""]:\n      os.makedirs(os.path.join(target_dir, split_dir, image_dir), exist_ok=True)\n\n   # Make training and test lists of target images\n   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))\n   # print(len(train_image_list), len(test_image_list))\n\n   # Copy training images\n   copy_images_to_file(img_path_list=train_image_list,\n      target_dir=target_dir,\n      train=True)\n\n   # Copy testing images\n      copy_images_to_file(img_path_list=test_image_list,\n         target_dir=target_dir,\n         train=False)\n']","['# Copy images\nfor image_path in img_path_list:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n   print(f""Copying: {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n\n# Create a function to move images\nfrom shutil import copy2\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   for split_dir in [""train"", ""test""]:\n      os.makedirs(os.path.join(target_dir, split_dir, image_dir), exist_ok=True)\n']"
16988,17021,0,"['# Copy images\nfor image_path in img_path_list:\n   image_file_name = os.path.split(image_path)[-1]\n   dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n   print(f""Copying: {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n\n# Create a function to move images\nfrom shutil import copy2\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   for split_dir in [""train"", ""test""]:\n      os.makedirs(os.path.join(target_dir, split_dir, image_dir), exist_ok=True)\n']",['\n']
17021,17410,0,['\n'],['import tensorflow as tf\n']
17410,17487,0,['import tensorflow as tf\n'],"['train_dir = ""data/model_test_images_split/train""\ntest_dir = ""data/model_test_images_split/test""\ntrain_dir, test_dir\n']"
17487,17642,0,"['train_dir = ""data/model_test_images_split/train""\ntest_dir = ""data/model_test_images_split/test""\ntrain_dir, test_dir\n']",['']
17642,17649,0,[''],"['# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntrain_data = test_data\n']"
17649,17667,0,"['# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntrain_data = test_data\n']",['']
17667,17671,0,[''],"['   image_size=(224, 224)\n}\n\ntrain_data, test_data\n']"
17671,17740,0,"['   image_size=(224, 224)\n}\n\ntrain_data, test_data\n']",['train_data = train_data.prefetch(tf.data.AUTOTUNE)\ntest_data = test_data.prefetch(tf.data.AUTOTUNE)\n']
17740,17894,0,['train_data = train_data.prefetch(tf.data.AUTOTUNE)\ntest_data = test_data.prefetch(tf.data.AUTOTUNE)\n'],['base_model = tf.keras.applications.EfficientNetB0(include_top=False)\nbase_model\n']
17894,18058,1,['base_model = tf.keras.applications.EfficientNetB0(include_top=False)\nbase_model\n'],"['base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput = tf.keras.layers.Input(shape=(224, 223, 3))\nx = base_model(input)\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\n']"
18058,18320,7,"['base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput = tf.keras.layers.Input(shape=(224, 223, 3))\nx = base_model(input)\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\n']","['base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.layers.Input(shape=(224, 223, 3))\nx = base_model(input)\nx = tf.keras. layers.GlobalAveragePooling2D()(x)\noutput_layer = tf.keras.layers.Dense(1)(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\nmodel_1\n']"
18320,18338,11,"['base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.layers.Input(shape=(224, 223, 3))\nx = base_model(input)\nx = tf.keras. layers.GlobalAveragePooling2D()(x)\noutput_layer = tf.keras.layers.Dense(1)(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\nmodel_1\n']","['base_model = tf.keras.applications.EfficientNetB@(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.Input(shape=(224, 223, 3))\nx = base_model(input)\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\noutput_layer = tf.keras.layers.Dense(1)(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\nmodel_1\n']"
18338,18339,11,"['base_model = tf.keras.applications.EfficientNetB@(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.Input(shape=(224, 223, 3))\nx = base_model(input)\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\noutput_layer = tf.keras.layers.Dense(1)(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\nmodel_1\n']","['base_model = tf.keras.applications.EfficientNetB@(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.Input(shape=(224, 223, 3))\nx = base_model(input)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutput_layer = tf.keras.layers.Dense(1)(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\nmodel_1\n']"
18339,18354,8,"['base_model = tf.keras.applications.EfficientNetB@(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.Input(shape=(224, 223, 3))\nx = base_model(input)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutput_layer = tf.keras.layers.Dense(1)(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\nmodel_1\n']","['base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.Input(shape=(224, 223, 3))\nx = base_model(input_layer)\nx = tf.keras.\noutput_layer\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\nmodel_1\n']"
18354,18394,0,"['base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.Input(shape=(224, 223, 3))\nx = base_model(input_layer)\nx = tf.keras.\noutput_layer\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\nmodel_1\n']",['tf.keras.utils.plot_model(model_1)\n']
18394,18394,1,['tf.keras.utils.plot_model(model_1)\n'],['tf.keras.utils.plot_model(model_1)\n']
18394,18405,1,['tf.keras.utils.plot_model(model_1)\n'],['tf.keras.utils.plot_model(model_1)\n\n!pip install pydot\n']
18405,18632,1,['tf.keras.utils.plot_model(model_1)\n\n!pip install pydot\n'],"[""!pip install pydot\n!pip install wandb\n\nimport tensorflow as tf\ntf.get_logger().setLevel('INFO')\n""]"
18632,18666,0,"[""!pip install pydot\n!pip install wandb\n\nimport tensorflow as tf\ntf.get_logger().setLevel('INFO')\n""]",['import wandb\n']
18666,19137,1,['import wandb\n'],"['import wandb\nwandb.init(project=""100k-livestream-video"", sync_tensorboard=True)\n']"
19137,19351,0,"['import wandb\nwandb.init(project=""100k-livestream-video"", sync_tensorboard=True)\n']",['tf.keras.utils.plot_model(model_l)\n']
19351,19360,0,['tf.keras.utils.plot_model(model_l)\n'],"['model_1 = tf.keras.Model(input_layer, output_layer)\n\ntf.keras.utils.plot_model(model_1, include_shapes=True)\n']"
19360,19360,2,"['model_1 = tf.keras.Model(input_layer, output_layer)\n\ntf.keras.utils.plot_model(model_1, include_shapes=True)\n']","['model_1 = tf.keras.Model(input_layer, output_layer)\n\ntf.keras.utils.plot_model(model_1, include_shapes=True)\n']"
19360,19395,2,"['model_1 = tf.keras.Model(input_layer, output_layer)\n\ntf.keras.utils.plot_model(model_1, include_shapes=True)\n']","['model_1 = tf.keras.Model(input_layer, output_layer)\n\ntf.keras.utils.plot_model(model_1, show_shapes=True)\n']"
19395,19488,1,"['model_1 = tf.keras.Model(input_layer, output_layer)\n\ntf.keras.utils.plot_model(model_1, show_shapes=True)\n']","['input_tayer = tf.keras.input(shape=(224, 243, 3)) \nx = base_model(input_layer)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutput_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\n']"
19488,19531,0,"['input_tayer = tf.keras.input(shape=(224, 243, 3)) \nx = base_model(input_layer)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutput_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer)\n']","['# Compile model\nmodel_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n   optimizer=tf.keras.optimizers.Adam(),\n   metrics=[""accuracy""]\n}']"
19531,19534,4,"['# Compile model\nmodel_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n   optimizer=tf.keras.optimizers.Adam(),\n   metrics=[""accuracy""]\n}']","['# Compile model\nmodel_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n   optimizer=tf.keras.optimizers.Adam(),\n   metrics=[""accuracy""]\n)\n']"
19534,19607,1,"['# Compile model\nmodel_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n   optimizer=tf.keras.optimizers.Adam(),\n   metrics=[""accuracy""]\n)\n']","['# Create EarlyStopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=5,\n   monitor=""val_loss""\n)\n\n# fit model\nhistory_1 = model_1.fit(train_data,\n  epochs=25,\n)\n']"
19607,19639,8,"['# Create EarlyStopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=5,\n   monitor=""val_loss""\n)\n\n# fit model\nhistory_1 = model_1.fit(train_data,\n  epochs=25,\n)\n']","['# Create EarlyStopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=5,\n   monitor=""val_loss""\n)\n\n# Fit model\nhistory_1 = model_1.fit((train_data,\n   epochs=25,\n   validation_data=test_data,\n   callbacks=[early_stopping])\n']"
19639,19664,0,"['# Create EarlyStopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=5,\n   monitor=""val_loss""\n)\n\n# Fit model\nhistory_1 = model_1.fit((train_data,\n   epochs=25,\n   validation_data=test_data,\n   callbacks=[early_stopping])\n']","['yer = tf.keras.input(shape=(224, 223, 3))\n_model(input_layer)\neras. layers.GlobalAveragePooling2D()(x)\nayer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\nact model\n= tf.keras.Model(input_layer, output_layer, name=""EfficientNetB0-V1"")\n']"
19664,19672,0,"['yer = tf.keras.input(shape=(224, 223, 3))\n_model(input_layer)\neras. layers.GlobalAveragePooling2D()(x)\nayer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\nact model\n= tf.keras.Model(input_layer, output_layer, name=""EfficientNetB0-V1"")\n']","['# Create EarlyStopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=5,\n   monitor=""val_loss""\n)\n\n# Fit model\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callhacks:[early_stapping])\n']"
19672,19682,0,"['# Create EarlyStopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=5,\n   monitor=""val_loss""\n)\n\n# Fit model\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callhacks:[early_stapping])\n']",['\n']
19682,19708,0,['\n'],"['base_model = tf.keras.applications.EfficientNetB@(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.Input(shape=(224, 224, 3))\nx = base_model(input_layer)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutput_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\n# Construct model \nmodel_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetBo-\n']"
19708,19733,0,"['base_model = tf.keras.applications.EfficientNetB@(include_top=False)\n\n# Make model untrainable\nbase_model.trainable = False\n\n# Build a functional model\ninput_layer = tf.keras.Input(shape=(224, 224, 3))\nx = base_model(input_layer)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutput_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\n# Construct model \nmodel_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetBo-\n']",['model_1.evaluate(test_data)\n']
19733,19735,1,['model_1.evaluate(test_data)\n'],['model_1.evaluate(test_data)\n']
19735,19961,0,['model_1.evaluate(test_data)\n'],"[""# Get helper_functions.py script from course GitHub\n!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learni\n\n# Impart helper functions we're going to use\nfrom helper_functions import create_tensorboard_callback, plot_loss_curve\n""]"
19961,19986,4,"[""# Get helper_functions.py script from course GitHub\n!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learni\n\n# Impart helper functions we're going to use\nfrom helper_functions import create_tensorboard_callback, plot_loss_curve\n""]","[""!pip install pydot\n!pip install wandb \n# Get helper_functions.py script from course GitHub\n!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learni\n\n# Import helper functions we're going to use\nfrom helper_functions import create_tensorboard_callback, plot_loss_curve\n""]"
19986,20105,0,"[""!pip install pydot\n!pip install wandb \n# Get helper_functions.py script from course GitHub\n!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learni\n\n# Import helper functions we're going to use\nfrom helper_functions import create_tensorboard_callback, plot_loss_curve\n""]","['   monitor=""val_loss"" \n}\n\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"")])\n']"
20105,20149,4,"['   monitor=""val_loss"" \n}\n\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"")])\n']","['# Fit model\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"", str(model_1.name))])\n']"
20149,20153,5,"['# Fit model\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"", str(model_1.name))])\n']","['model_1.name\n\n# Fit model\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n']"
20153,20156,5,"['model_1.name\n\n# Fit model\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n']","['str(model_1.name)\n\n# Fit model\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"", str(model_1.name))])\n']"
20156,20180,6,"['str(model_1.name)\n\n# Fit model\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"", str(model_1.name))])\n']","['# fit model\nhistory 1 = model_1,fit(train_data\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping\n      create_tensorboard_callback(""logs"", model_1.name)])\n\nmodel_1.evaluate(test_data)\n']"
20180,20257,0,"['# fit model\nhistory 1 = model_1,fit(train_data\n   epochs=50,\n   validation_data=test_data,\n   callbacks=[early_stopping\n      create_tensorboard_callback(""logs"", model_1.name)])\n\nmodel_1.evaluate(test_data)\n']","['import wandb\nwandb.tensorboard.patch(root_logdir:""logs/"")\nwandb.init(project=""100k-livestream-video"", sync_tensorboard=True)\n']"
20257,20273,2,"['import wandb\nwandb.tensorboard.patch(root_logdir:""logs/"")\nwandb.init(project=""100k-livestream-video"", sync_tensorboard=True)\n']","['import wandb\nwandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k-livestream-video"")\n']"
20273,20281,3,"['import wandb\nwandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k-livestream-video"")\n']","['import wandb\nwandb.tensorboard.patch(root_logdir=""logs"")\n# wandb.init(project=""100k-livestream-video"")\n']"
20281,20324,2,"['import wandb\nwandb.tensorboard.patch(root_logdir=""logs"")\n# wandb.init(project=""100k-livestream-video"")\n']","['import wandb\n# wandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k—livestream-video"", sync_tensorboard=True)\n']"
20324,20723,0,"['import wandb\n# wandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k—livestream-video"", sync_tensorboard=True)\n']","['# Create EarlyStopping callback and TensorBoard callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=5,\n   monitor=""val_loss""\n)\n\n# Fit model\nwandb.init(sync_tensorboard=True)\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data\n']"
20723,21163,0,"['# Create EarlyStopping callback and TensorBoard callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=5,\n   monitor=""val_loss""\n)\n\n# Fit model\nwandb.init(sync_tensorboard=True)\nhistory_1 = model_1.fit(train_data,\n   epochs=50,\n   validation_data=test_data\n']","['import wandb\nwandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k-livestream-video"")\n\nimport tensorflow as tf\ntf.get_logger().setLevel(\'INFO\')\n']"
21163,21239,0,"['import wandb\nwandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k-livestream-video"")\n\nimport tensorflow as tf\ntf.get_logger().setLevel(\'INFO\')\n']","['import os\nimage_files = []\n\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   image_files.append(files)\nlen(image_files)\n']"
21239,21274,4,"['import os\nimage_files = []\n\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   image_files.append(files)\nlen(image_files)\n']","['import os\nimage_files = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images""):\n   image_files.append(files)\nlen(image_files) \n\nimage_files\n']"
21274,21274,2,"['import os\nimage_files = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images""):\n   image_files.append(files)\nlen(image_files) \n\nimage_files\n']",['len(image_files)\r\nimage_files']
21274,21305,0,['len(image_files)\r\nimage_files'],"['list([""item_1"", ""item 2""]).items()\n']"
21305,21324,0,"['list([""item_1"", ""item 2""]).items()\n']","['import os\nimage_files = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):\n   image_files.append(file for file in files)\nlen(image_files)\n\nimage_files\n']"
21324,21407,5,"['import os\nimage_files = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):\n   image_files.append(file for file in files)\nlen(image_files)\n\nimage_files\n']","['import os\nimage_files = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):\n   for item in files:\n      image_files.append(files)|\nlen(image_files)\n\nimage_files\n']"
21407,21413,7,"['import os\nimage_files = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):\n   for item in files:\n      image_files.append(files)|\nlen(image_files)\n\nimage_files\n']","['import os\nimage_files = []\nfor dirs, m_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):\n   for item in files:\n      image_files.append(files)\nlen(image_files)\n\nimage_files\n']"
21413,21413,7,"['import os\nimage_files = []\nfor dirs, m_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):\n   for item in files:\n      image_files.append(files)\nlen(image_files)\n\nimage_files\n']","['import os\nimage_files = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):\n   for item in files:\n      image_files.append(item)\nlen(image_files)\n\nimage_files\n']"
21413,21428,2,"['import os\nimage_files = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):\n   for item in files:\n      image_files.append(item)\nlen(image_files)\n\nimage_files\n']",['import os\nimage_files = []\nima\n']
21428,21553,0,['import os\nimage_files = []\nima\n'],"['image_dirs = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\n   len(image_files) I\n\nimage_files[:5], sub_dirs[:5]\n']"
21553,21582,6,"['image_dirs = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\n   len(image_files) I\n\nimage_files[:5], sub_dirs[:5]\n']","['image_dirs = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   print(sub_dirs)\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\nlen(image_files)\n']"
21582,21596,6,"['image_dirs = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   print(sub_dirs)\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\nlen(image_files)\n']","['image_dirs = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   print(dirs)\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\nlen(image_files)\n']"
21596,21642,5,"['image_dirs = []\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   print(dirs)\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\nlen(image_files)\n']","['image_dirs = os.listdir(""data/imagenet_images/"")\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\nlen(image_files) \n']"
21642,21646,1,"['image_dirs = os.listdir(""data/imagenet_images/"")\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\nlen(image_files) \n']","['len(image_files)\n\nimage_files[:5], image_dirs[:5]\n']"
21646,21690,1,"['len(image_files)\n\nimage_files[:5], image_dirs[:5]\n']","['image_dirs = []\nfor dirs, dirs, files in os.walk(""data/imagenet_images/""):\n   print(sub_dirs)\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\nlen(image_files)\n\nimage_files[:5], dirs[:5]\n']"
21690,21690,0,"['image_dirs = []\nfor dirs, dirs, files in os.walk(""data/imagenet_images/""):\n   print(sub_dirs)\n   image_dirs.append(sub_dirs)\n   for item in files:\n      image_files.append(item)\nlen(image_files)\n\nimage_files[:5], dirs[:5]\n']",['len(image_dirs) \n']
21690,21729,1,['len(image_dirs) \n'],['len(image_dirs)\n\nimage_dirs\n']
21729,21858,0,['len(image_dirs)\n\nimage_dirs\n'],['!mkdir data/train\n\n!mkdir data/test\n']
21858,21964,0,['!mkdir data/train\n\n!mkdir data/test\n'],"['import os\n\nfor dirs, sub_dirs, files in os.walk(""data/model_test_images/""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n\nimport random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n']"
21964,21979,6,"['import os\n\nfor dirs, sub_dirs, files in os.walk(""data/model_test_images/""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n\nimport random\ndef create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n']","['import os\nfrom shutil import copy2\nimport random\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n']"
21979,21989,7,"['import os\nfrom shutil import copy2\nimport random\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n']","['import os\nfrom shutil import copy2\nimport random\n\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n']"
21989,22003,0,"['import os\nfrom shutil import copy2\nimport random\n\nfor dirs, sub_dirs, files in os.walk(""data/imagenet_images""):\n   print(dirs)\n   print(sub_dirs)\n   print(files)\n']","['def create_train_test_list(target_dir):\n   random. seed(42)\n   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']"
22003,22016,9,"['def create_train_test_list(target_dir):\n   random. seed(42)\n   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']","['def create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']"
22016,22021,0,"['def create_train_test_list(target_dir):\n   random.seed(42)\n   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n']","['      # Copy images\n      for image_path in img_path_list:\n         image_file_name = os.path.split(image_path)[-1]\n         dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n         print(f""Copying: {image_path} to {dest_path}"")\n         copy2(image_path, dest_path)\n\n# Create a function to move images\n\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   for split_dir in [""train"", ""test""]:\n      os.makedirs(os.path.ioin(target_dir, split_dir, image_dir), exist_ok=True)\n']"
22021,22024,0,"['      # Copy images\n      for image_path in img_path_list:\n         image_file_name = os.path.split(image_path)[-1]\n         dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n         print(f""Copying: {image_path} to {dest_path}"")\n         copy2(image_path, dest_path)\n\n# Create a function to move images\n\ndata_dir = ""data/model_test_images""\ntarget_dir = ""data/model_test_images_split""\nfor image_dir in os.listdir(data_dir):\n   for split_dir in [""train"", ""test""]:\n      os.makedirs(os.path.ioin(target_dir, split_dir, image_dir), exist_ok=True)\n']","['# Copy testing images\ncopy_images_to_file(img_path_list=test_image_list,\n   target_dir=target_dir,\n   train=False)\n']"
22024,22025,0,"['# Copy testing images\ncopy_images_to_file(img_path_list=test_image_list,\n   target_dir=target_dir,\n   train=False)\n']","['   train_image_List = random.sample(image_List, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n\ndef copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      split_dir = ""train""\n   else:\n      split_dir = ""test""\n\n   # Copy images\n']"
22025,22077,0,"['   train_image_List = random.sample(image_List, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")\nlen(train_image_list), len(test_image_list)\n\ndef copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      split_dir = ""train""\n   else:\n      split_dir = ""test""\n\n   # Copy images\n']",['df_food.class_name.tolist()\n']
22077,22077,0,['df_food.class_name.tolist()\n'],['df_food.clasnames|\n']
22077,22112,0,['df_food.clasnames|\n'],['food_list_filter = df_food.class_name.tolist()\nnon_food_list_filter = df_non_food.class_name.tolist()\n']
22112,22123,2,['food_list_filter = df_food.class_name.tolist()\nnon_food_list_filter = df_non_food.class_name.tolist()\n'],"['food_list_filter = df_food.class_name.tolist()\nnon_food_list_filter = df_non_food.class_name.tolist()\n\n\nfood_list_filter[:5], non_food_list_filter[:5]\n']"
22123,22123,3,"['food_list_filter = df_food.class_name.tolist()\nnon_food_list_filter = df_non_food.class_name.tolist()\n\n\nfood_list_filter[:5], non_food_list_filter[:5]\n']","['food_list_filter = df_food.class_name.tolist()\nnon_food_list_filter = df_non_food.class_name.tolist()\n\nfood_list_filter[:5], non_food_list_filter[:5]\n']"
22123,22192,0,"['food_list_filter = df_food.class_name.tolist()\nnon_food_list_filter = df_non_food.class_name.tolist()\n\nfood_list_filter[:5], non_food_list_filter[:5]\n']","['# Move food images to food_images folder\nimagenet_downloaded_image_folders = os.listdir(""data/imagenet_images/"")\nimagenet_downloaded_image_folders\n']"
22192,22192,3,"['# Move food images to food_images folder\nimagenet_downloaded_image_folders = os.listdir(""data/imagenet_images/"")\nimagenet_downloaded_image_folders\n']","['# Move food images to food_images folder\nimagenet_downloaded_image_folders = os.listdir(""data/imagenet_images/"")\nimagenet_downloaded_image_folders\n']"
22192,22215,2,"['# Move food images to food_images folder\nimagenet_downloaded_image_folders = os.listdir(""data/imagenet_images/"")\nimagenet_downloaded_image_folders\n']","['# Move food images to food_images folder\nimagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]\nimagenet_downloaded_image_folders\n']"
22215,22220,3,"['# Move food images to food_images folder\nimagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]\nimagenet_downloaded_image_folders\n']","['# Move food images to food_images folder\nimagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]\nimagenet_downloaded_image_folders[:10]\n']"
22220,22228,3,"['# Move food images to food_images folder\nimagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]\nimagenet_downloaded_image_folders[:10]\n']","['# Move food images to food_images folder\nimagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]\nimagenet_downloaded_image_folders[:5]\n']"
22228,22246,2,"['# Move food images to food_images folder\nimagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]\nimagenet_downloaded_image_folders[:5]\n']","['# Get list of downloaded ImageNet class folder names\nimagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]\nimagenet_downloaded_image_folders[:5]\n']"
22246,22673,0,"['# Get list of downloaded ImageNet class folder names\nimagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]\nimagenet_downloaded_image_folders[:5]\n']","['from shutil import copy2\nstart_dir = ""imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in imagenet_downloaded_image_folders:\n   if image_folder in food_list_filter:\n   # Make new target dir\n   dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   start_dir = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(start_dir)\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split()[-1]\n      start_path = os.path.join(start_dir, image_filename)\n      dest_path = os.path.join(dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      # copy2(image_to_copy)\n']"
22673,22764,16,"['from shutil import copy2\nstart_dir = ""imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in imagenet_downloaded_image_folders:\n   if image_folder in food_list_filter:\n   # Make new target dir\n   dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   start_dir = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(start_dir)\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split()[-1]\n      start_path = os.path.join(start_dir, image_filename)\n      dest_path = os.path.join(dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      # copy2(image_to_copy)\n']","['from shutil import copy2\nstart_dir = ""data/limagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in imagenet_downloaded_image_folders:\n   if image_folder in food_list_filter:\n   #Make new target dir\n   dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   start_dir = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(start_dir)\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split()[-1]\n      start_path = os.path.join(start_dir, image_filename)\n      dest_path = os.path.join(dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      # copy2(image_to_copy)\n']"
22764,22839,10,"['from shutil import copy2\nstart_dir = ""data/limagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in imagenet_downloaded_image_folders:\n   if image_folder in food_list_filter:\n   #Make new target dir\n   dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   start_dir = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(start_dir)\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split()[-1]\n      start_path = os.path.join(start_dir, image_filename)\n      dest_path = os.path.join(dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      # copy2(image_to_copy)\n']","['# Move food images from ImageNet downloaded folders to data/food_images\nfrom shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   if image_folder in food_list_filter:\n   # Make new target dir\n   dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   start_dir = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(start_dir)\n   for image_to_copy in images_to_copy:\n']"
22839,22842,10,"['# Move food images from ImageNet downloaded folders to data/food_images\nfrom shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   if image_folder in food_list_filter:\n   # Make new target dir\n   dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   start_dir = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(start_dir)\n   for image_to_copy in images_to_copy:\n']","['# Move food images from ImageNet downloaded folders to data/food_images\nfrom shutil import copy2\nstart_dir = ""data/imagenet \ndest_dir = ""data/food_imag\nfor image_folder in os.lis\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n\n      start_dir = os.path.join(start_dir, image_folder)\n      images_to_copy = os.listdir(start_dir)\n      for image_to_copy in images_to_copy:\n']"
22842,22976,10,"['# Move food images from ImageNet downloaded folders to data/food_images\nfrom shutil import copy2\nstart_dir = ""data/imagenet \ndest_dir = ""data/food_imag\nfor image_folder in os.lis\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n\n      start_dir = os.path.join(start_dir, image_folder)\n      images_to_copy = os.listdir(start_dir)\n      for image_to_copy in images_to_copy:\n']","['# Move food images from ImageNet downloaded folders to data/food_im\nfrom shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter: \n      # Make new target dir\n      dest_dir = os.path.join(dest_dir, image_ \n      os.makedirs(dest_dir, exist_ok=True) \n\n      start_dir = os.path.join(start_dir, imag\n      images_to_copy = os.listdir(start_dir) \n\n      for image_to_copy in images_to_copy: \n         image_filename = image_to_copy.split.\n         start_path = os.path.join(start_dir, image_filename)\n         dest path = os.path.join(dest_dir, image_filename)\n']"
22976,23038,12,"['# Move food images from ImageNet downloaded folders to data/food_im\nfrom shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter: \n      # Make new target dir\n      dest_dir = os.path.join(dest_dir, image_ \n      os.makedirs(dest_dir, exist_ok=True) \n\n      start_dir = os.path.join(start_dir, imag\n      images_to_copy = os.listdir(start_dir) \n\n      for image_to_copy in images_to_copy: \n         image_filename = image_to_copy.split.\n         start_path = os.path.join(start_dir, image_filename)\n         dest path = os.path.join(dest_dir, image_filename)\n']","['for image_folder in os.listdir(start_dir):\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n\n      start_dir = os.path.join(start_dir, image_folder)\n      images_to_copy = os.listdir(start_dir)\n\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split()[-1]\n      start_path = os.path.join(start_dir, image_filename)\n      dest_path = os.path.join(dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      #- copy2(image_to_copy)\n']"
23038,23093,11,"['for image_folder in os.listdir(start_dir):\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n\n      start_dir = os.path.join(start_dir, image_folder)\n      images_to_copy = os.listdir(start_dir)\n\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split()[-1]\n      start_path = os.path.join(start_dir, image_filename)\n      dest_path = os.path.join(dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      #- copy2(image_to_copy)\n']","['for image_folder in os.listdir(start_dir):\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n\n      target_image_folder = os.path.join(start_dir, image_folder)\n      images_to_copy = os.listdir(target_image_folder)\n\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split()[-1]\n      start_path = os.path.join(target,image_folder, image_filename)\n      dest_path = os.path.join(new_dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      # copy2(image_to_copy)\n']"
23093,23163,13,"['for image_folder in os.listdir(start_dir):\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n\n      target_image_folder = os.path.join(start_dir, image_folder)\n      images_to_copy = os.listdir(target_image_folder)\n\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split()[-1]\n      start_path = os.path.join(target,image_folder, image_filename)\n      dest_path = os.path.join(new_dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      # copy2(image_to_copy)\n']","['print(f""image folderr: .... {image_folder}..."")\nif image_folder.lower() in food_list_filter:\n   # Make new target dir\n   new_dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   target_image_folder = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(target_image_folder)\nelse:\n   pass\n\nif target_image_folder:\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split() [-1]\n      start_path = os.path.join(target_image_folder, image_filename)\n      dest_path = os.path.join(new_dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      # copy2(image_to_copy)\n']"
23163,23238,8,"['print(f""image folderr: .... {image_folder}..."")\nif image_folder.lower() in food_list_filter:\n   # Make new target dir\n   new_dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   target_image_folder = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(target_image_folder)\nelse:\n   pass\n\nif target_image_folder:\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split() [-1]\n      start_path = os.path.join(target_image_folder, image_filename)\n      dest_path = os.path.join(new_dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      # copy2(image_to_copy)\n']","['   # Make new target dir\n   new_dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   target_image_folder = os.path.join(start_dir, image_folder)\n   print(target_image_folder)\n   images_to_copy = os.list\nelse:\n   pass \n\nif target_image_folder: [\n   for image_to_copy in imag \n      image_filename = imag \n      start_path = os.path. \n      dest_path = os.path.\n      print(f""Copying: (sta\n      # copy2(image_to_copy)\n']"
23238,23262,7,"['   # Make new target dir\n   new_dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   target_image_folder = os.path.join(start_dir, image_folder)\n   print(target_image_folder)\n   images_to_copy = os.list\nelse:\n   pass \n\nif target_image_folder: [\n   for image_to_copy in imag \n      image_filename = imag \n      start_path = os.path. \n      dest_path = os.path.\n      print(f""Copying: (sta\n      # copy2(image_to_copy)\n']","['from shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n\n      target_image_folder = os.path.join(start_dir, image_folder)\n      images_to_copy = os.listdir(target_image_folder)\n   else:\n      pass\n\nif target_image_folder:\n   for image_to_copy in images_to_copy:\n']"
23262,23337,6,"['from shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n\n      target_image_folder = os.path.join(start_dir, image_folder)\n      images_to_copy = os.listdir(target_image_folder)\n   else:\n      pass\n\nif target_image_folder:\n   for image_to_copy in images_to_copy:\n']","['   target_image_folder = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(target_image_folder)\nelse:\n   pass\n\nif target_image_folder:\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split() [-1]\n      start_path = os.path.join(target_image_folder, image_filename)\n      dest_path = os.path.join(new_dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      copy2(start_path, dest_path)\n']"
23337,23451,5,"['   target_image_folder = os.path.join(start_dir, image_folder)\n   images_to_copy = os.listdir(target_image_folder)\nelse:\n   pass\n\nif target_image_folder:\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split() [-1]\n      start_path = os.path.join(target_image_folder, image_filename)\n      dest_path = os.path.join(new_dest_dir, image_filename)\n      print(f""Copying: {start_path} to {dest_path}..."")\n      copy2(start_path, dest_path)\n']","['from shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir): \n   target_image_folder = None \n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter: \n      # Make new target dir \n      new_dest_dir = os.path.join(dest_dir, image_folder) \n      os.makedirs(dest_dir, exist_ok=True) \n\n      target_image_folder = os.path.join(start_dir, image f\n      print(f""Target image folder: {target_image folder}..."")\n      images_to_copy = os.listdir(target_image_folder)\n   else:\n      pass\n\n   if target_image_folder:\n']"
23451,23556,12,"['from shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir): \n   target_image_folder = None \n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter: \n      # Make new target dir \n      new_dest_dir = os.path.join(dest_dir, image_folder) \n      os.makedirs(dest_dir, exist_ok=True) \n\n      target_image_folder = os.path.join(start_dir, image f\n      print(f""Target image folder: {target_image folder}..."")\n      images_to_copy = os.listdir(target_image_folder)\n   else:\n      pass\n\n   if target_image_folder:\n']","['target_image_folder = None\nprint(f""Image folder: .... {image_folder}..."")\nif image_folder.lower() in food_list_filter:\n   # Make new target dir\n   new_dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   target_image_folder = os.path.join(start_dir, image_folder)\nelse:\n   pass\n\nif target_image_folder:\n   print{{f""Target image folder: {target_image_folder}..."")|\n   images_to_copy = os.listdir(target_image_folder)\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split() [-1]\n      start_path = os.path.join(target_image_folder, image_filename)\n      dest path = os.path.join(new_dest_dir, image_filename)\n']"
23556,23688,9,"['target_image_folder = None\nprint(f""Image folder: .... {image_folder}..."")\nif image_folder.lower() in food_list_filter:\n   # Make new target dir\n   new_dest_dir = os.path.join(dest_dir, image_folder)\n   os.makedirs(dest_dir, exist_ok=True)\n\n   target_image_folder = os.path.join(start_dir, image_folder)\nelse:\n   pass\n\nif target_image_folder:\n   print{{f""Target image folder: {target_image_folder}..."")|\n   images_to_copy = os.listdir(target_image_folder)\n   for image_to_copy in images_to_copy:\n      image_filename = image_to_copy.split() [-1]\n      start_path = os.path.join(target_image_folder, image_filename)\n      dest path = os.path.join(new_dest_dir, image_filename)\n']","['# Move food images from ImageNet downloaded folders to data/food_images\nfrom shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n      print{(new_dest_dir)\n\n      # Images to copy\n      target_image_folder = os.path.join(start_dir, image_folder)\n   else:\n      pass\n']"
23688,23715,15,"['# Move food images from ImageNet downloaded folders to data/food_images\nfrom shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(dest_dir, exist_ok=True)\n      print{(new_dest_dir)\n\n      # Images to copy\n      target_image_folder = os.path.join(start_dir, image_folder)\n   else:\n      pass\n']","['from shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(new_dest_dir, exist_ok=True)\n      print(new_dest_dir)\n\n      # Images to copy\n      target_image_folder = os.path.join(start_dir, image_folder)\n   else:\n      pass\n\n   if target_image_folder:\n']"
23715,23735,13,"['from shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images""\nfor image_folder in os.listdir(start_dir):\n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      os.makedirs(new_dest_dir, exist_ok=True)\n      print(new_dest_dir)\n\n      # Images to copy\n      target_image_folder = os.path.join(start_dir, image_folder)\n   else:\n      pass\n\n   if target_image_folder:\n']","['from shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images"" \nfor image_folder in os.listdir(start_dir): \n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}... \n   if image_folder.lower() in food_list_filter: \n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, im\n      print(f""Making folder: {new_dest_dir}..."")\n      os.makedirs(new_dest_dir, exist_ok=True)\n\n\n      # Images to copy\n      target_image_folder = os.path.join(start_dir, image_folder)\n   else:\n      pass\n']"
23735,23740,0,"['from shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/food_images"" \nfor image_folder in os.listdir(start_dir): \n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}... \n   if image_folder.lower() in food_list_filter: \n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, im\n      print(f""Making folder: {new_dest_dir}..."")\n      os.makedirs(new_dest_dir, exist_ok=True)\n\n\n      # Images to copy\n      target_image_folder = os.path.join(start_dir, image_folder)\n   else:\n      pass\n']","['for image_to_copy in images_to_copy:\n   image_filename = image_to_copy.split()[-1]\n   start_path = os.path.join(target_image_folder, image_filename)\n   dest_path = os.path.join(new_dest_dir, image_filename)\n   print(f""Copying: {start_path} to {dest_path}..."")\n   # copy2(start_path, dest_path)\n']"
23740,23866,0,"['for image_to_copy in images_to_copy:\n   image_filename = image_to_copy.split()[-1]\n   start_path = os.path.join(target_image_folder, image_filename)\n   dest_path = os.path.join(new_dest_dir, image_filename)\n   print(f""Copying: {start_path} to {dest_path}..."")\n   # copy2(start_path, dest_path)\n']","['# Move food images from ImageNet downloaded folders to data/food_images\nfrom shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/non_food_images""\nfor image_folder in os.listdir(start_dir):\n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in non_food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      print(f""Making folder: {new_dest_dir}..."")\n      os.makedirs(new_dest_dir, exist_ok=True)\n']"
23866,24279,0,"['# Move food images from ImageNet downloaded folders to data/food_images\nfrom shutil import copy2\nstart_dir = ""data/imagenet_images""\ndest_dir = ""data/non_food_images""\nfor image_folder in os.listdir(start_dir):\n   target_image_folder = None\n   print(f""Image folder: .... {image_folder}..."")\n   if image_folder.lower() in non_food_list_filter:\n      # Make new target dir\n      new_dest_dir = os.path.join(dest_dir, image_folder)\n      print(f""Making folder: {new_dest_dir}..."")\n      os.makedirs(new_dest_dir, exist_ok=True)\n']","['# Extract food_images files and move to train/food_images\n# Do the same with test & non_food_images\nfood_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/food_images/""):\n   food_image_filepaths.append(files)\nfood_images_filepaths\n']"
24279,24347,5,"['# Extract food_images files and move to train/food_images\n# Do the same with test & non_food_images\nfood_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/food_images/""):\n   food_image_filepaths.append(files)\nfood_images_filepaths\n']","['# Extract food_images files and move to train/food_images\n# Do the same with test & non_food_images\nfood_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/food_images/""):\n   food_image_filepaths.append(os.path,join(dir, files))\nfood_image_filepaths\n']"
24347,24368,5,"['# Extract food_images files and move to train/food_images\n# Do the same with test & non_food_images\nfood_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/food_images/""):\n   food_image_filepaths.append(os.path,join(dir, files))\nfood_image_filepaths\n']","['# Do the same with test & non_food_images\nfood_image_filepaths = []\nfor dir, sub_dir, files in os.walk(\'""data/food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\nfood_image_filepaths\n']"
24368,24379,4,"['# Do the same with test & non_food_images\nfood_image_filepaths = []\nfor dir, sub_dir, files in os.walk(\'""data/food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\nfood_image_filepaths\n']","['food_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\nlen(food_image_filepaths)\n']"
24379,24483,0,"['food_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\nlen(food_image_filepaths)\n']","['def create_train_test_list(image_list):\n   random.seed(42)\n   # image_list = (os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 % len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(food_image_filepaths)\nlen(train_image_list), len(test_image_list)\n']"
24483,24564,0,"['def create_train_test_list(image_list):\n   random.seed(42)\n   # image_list = (os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 % len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n\ntrain_image_list, test_image_list = create_train_test_list(food_image_filepaths)\nlen(train_image_list), len(test_image_list)\n']","['# Extract food_images files and move to train/food_images\n# Do the same with test & non_food_images\nfood_image_filepaths = [1\nfor dir, sub_dir, files in os.walk(""data/food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\n\nnon_food_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/non_food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\nfood_image_filepaths[:5] \n']"
24564,24577,7,"['# Extract food_images files and move to train/food_images\n# Do the same with test & non_food_images\nfood_image_filepaths = [1\nfor dir, sub_dir, files in os.walk(""data/food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\n\nnon_food_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/non_food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\nfood_image_filepaths[:5] \n']","['non_food_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/non_food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\nfood_image_filepaths[:5], non_food_image_filepaths[:5]\n']"
24577,24592,5,"['non_food_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/non_food_images/""):\n   for file in files:\n      food_image_filepaths.append(os.path.join(dir, file))\nfood_image_filepaths[:5], non_food_image_filepaths[:5]\n']","['non_food_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/non_food_images/""):\n   for file in files:\n      non_food_image_filepaths.append(os.path.join(dir, file))\nfood_image_filepaths[:5], non_food_image_filepaths[:5]\n\ndef create_train_test_list(image_list):\n   random.seed(42)\n   # image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n']"
24592,24650,0,"['non_food_image_filepaths = []\nfor dir, sub_dir, files in os.walk(""data/non_food_images/""):\n   for file in files:\n      non_food_image_filepaths.append(os.path.join(dir, file))\nfood_image_filepaths[:5], non_food_image_filepaths[:5]\n\ndef create_train_test_list(image_list):\n   random.seed(42)\n   # image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list)))\n   return train_image_list, test_image_list\n']","['# Move to train and test\ndef copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      split_dir = ""train""\n   else:\n      split_dir = ""test""\n\n   # Copy images\n   for image_path in img_path_list:\n      image_file_name = os.path.split(image_path)[-1]\n      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n']"
24650,24846,7,"['# Move to train and test\ndef copy_images_to_file(img_path_list, target_dir, train=True):\n   if train:\n      split_dir = ""train""\n   else:\n      split_dir = ""test""\n\n   # Copy images\n   for image_path in img_path_list:\n      image_file_name = os.path.split(image_path)[-1]\n      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n']","['# Move to train and test\ndef copy_images_to_file(img_path_list, split_dir):\n   # Copy images\n   for image_path in img_path_list:\n      image_file_name = os.path.split(image_path)[-1]\n      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\nfor split_dir in [""train"", ""test""]:\n   for image_path_list in [food_image_filepaths, non_food_image_filepaths]:\n      train_images, test_images = create_train_test_list(image_path_list)\n\ncopy_images_to_file(train_images, )\n']"
24846,25170,2,"['# Move to train and test\ndef copy_images_to_file(img_path_list, split_dir):\n   # Copy images\n   for image_path in img_path_list:\n      image_file_name = os.path.split(image_path)[-1]\n      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)\n      print(f""Copying: {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\nfor split_dir in [""train"", ""test""]:\n   for image_path_list in [food_image_filepaths, non_food_image_filepaths]:\n      train_images, test_images = create_train_test_list(image_path_list)\n\ncopy_images_to_file(train_images, )\n']","['train_images, test_images = create_train_test_list(food_image_filepaths)\n\n# Training images\ntarget_dir = ""data/train/food_images/""\nfor image_path in train_images:\n   image_filename = image_path.split()[-1]\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   # copy2(image_path, )\n']"
25170,25211,4,"['train_images, test_images = create_train_test_list(food_image_filepaths)\n\n# Training images\ntarget_dir = ""data/train/food_images/""\nfor image_path in train_images:\n   image_filename = image_path.split()[-1]\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   # copy2(image_path, )\n']","['train_images, test_image \n\n# Training images \ntarget_dir = ""data/train \nfor image_path in train_\n   image_filename = ima\n   print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   # copy2(image_path, )\n']"
25211,25234,4,"['train_images, test_image \n\n# Training images \ntarget_dir = ""data/train \nfor image_path in train_\n   image_filename = ima\n   print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   # copy2(image_path, )\n']","['target_dir = ""data/train/food_images/""\nfor image_path in trajn_images:\n   image_filename = os.path.split(image_path)[-1]\n   print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f“Copying {image_path} to {dest_path}"")\n   # copy2(image_path, )\n']"
25234,25272,7,"['target_dir = ""data/train/food_images/""\nfor image_path in trajn_images:\n   image_filename = os.path.split(image_path)[-1]\n   print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f“Copying {image_path} to {dest_path}"")\n   # copy2(image_path, )\n']","['# Training images\ntarget_dir = ""data/train/food_images/""\nfor image_path in train_images:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   # copy2(image_path, )\n\n# Test images\ntarget_dir = ""data/test/food_images/""\nfor image_path in test_images:\n   image_filename = os.path.split(image_path) [-1]\n   # print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {imagp_path} to {dest_path}"")\n   # copy2(image_path, )\n']"
25272,25297,13,"['# Training images\ntarget_dir = ""data/train/food_images/""\nfor image_path in train_images:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   # copy2(image_path, )\n\n# Test images\ntarget_dir = ""data/test/food_images/""\nfor image_path in test_images:\n   image_filename = os.path.split(image_path) [-1]\n   # print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {imagp_path} to {dest_path}"")\n   # copy2(image_path, )\n']","['for image_path in train_images:\n   image_filename = os.path.split(image_path)[-1]\n   # print(inage_filenane)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n\n# Test images\ntarget_dir = ""data/test/food_images/""\nfor image_path in test_images:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filenane)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n']"
25297,25343,12,"['for image_path in train_images:\n   image_filename = os.path.split(image_path)[-1]\n   # print(inage_filenane)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n\n# Test images\ntarget_dir = ""data/test/food_images/""\nfor image_path in test_images:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filenane)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n']","['# Training images\ntarget_dir = ""data/train/food_images/""\nos.makedirs(target_dir, exist_ok=True)\nfor image_path in train_images: \n   image_filename = os.path.split(im\n   # print(image_filename) \n   dest_path = os.path.join(target_d \n   print(f""Copying {image_path} to { \n   copy2(image_path, dest_path) \n\n# Test images\ntarget_dir = ""data/test/food_images/""\nos.makedirs(target_dir, exist_ok=True)\nfor image_path in test_images:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filename)\n   dest path = os.path.join(target_dir, image_filename)\n']"
25343,25520,9,"['# Training images\ntarget_dir = ""data/train/food_images/""\nos.makedirs(target_dir, exist_ok=True)\nfor image_path in train_images: \n   image_filename = os.path.split(im\n   # print(image_filename) \n   dest_path = os.path.join(target_d \n   print(f""Copying {image_path} to { \n   copy2(image_path, dest_path) \n\n# Test images\ntarget_dir = ""data/test/food_images/""\nos.makedirs(target_dir, exist_ok=True)\nfor image_path in test_images:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filename)\n   dest path = os.path.join(target_dir, image_filename)\n']","['train_images, test_images = create_train_test_list(food_image_filepaths)\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_lmages/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest path}"")\n   copy2(image_path, dest_path)\n\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/""):\ncopy_images_to_file(image_list=train_images, target_dir=“data/train/foodimages/""):\n']"
25520,25523,13,"['train_images, test_images = create_train_test_list(food_image_filepaths)\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_lmages/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f""Copying {image_path} to {dest path}"")\n   copy2(image_path, dest_path)\n\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/""):\ncopy_images_to_file(image_list=train_images, target_dir=“data/train/foodimages/""):\n']","['train_images, test_images = create_train_test_list(food_image_filepaths)\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image filename\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/""):\ncopy_images_to_file(image_list=test_images, target_dir=""data/train/food_images/""):\n']"
25523,25542,9,"['train_images, test_images = create_train_test_list(food_image_filepaths)\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image filename\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/""):\ncopy_images_to_file(image_list=test_images, target_dir=""data/train/food_images/""):\n']","['os.makedirs(target_dir, exist_ok=True)\nfor image_path in image_list:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f“Copying {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/"")\ncopy_images_to_file(image_list=test_images, target_dir=""data/test/food_images/"")\n']"
25542,25610,9,"['os.makedirs(target_dir, exist_ok=True)\nfor image_path in image_list:\n   image_filename = os.path.split(image_path)[-1]\n   # print(image_filename)\n   dest_path = os.path.join(target_dir, image_filename)\n   print(f“Copying {image_path} to {dest_path}"")\n   copy2(image_path, dest_path)\n\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/"")\ncopy_images_to_file(image_list=test_images, target_dir=""data/test/food_images/"")\n']","['train_images, test_images = create_train_test_list(food_image_filepaths)\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\nprint(test_images)\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/"")\ncopy_images_to_file(image_list=test_images, target_dir=""data/test/food_images/""|)\n']"
25610,25739,3,"['train_images, test_images = create_train_test_list(food_image_filepaths)\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\nprint(test_images)\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/"")\ncopy_images_to_file(image_list=test_images, target_dir=""data/test/food_images/""|)\n']","['train_images, test_images = create_train_test_list(non_food_image_filepaths)\n\ncopy_images_to_file(image_list=train_images, target dir=""data/train/non_food_images/"")\ncopy_images_to_file(image_list=test_images, target_dir=""data/test/non_food_images/"")\n']"
25739,25899,0,"['train_images, test_images = create_train_test_list(non_food_image_filepaths)\n\ncopy_images_to_file(image_list=train_images, target dir=""data/train/non_food_images/"")\ncopy_images_to_file(image_list=test_images, target_dir=""data/test/non_food_images/"")\n']","['train_dir = ""data/train""\ntest_dir = ""data/test""\ntrain_dir, test_dir\n\n# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest data = tf.keras.preprocessing.image dataset from directory(test dir,\n']"
25899,26113,0,"['train_dir = ""data/train""\ntest_dir = ""data/test""\ntrain_dir, test_dir\n\n# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest data = tf.keras.preprocessing.image dataset from directory(test dir,\n']","['input_layer = tf.keras.Input(shape=(224, 224, 3))\nx = base_model(input_layer)\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\noutput_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetB0-V1"")\n']"
26113,26611,0,"['input_layer = tf.keras.Input(shape=(224, 224, 3))\nx = base_model(input_layer)\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\noutput_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\n# Construct model\nmodel_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetB0-V1"")\n']","['len(os.listdir(""data/train/food_images/""))\n']"
26611,26680,0,"['len(os.listdir(""data/train/food_images/""))\n']","['model_1.save(""food_not_food_model_v0"")\n']"
26680,26728,0,"['model_1.save(""food_not_food_model_v0"")\n']","[""# Convert the model\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\ntflite_model = converter.convert()\n\n# Save the model\nwith open('model.tflite', 'wb') as f:\n   f.write(tflite_model)\n""]"
26728,26764,6,"[""# Convert the model\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\ntflite_model = converter.convert()\n\n# Save the model\nwith open('model.tflite', 'wb') as f:\n   f.write(tflite_model)\n""]","[""# Convert the model\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model dir) #\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:I\n   f.write(tflite_model)\n""]"
26764,26768,4,"[""# Convert the model\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model dir) #\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:I\n   f.write(tflite_model)\n""]","['# Convert the model\nsave_model_dir = ""food_not_food_model_v0""\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved model dir) # path to the SavedModel directory\ntflite_model = converter.convert()\n\n# Save the model.\nwith open(\'food_not_food_model_v0.tflite\', \'wb\') as f:\n   f.write(tflite_model)\n']"
26768,26771,6,"['# Convert the model\nsave_model_dir = ""food_not_food_model_v0""\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved model dir) # path to the SavedModel directory\ntflite_model = converter.convert()\n\n# Save the model.\nwith open(\'food_not_food_model_v0.tflite\', \'wb\') as f:\n   f.write(tflite_model)\n']","['(variable) saved_model_dir: Literal(\'food_not_food_model_v0\')\nsaved_model_dir = ""food_not_food_model_v0""\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory\ntflite_model = converter.convert()\n\n# Save the model.\nwith open(\'food_not_food_model_v0.tflite\', \'wb\') as f:\n   f.write(tflite_model)\n']"
26771,26880,0,"['(variable) saved_model_dir: Literal(\'food_not_food_model_v0\')\nsaved_model_dir = ""food_not_food_model_v0""\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory\ntflite_model = converter.convert()\n\n# Save the model.\nwith open(\'food_not_food_model_v0.tflite\', \'wb\') as f:\n   f.write(tflite_model)\n']","['export const classes = {\n   1: ""food"",\n   2: ""not_food""\n};\n']"
26880,26891,0,"['export const classes = {\n   1: ""food"",\n   2: ""not_food""\n};\n']",['train_data.class_names\n']
26891,26998,0,['train_data.class_names\n'],"['# Make model untrainable\n\nbase_model.trainable = False\n\n# Build a functional model\n\ninput_layer = tf.keras.Input(shape=(224, 224, 3))\n\nx = base_model(input_layer)\n\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\n\noutput_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\n# Construct model\n\nmodel_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetBO-v1"")\n¢ AL i\n\ntf.keras.utils.plot_model(model_1, show_shapes=True)\n']"
26998,27068,0,"['# Make model untrainable\n\nbase_model.trainable = False\n\n# Build a functional model\n\ninput_layer = tf.keras.Input(shape=(224, 224, 3))\n\nx = base_model(input_layer)\n\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\n\noutput_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)\n\n# Construct model\n\nmodel_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetBO-v1"")\n¢ AL i\n\ntf.keras.utils.plot_model(model_1, show_shapes=True)\n']","[""# See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sun of the weights of all exaples stays the same.\nweight_for_0 = (1 / neg) * (total / 2.0)\nweight_for_1 = (1 / pos) * (total / 2.9)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint{'Weight for class 1: {:.2f}'.format(weight_for_1))\n""]"
27068,27156,0,"[""# See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sun of the weights of all exaples stays the same.\nweight_for_0 = (1 / neg) * (total / 2.0)\nweight_for_1 = (1 / pos) * (total / 2.9)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint{'Weight for class 1: {:.2f}'.format(weight_for_1))\n""]","['total_samples = len(os.listdir(train_dir))\nnum_food_samples = len(os.listdir(train_dir + ""food_images""))\nnum_non_food_samples = len(os.listdir(train_dir + ""non_food_images""))\ntotal_samples, num_food_samples, num_non_food_samples\n']"
27156,27176,4,"['total_samples = len(os.listdir(train_dir))\nnum_food_samples = len(os.listdir(train_dir + ""food_images""))\nnum_non_food_samples = len(os.listdir(train_dir + ""non_food_images""))\ntotal_samples, num_food_samples, num_non_food_samples\n']","['test_dir = ""data/test""\ntrain_dir, test_dir\n\ntotal_samples = len(os.listdir(train_dir))\nnum_food_samples = len(os.listdir(os.path.join(train_dir + ""food_images"")))\nnum_non_food_samples = len(os.listdir(os.path.join(train_dir + ""non_food_images"")))\ntotal_samples, num_food_samples, num_non_food_samples\n']"
27176,27176,6,"['test_dir = ""data/test""\ntrain_dir, test_dir\n\ntotal_samples = len(os.listdir(train_dir))\nnum_food_samples = len(os.listdir(os.path.join(train_dir + ""food_images"")))\nnum_non_food_samples = len(os.listdir(os.path.join(train_dir + ""non_food_images"")))\ntotal_samples, num_food_samples, num_non_food_samples\n']","['test_dir = ""data/test""\ntrain_dir, test_dir\n\ntotal_samples = len(os.listdir(train_dir))\nnum_food_samples = len(os.listdir(os.path.join(train_dir + ""food_images"")))\nnum_non_food_samples = len(os.listdir(os.path.join(train_dir + ""non_food_images"")))\ntotal_samples, num_food_samples, num_non_food_samples\n']"
27176,27186,6,"['test_dir = ""data/test""\ntrain_dir, test_dir\n\ntotal_samples = len(os.listdir(train_dir))\nnum_food_samples = len(os.listdir(os.path.join(train_dir + ""food_images"")))\nnum_non_food_samples = len(os.listdir(os.path.join(train_dir + ""non_food_images"")))\ntotal_samples, num_food_samples, num_non_food_samples\n']","['test_dir = ""data/test""\ntrain_dir, test_dir\n\ntotal_samples = len(os.listdir(train_dir))\nnum_food_samples = len(os.listdir(os.path.join(train_dir, ""food_images"")))\nnum_non_food_samples = len(os.listdir(os.path.join(train_dir, ""non_food_images"")))\ntotal_samples, num_food_samples, num_non_food_samples \n\n# See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_0 = (1 / neg) * (total / 2.0)\nweight_for_1 = (1 / pos) * (total / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(""weight for class 0: {:.2f}"".format(weight_for_0))\n']"
27186,27223,0,"['test_dir = ""data/test""\ntrain_dir, test_dir\n\ntotal_samples = len(os.listdir(train_dir))\nnum_food_samples = len(os.listdir(os.path.join(train_dir, ""food_images"")))\nnum_non_food_samples = len(os.listdir(os.path.join(train_dir, ""non_food_images"")))\ntotal_samples, num_food_samples, num_non_food_samples \n\n# See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_0 = (1 / neg) * (total / 2.0)\nweight_for_1 = (1 / pos) * (total / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(""weight for class 0: {:.2f}"".format(weight_for_0))\n']","['# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n']"
27223,27231,0,"['# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n']","[""# See: https://wa. tensorflow.org/tutorials/structured data/inbalanced data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sun of the weights of all examples stays the same.\nweight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)\nweight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1} \n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\n""]"
27231,27248,8,"[""# See: https://wa. tensorflow.org/tutorials/structured data/inbalanced data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sun of the weights of all examples stays the same.\nweight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)\nweight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1} \n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\n""]","[""# Since we have a data imabalance let's get class weights\n\n# See: https://waw.tensorflow.org/tutorials/structured data/inbalanced data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\n\nweight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)\nweight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\n""]"
27248,27248,9,"[""# Since we have a data imabalance let's get class weights\n\n# See: https://waw.tensorflow.org/tutorials/structured data/inbalanced data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\n\nweight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)\nweight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\n""]","[""# Since we have a data imabalance let's get class weights\n\n# See: https://waw.tensorflow.org/tutorials/structured data/inbalanced data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)\nweight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\n""]"
27248,27318,1,"[""# Since we have a data imabalance let's get class weights\n\n# See: https://waw.tensorflow.org/tutorials/structured data/inbalanced data\n# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)\nweight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\n""]","[""class_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {weight_for_0}')\nprint('Weight for class 1: {weight_for_1}')\n\n# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest data = tf.keras.preprocessing.image dataset from directory(test_dir,\n""]"
27318,27324,9,"[""class_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {weight_for_0}')\nprint('Weight for class 1: {weight_for_1}')\n\n# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest data = tf.keras.preprocessing.image dataset from directory(test_dir,\n""]","[""class_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(f'Weight for class 0: {weight_for_0}')\nprint(f'Weight for class 1: {weight_for_1}')\n\n# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest data = tf.keras.preprocessing.image dataset from directorv(test_dir,\n""]"
27324,27370,0,"[""class_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(f'Weight for class 0: {weight_for_0}')\nprint(f'Weight for class 1: {weight_for_1}')\n\n# Load in data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n   batch_size=32,\n   image_size=(224, 224)\n)\n\ntest data = tf.keras.preprocessing.image dataset from directorv(test_dir,\n""]","['# wandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k-livestream-video"", sync_tensorboard=True)\nhistory_1 = model_1.fit(train_data,\n   epochs=5,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"", model_1.name)])\n']"
27370,27391,7,"['# wandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k-livestream-video"", sync_tensorboard=True)\nhistory_1 = model_1.fit(train_data,\n   epochs=5,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"", model_1.name)])\n']","['# Fit model\nimport wandb \n# wandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k-livestream-video"", sync_tensorboard=True)\nhistory_1 = model_1.fit(train_data,\n   epochs=5,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"", model_1.name)],\n   class_weight=class_weight) # adjust for different numbers of classes...\n']"
27391,27583,0,"['# Fit model\nimport wandb \n# wandb.tensorboard.patch(root_logdir=""logs"")\nwandb.init(project=""100k-livestream-video"", sync_tensorboard=True)\nhistory_1 = model_1.fit(train_data,\n   epochs=5,\n   validation_data=test_data,\n   callbacks=[early_stopping,\n      create_tensorboard_callback(""logs"", model_1.name)],\n   class_weight=class_weight) # adjust for different numbers of classes...\n']",['model_1.evaluate(test_data)\n']
27583,27641,1,['model_1.evaluate(test_data)\n'],['model_1.evaluate(test_data)\n']
27641,27641,1,['model_1.evaluate(test_data)\n'],['model_1.evaluate(test_data)\n']
27641,27757,0,['model_1.evaluate(test_data)\n'],"['len(os.listdir(""data/train/food_images/"")), len(os.listdir(""data/train/non_food_images/""))\n']"
27757,27769,1,"['len(os.listdir(""data/train/food_images/"")), len(os.listdir(""data/train/non_food_images/""))\n']","['len(os.listdir(""data/train/food_images/"")), len(os.listdir(""data/train/non_food_images/""))\n\nmodel_1. save(""food_not_food_model_v1"")\n']"
27769,28288,0,"['len(os.listdir(""data/train/food_images/"")), len(os.listdir(""data/train/non_food_images/""))\n\nmodel_1. save(""food_not_food_model_v1"")\n']","['export const classes = {\n1: ""food"",\n2: ""not_food""\n};\n']"
28288,28466,0,"['export const classes = {\n1: ""food"",\n2: ""not_food""\n};\n']",['']
28466,28473,0,[''],"['   // Check if model loaded\n   if (tfliteModel) {\n      model_status.innerText = ""Model loaded"";\n   }\n} catch (error) {\n   console. log(error);\n}\n\n// // Prepare input tensors.\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n// // Run inference and get output tensors.\n// let outputTensor = tfliteModel.predict(input);\n// console.log(outputTensor.dataSync());\n}\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n  image = tf.cast(image, ""int32""); // Model requires uints\n  const output = model.predict(image) ;\n  const output_values = tf.softmax(output.arraySync()[0]);\n  console. log(output.arraySync()) //arraySync() Returns an array to use\n\n  // update HTML\n  predicted_class.innerText = classes[output_values.argMax().arraySync()];\n  predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n']"
28473,28556,0,"['   // Check if model loaded\n   if (tfliteModel) {\n      model_status.innerText = ""Model loaded"";\n   }\n} catch (error) {\n   console. log(error);\n}\n\n// // Prepare input tensors.\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n// // Run inference and get output tensors.\n// let outputTensor = tfliteModel.predict(input);\n// console.log(outputTensor.dataSync());\n}\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n  image = tf.cast(image, ""int32""); // Model requires uints\n  const output = model.predict(image) ;\n  const output_values = tf.softmax(output.arraySync()[0]);\n  console. log(output.arraySync()) //arraySync() Returns an array to use\n\n  // update HTML\n  predicted_class.innerText = classes[output_values.argMax().arraySync()];\n  predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n']",['']
28556,28592,0,[''],['']
28592,28609,0,[''],"['<IDOCTYPE html>\n<html>\n   <head>\n      <meta charset=""utf-8"" />\n      <meta name=""viewport"" content=""width=device-width"" />\n      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>\n']"
28609,28609,36,"['<IDOCTYPE html>\n<html>\n   <head>\n      <meta charset=""utf-8"" />\n      <meta name=""viewport"" content=""width=device-width"" />\n      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>\n']","['<IDOCTYPE html>\n<html>\n   <head>\n      <meta charset=""utf-8"" />\n      <meta name=""viewport"" content=""width=device-width"" />\n      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>']"
28609,28645,33,"['<IDOCTYPE html>\n<html>\n   <head>\n      <meta charset=""utf-8"" />\n      <meta name=""viewport"" content=""width=device-width"" />\n      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>']","['      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n\n      <br>\n      <p> This line below will say loaded if the model is loaded:</p>\n      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>']"
28645,28665,32,"['      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n\n      <br>\n      <p> This line below will say loaded if the model is loaded:</p>\n      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>']","['      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n      <br>\n      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n      <p id=""status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <br>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>']"
28665,28665,34,"['      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n      <br>\n      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n      <p id=""status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <br>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>']","['      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n\n      <br>\n      <p>This line below will say loaded if the model is loaded</p>\n      <p id=""status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <br>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>']"
28665,28696,0,"['      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n   <body>\n      <h1>Food Not Food</h1>\n      <p>This app will tell you if the image you upload is food or not.</p>\n      <p>Yes. That\'s it. </p>\n      <p>It\'ll use a computer vision machine learning model to classify your\n      image as ""food"" or ""not food"".</p>\n      <br>\n      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>\n      <p id=""status"">Awaiting TF.js load</p>\n\n      <br>\n      <p>This line below will say loaded if the model is loaded</p>\n      <p id=""status"">Awaiting TF.js model/TFLite model loading</p>\n\n      <!— Upload image —>\n      <br>\n      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n      /></p>\n      <p<img id=""image"" width=""200"" /></p>\n\n      <p>Predicted class:</p>\n      <p id=""predicted_class""></p>\n      <p>Predicted probability:</p>\n      <p id=""predicted_prob""></p>\n     \n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""\n         type=""text/javascript""\n      ></script>\n      <script\n         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>\n\n      <script src=""script.js""></script>\n   </body>\n</html>']","['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(“status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']"
28696,28863,31,"['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(“status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']","['const status = document.getElementById(“status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         // ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n']"
28863,28865,30,"['const status = document.getElementById(“status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         // ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n']","['const status = document.getElementById(“status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']"
28865,28913,30,"['const status = document.getElementById(“status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']","['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(“status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']"
28913,28963,34,"['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(“status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']","['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/food_not_food_model_v1.tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']"
28963,28963,0,"['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/food_not_food_model_v1.tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']",['']
28963,28973,0,[''],"['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/food_not_food_model_v1.tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']"
28973,29020,0,"['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/food_not_food_model_v1.tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']","['<IDOCTYPE html>\n<html>\n   <head>\n      <meta charset=""utf-8"" />\n      <meta name=""viewport"" content=""width=device-width"" /> !\n      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n\n<body>\n   <h1>Food Not Food (£ or £© )</h1>\n   <p>This app will tell you if the image you upload is food or not.</p>\n   <p>Yes. That\'s it. </p>\n   <p>It\'ll use a computer vision machine learning model to classify your\n   image as ""food"" or ""not food"".</p>\n   <br>\n   <p>This line below will say loaded if TensorFlow.js is loaded:</p>\n   <p id=""status\'"">Awaiting TF.js load</p>\n\n   <br>\n   <p>This line below will say loaded if the model is loaded:</p>\n   <p id=""model status"">Awaiting TF.js model/TFLite model loading</p>\n\n   <!-- Upload image -->\n   <br>\n   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n   <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n   /></p>\n   <p><img id=""inage"" width=""200"" /></p>\n\n   <p>Predicted class:</p>\n   <p id=""predicted_class""></p>\n   <p>Predicted probability:</p>\n   <p id=""predicted_prob""></p>\n\n   <script\n      src=""https://cdn.jsdelivr.net/npn/gtensorflow/tfjs/dist/tf.min.js""\n      type=""text/javascript""\n   ></script>\n']"
29020,29128,0,"['<IDOCTYPE html>\n<html>\n   <head>\n      <meta charset=""utf-8"" />\n      <meta name=""viewport"" content=""width=device-width"" /> !\n      <title>Hello World - TensorFlow.js</title>\n      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n   </head>\n\n<body>\n   <h1>Food Not Food (£ or £© )</h1>\n   <p>This app will tell you if the image you upload is food or not.</p>\n   <p>Yes. That\'s it. </p>\n   <p>It\'ll use a computer vision machine learning model to classify your\n   image as ""food"" or ""not food"".</p>\n   <br>\n   <p>This line below will say loaded if TensorFlow.js is loaded:</p>\n   <p id=""status\'"">Awaiting TF.js load</p>\n\n   <br>\n   <p>This line below will say loaded if the model is loaded:</p>\n   <p id=""model status"">Awaiting TF.js model/TFLite model loading</p>\n\n   <!-- Upload image -->\n   <br>\n   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n   <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""\n   /></p>\n   <p><img id=""inage"" width=""200"" /></p>\n\n   <p>Predicted class:</p>\n   <p id=""predicted_class""></p>\n   <p>Predicted probability:</p>\n   <p id=""predicted_prob""></p>\n\n   <script\n      src=""https://cdn.jsdelivr.net/npn/gtensorflow/tfjs/dist/tf.min.js""\n      type=""text/javascript""\n   ></script>\n']","['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         //""/food_not_food_model_v1.tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n};\n']"
29128,29146,32,"['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         //""/food_not_food_model_v1.tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n};\n']","['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/food_not_food_model_v1.tflite""\n         // ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']"
29146,29191,31,"['const classes = {\n   1: “food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         ""/food_not_food_model_v1.tflite""\n         // ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\n']","['if (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         // ""/food_not_food_model_v1.tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\n']"
29191,29236,14,"['if (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_\n         model_v0. tflite""\n         // ""/food_not_food_model_v1.tflite""\n         ""/10_whole_foods_model_vo. tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\n']","['      }\n   } catch (error) {\n      console.log(error); \n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as \n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""&"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\n']"
29236,29242,9,"['      }\n   } catch (error) {\n      console.log(error); \n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as \n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""&"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\n']","['const classes = {\n   1: ""food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis.com/food-vision-model-playground/food_not_fo\n         od_model_v1.tflite\n         ""/food_not_food_model_v1.tflite""\n         // ""/10_whole_foods_model_vo kflite""\n      };\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) { \n         model_status. innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n']"
29242,29274,9,"['const classes = {\n   1: ""food"",\n   2: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis.com/food-vision-model-playground/food_not_fo\n         od_model_v1.tflite\n         ""/food_not_food_model_v1.tflite""\n         // ""/10_whole_foods_model_vo kflite""\n      };\n      model = tfliteModel; // assigning it to the global scope model as\n      tfliteModel can only be used within this scope\n      // console. log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) { \n         model_status. innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n']","['      console. log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims (image);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   // image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   const output_values = tf.softmax(output.arraySync() [6]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n\n   // Update HTML\n   predicted_class. innerText = classes [output_values.argMax().arraySync()1;\n   predicted_prob. innerText = output_values.max().arraySync() * 100 + ""5"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"") ;\n']"
29274,29339,30,"['      console. log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims (image);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   // image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   const output_values = tf.softmax(output.arraySync() [6]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n\n   // Update HTML\n   predicted_class. innerText = classes [output_values.argMax().arraySync()1;\n   predicted_prob. innerText = output_values.max().arraySync() * 100 + ""5"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"") ;\n']","['      console. log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims (image);\n   console.log(image);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   // image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   const output_values = tf.softmax(output.arraySync() [6]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()1;\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"") ;']"
29339,29419,27,"['      console. log(error);\n   }\n\n   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims (image);\n   console.log(image);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   // image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   const output_values = tf.softmax(output.arraySync() [6]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()1;\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"") ;']","['   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims (image);\n   console.log(image.arraySync());\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   // image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   const output_values = tf.softmax(output.arraySync() [6]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n   // Update HTML\n   predicted_class. innerText = classes [output_values.argMax().arraySync()1;\n   predicted_prob. innerText = output_values.max().arraySync() * 100 + ""5"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"") ;\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files(0);']"
29419,29444,25,"['   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims (image);\n   console.log(image.arraySync());\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   // image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   const output_values = tf.softmax(output.arraySync() [6]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n   // Update HTML\n   predicted_class. innerText = classes [output_values.argMax().arraySync()1;\n   predicted_prob. innerText = output_values.max().arraySync() * 100 + ""5"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"") ;\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files(0);']","['};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(inage); \n   // console.log(image.arraySync());\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as \n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   // image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict (inage);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementByTd(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n\n   // When reader is ready display image\n   reader.onload = function (event) {\n']"
29444,29589,25,"['};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(inage); \n   // console.log(image.arraySync());\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as \n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   // image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict (inage);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementByTd(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n\n   // When reader is ready display image\n   reader.onload = function (event) {\n']","['\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image); \n   console.log(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as \n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   // image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementByTd(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n ']"
29589,29633,26,"['\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image); \n   console.log(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as \n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   // image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementByTd(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n ']","['};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image); \n   // console.log(image.arraySync());\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as \n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict (inage);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementByTd(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n\n   // When reader is ready display image\n   reader.onload = function (event) {']"
29633,29671,3,"['};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image); \n   // console.log(image.arraySync());\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as \n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict (inage);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementByTd(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n\n   // When reader is ready display image\n   reader.onload = function (event) {']","['const status = document.getElementById(""status"");\nif (status) {\n   status.innerText = “Loaded TensorFlow.js — version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n      //\n      https://storage.googleapis.com/food-vision-model-playground/food_not_fo\n      od_model_v1.tflite\n      // ""/food_not_food_model_v1.tflite""\n      ""/10_whole_foods_model_vo. tflite""\n   };\n   model = tfliteModel; // assigning it to the global scope model as\n   tfliteModel can only be used within this scope\n   // console.log(tfliteModel);\n\n   // Check if model loaded\n   if (tfliteModel) {\n      model_status.innerText = ""Model loaded"";\n   }\n} catch (error) {\n   console. log(error) ;\n}\n\n   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n']"
29671,29704,14,"['const status = document.getElementById(""status"");\nif (status) {\n   status.innerText = “Loaded TensorFlow.js — version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n      //\n      https://storage.googleapis.com/food-vision-model-playground/food_not_fo\n      od_model_v1.tflite\n      // ""/food_not_food_model_v1.tflite""\n      ""/10_whole_foods_model_vo. tflite""\n   };\n   model = tfliteModel; // assigning it to the global scope model as\n   tfliteModel can only be used within this scope\n   // console.log(tfliteModel);\n\n   // Check if model loaded\n   if (tfliteModel) {\n      model_status.innerText = ""Model loaded"";\n   }\n} catch (error) {\n   console. log(error) ;\n}\n\n   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n']","['} catch (error) {\n   console. log(error) ;\n}\n\n   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   image = tf.cast(image, ""float32"");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");']"
29704,29704,0,"['} catch (error) {\n   console. log(error) ;\n}\n\n   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   image = tf.cast(image, ""float32"");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");']",['']
29704,29715,0,[''],"['if (status) {\n   status.innerText = “Loaded TensorFlow.js — version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n      //\n      https://storage.googleapis.com/food-vision-model-playground/food_not_fo\n      od_model_v1.tflite\n      ""/food_not_food_model_v1.tflite""\n      // ""/10_whole_foods_model_vo. tflite""\n   };\n   model = tfliteModel; // assigning it to the global scope model as\n   tfliteModel can only be used within this scope\n   // console.log(tfliteModel);\n\n   // Check if model loaded\n   if (tfliteModel) {\n      model_status.innerText = ""Model loaded"";\n   }\n} catch (error) {\n   console. log(error) ;\n}\n\n   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image)']"
29715,29882,15,"['if (status) {\n   status.innerText = “Loaded TensorFlow.js — version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n      //\n      https://storage.googleapis.com/food-vision-model-playground/food_not_fo\n      od_model_v1.tflite\n      ""/food_not_food_model_v1.tflite""\n      // ""/10_whole_foods_model_vo. tflite""\n   };\n   model = tfliteModel; // assigning it to the global scope model as\n   tfliteModel can only be used within this scope\n   // console.log(tfliteModel);\n\n   // Check if model loaded\n   if (tfliteModel) {\n      model_status.innerText = ""Model loaded"";\n   }\n} catch (error) {\n   console. log(error) ;\n}\n\n   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image)']","['   console. log(error) ;\n}\n\n   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyInage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]);  // arraySync() Returns an array to use\n\n   // Update HTHL\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n']"
29882,30078,30,"['   console. log(error) ;\n}\n\n   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyInage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]);  // arraySync() Returns an array to use\n\n   // Update HTHL\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n']","['   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   // image = tf.image.resizeBilinear(image, [224, 224]); // image size needs\n   to be same as model inputs\n   // image = tf.expandDims(image);\n   console.log(image);\n\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n']"
30078,30126,30,"['   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   // image = tf.image.resizeBilinear(image, [224, 224]); // image size needs\n   to be same as model inputs\n   // image = tf.expandDims(image);\n   console.log(image);\n\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n']","['   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   // image = tf.expandDims(image);\n   console.log(image);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   // image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {']"
30126,30170,30,"['   // // Prepare input tensors\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   // image = tf.expandDims(image);\n   console.log(image);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   // image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {']","['   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   // image = tf.image.resizeBilinear(image, [224, 224]); // image size needs\n   to be same as model inputs\n   // image = tf.expandDims(image);\n   console.log(image);\n\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n']"
30170,30191,31,"['   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   // image = tf.image.resizeBilinear(image, [224, 224]); // image size needs\n   to be same as model inputs\n   // image = tf.expandDims(image);\n   console.log(image);\n\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n']","['   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs\n   to be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n']"
30191,30229,22,"['   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs\n   to be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n']","['   // console. log(tfliteModel);\n\n   // Check if model loaded\n   if (tfliteModel) {\n      model_status.innerText = “Model loaded"";\n   }\n} catch (error) { \n console.log(error);\n}\n\n// // Prepare input tensors.\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1); \n// // Run inference and get output tensors.\n// let outputTensor = tfliteModel.predict(input);\n// console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n  // Preprocess image\n  image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n  be same as model inputs\n  image = tf.expandDims(image);\n  console.log(image);\n  console.log(model);\n\n// console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as\noutput thus we cast int32 in below line\nconsole.log(tflite.getDTypeFronTFLiteType(""uint8""));\n// image = tf.cast(image, \'int32\'); // Model requires uint8\nconst output = model.predict(image);\n// const output_values = tf.softmax(output.arraySync()[0]);\nconsole.log(output.arraySync());\nconsole.log(output.arraySync()[0]);\n\n']"
30229,30332,28,"['   // console. log(tfliteModel);\n\n   // Check if model loaded\n   if (tfliteModel) {\n      model_status.innerText = “Model loaded"";\n   }\n} catch (error) { \n console.log(error);\n}\n\n// // Prepare input tensors.\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1); \n// // Run inference and get output tensors.\n// let outputTensor = tfliteModel.predict(input);\n// console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n  // Preprocess image\n  image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n  be same as model inputs\n  image = tf.expandDims(image);\n  console.log(image);\n  console.log(model);\n\n// console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as\noutput thus we cast int32 in below line\nconsole.log(tflite.getDTypeFronTFLiteType(""uint8""));\n// image = tf.cast(image, \'int32\'); // Model requires uint8\nconst output = model.predict(image);\n// const output_values = tf.softmax(output.arraySync()[0]);\nconsole.log(output.arraySync());\nconsole.log(output.arraySync()[0]);\n\n']","['} catch (error) { \n console.log(error);\n}\n\n// // Prepare input tensors.\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1); \n// // Run inference and get output tensors.\n// let outputTensor = tfliteModel.predict(input);\n// console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n  // Preprocess image\n  image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n  be same as model inputs\n  image = tf.expandDims(image);\n  console.log(image);\n  // console.log(model);\n\n// console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output\nthus we cast int32 in below line\nconsole.log(tflite.getDTypeFronTFLiteType(""uint8""));\n// image = tf.cast(image, \'int32\'); // Model requires uint8\nconst output = model.predict(image);\n// const output_values = tf.softmax(output.arraySync()[0]);\nconsole.log(output.arraySync());\nconsole.log(output.arraySync()[0]);\n\n// Update HTML\npredicted_class.innerText = classes[output_values.argMax().arraySync()];\npredicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n']"
30332,30435,0,"['} catch (error) { \n console.log(error);\n}\n\n// // Prepare input tensors.\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1); \n// // Run inference and get output tensors.\n// let outputTensor = tfliteModel.predict(input);\n// console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n  // Preprocess image\n  image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to\n  be same as model inputs\n  image = tf.expandDims(image);\n  console.log(image);\n  // console.log(model);\n\n// console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output\nthus we cast int32 in below line\nconsole.log(tflite.getDTypeFronTFLiteType(""uint8""));\n// image = tf.cast(image, \'int32\'); // Model requires uint8\nconst output = model.predict(image);\n// const output_values = tf.softmax(output.arraySync()[0]);\nconsole.log(output.arraySync());\nconsole.log(output.arraySync()[0]);\n\n// Update HTML\npredicted_class.innerText = classes[output_values.argMax().arraySync()];\npredicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n']","[""# Load the TFLite model in TFLite Interpreter\ninterpreter = tf.lite.Interpreter(food_not_food_model_v1.tflite)\n# There is only 1 signature defined in the model,\n# so it will return it by default.\n# If there are multiple signatures then we can pass the name.\nmy_signature = interpreter.get_signature_runner()\n\n# my_signature is callable with input as arguments.\noutput = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))\n# 'output' is dictionary with all outputs from the inference.\n# In this case we have single output 'result'.\nprint(output['result'])""]"
30435,30453,11,"[""# Load the TFLite model in TFLite Interpreter\ninterpreter = tf.lite.Interpreter(food_not_food_model_v1.tflite)\n# There is only 1 signature defined in the model,\n# so it will return it by default.\n# If there are multiple signatures then we can pass the name.\nmy_signature = interpreter.get_signature_runner()\n\n# my_signature is callable with input as arguments.\noutput = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))\n# 'output' is dictionary with all outputs from the inference.\n# In this case we have single output 'result'.\nprint(output['result'])""]","[""# Load the TFLite model in TFLite Interpreter\ninterpreter = tf.lite.Interpreter(food_not_food_model_v1.tflite)\n# There is only 1 signature defined in the model,\n# so it will return it by default.\n# If there are multiple signatures then we can pass the name.\nmy_signature = interpreter.get_signature_runner()\n\n# my_signature is callable with input as arguments.\noutput = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))\n# 'output' is dictionary with all outputs from the inference.\n# In this case we have single output 'result'.\nprint(output['result'])\n""]"
30453,30458,11,"[""# Load the TFLite model in TFLite Interpreter\ninterpreter = tf.lite.Interpreter(food_not_food_model_v1.tflite)\n# There is only 1 signature defined in the model,\n# so it will return it by default.\n# If there are multiple signatures then we can pass the name.\nmy_signature = interpreter.get_signature_runner()\n\n# my_signature is callable with input as arguments.\noutput = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))\n# 'output' is dictionary with all outputs from the inference.\n# In this case we have single output 'result'.\nprint(output['result'])\n""]","['# Load the TFLite model in TFLite Interpreter\ninterpreter = tf.lite.Interpreter(""food_not_food_model_v1.tflite"")\n# There is only 1 signature defined in the model,\n# so it will return it by default.\n# If there are multiple signatures then we can pass the name.\nmy_signature = interpreter.get_signature_runner()\n\n# my_signature is callable with input as arguments.\noutput = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))\n# \'output\' is dictionary with all outputs from the inference,\n# In this case we have single output \'result\'.\nprint(output[\'result\'])\n']"
30458,30472,11,"['# Load the TFLite model in TFLite Interpreter\ninterpreter = tf.lite.Interpreter(""food_not_food_model_v1.tflite"")\n# There is only 1 signature defined in the model,\n# so it will return it by default.\n# If there are multiple signatures then we can pass the name.\nmy_signature = interpreter.get_signature_runner()\n\n# my_signature is callable with input as arguments.\noutput = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))\n# \'output\' is dictionary with all outputs from the inference,\n# In this case we have single output \'result\'.\nprint(output[\'result\'])\n']","['# Load the TFLite model in TFLite Interpreter\ninterpreter = tf.lite.Interpreter(""food_not_food_model_v1.tflite"")\n# There is only 1 signature defined in the model,\n# so it will return it by default.\n# If there are multiple signatures then we can pass the name.\nmy_signature = interpreter.get_signature_runner()\n\n# my_signature is callable with input as arguments.\n# output = my_signature(x=tf.constant([1.6], shape=(1,10), dtype=tf.float32))\n# \'output\' is dictionary with all outputs from the inference.\n# In this case we have single output \'result\'.\n# print(output[‘result\'])\n']"
30472,30512,0,"['# Load the TFLite model in TFLite Interpreter\ninterpreter = tf.lite.Interpreter(""food_not_food_model_v1.tflite"")\n# There is only 1 signature defined in the model,\n# so it will return it by default.\n# If there are multiple signatures then we can pass the name.\nmy_signature = interpreter.get_signature_runner()\n\n# my_signature is callable with input as arguments.\n# output = my_signature(x=tf.constant([1.6], shape=(1,10), dtype=tf.float32))\n# \'output\' is dictionary with all outputs from the inference.\n# In this case we have single output \'result\'.\n# print(output[‘result\'])\n']","['   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   // console.log(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   // image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\n\n']"
30512,30585,0,"['   // // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel() ;\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   // console.log(image);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   // image = tf.cast(image, ""int32""); // Model requires uint8\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\n\n']","['import numpy as np\nimport tensorflow as tf\n\n# Load the TFLite model and allocate tensors.\ninterpreter = tf.lite.Interpreter(model_path=""food_not_food_model_v1.tflite"")\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Test the model on random input data.\ninput_shape = input_details[0][\'shape\']\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\ninterpreter.set_tensor(input_details[0][\'index\'], input_data)\n\ninterpreter. invoke()\n']"
30585,30604,13,"['import numpy as np\nimport tensorflow as tf\n\n# Load the TFLite model and allocate tensors.\ninterpreter = tf.lite.Interpreter(model_path=""food_not_food_model_v1.tflite"")\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Test the model on random input data.\ninput_shape = input_details[0][\'shape\']\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\ninterpreter.set_tensor(input_details[0][\'index\'], input_data)\n\ninterpreter. invoke()\n']","['import numpy as np\nimport tensorflow as tf\n\n# Load the TFLite model and allocate tensors.|\ninterpreter = tf.lite.Interpreter(model_path=""food_not_food_model_v1.tflite"")\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Test the model on random input data.\ninput_shape = input_details[0][\'shape\']\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\ninterpreter.set_tensor(input_details[0][\'index\'], input_data)\n\ninterpreter.invoke()\n']"
30604,30612,9,"['import numpy as np\nimport tensorflow as tf\n\n# Load the TFLite model and allocate tensors.|\ninterpreter = tf.lite.Interpreter(model_path=""food_not_food_model_v1.tflite"")\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Test the model on random input data.\ninput_shape = input_details[0][\'shape\']\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\ninterpreter.set_tensor(input_details[0][\'index\'], input_data)\n\ninterpreter.invoke()\n']","[""interpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Test the model on random input data.\ninput_shape = input_details[0]['shape']\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\ninterpreter.set_tensor(input_details[@] ['index'], input_data)\n\ninterpreter.invoke() \n\n# The function 'get_tensor()' returns a copy of the tensor data.\n# Use 'tensor()' in order to get a pointer to the tensor.\noutput_data = interpreter.get_tensor(output_details[0]['index'])\nprint(output_data)\n""]"
30612,30727,0,"[""interpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Test the model on random input data.\ninput_shape = input_details[0]['shape']\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\ninterpreter.set_tensor(input_details[@] ['index'], input_data)\n\ninterpreter.invoke() \n\n# The function 'get_tensor()' returns a copy of the tensor data.\n# Use 'tensor()' in order to get a pointer to the tensor.\noutput_data = interpreter.get_tensor(output_details[0]['index'])\nprint(output_data)\n""]","['   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   image = tf.cast(image, ""int32"");  // Model requires uint8\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if(fileInput.files[0]) throw new Error(""Image not found"");']"
30727,30825,32,"['   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   image = tf.cast(image, ""int32"");  // Model requires uint8\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if(fileInput.files[0]) throw new Error(""Image not found"");']","['   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as output \n   thus we cast int32 in below line\n   console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   // image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   // const output_values = tf.softmax(output.arraySync() [6]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes [output_values.argMax().arraySync()1;\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"") ;\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n']"
30825,30901,0,"['   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as output \n   thus we cast int32 in below line\n   console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   // image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   // const output_values = tf.softmax(output.arraySync() [6]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes [output_values.argMax().arraySync()1;\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"") ;\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n']",['']
30901,30901,0,[''],"['};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   // image = tf.cast(image, ""int32"");  // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if(fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();']"
30901,31103,0,"['};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   // image = tf.cast(image, ""int32"");  // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if(fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();']","['import os\n\nimport numpy as np\n\nimport tensorflow as tf\nassert tf.__version__.startswith(\'2""\')\n\nfrom tflite_model_maker import model spec\nfrom tflite_model_maker import image classifier\nfrom tflite_model_maker.config import ExportFormat\nfrom tflite_model_maker.config import QuantizationConfig\nfrom tflite_model_maker.image_classifier import Dataloader\nimport matplotlib.pyplot as plt\n']"
31103,31123,4,"['import os\n\nimport numpy as np\n\nimport tensorflow as tf\nassert tf.__version__.startswith(\'2""\')\n\nfrom tflite_model_maker import model spec\nfrom tflite_model_maker import image classifier\nfrom tflite_model_maker.config import ExportFormat\nfrom tflite_model_maker.config import QuantizationConfig\nfrom tflite_model_maker.image_classifier import Dataloader\nimport matplotlib.pyplot as plt\n']","['from tflite_model_maker.config import QuantizationConfig\nfrom tflite_model_maker.image_classifier import Dataloader\n\nimport matplotlib.pyplot as plt\n\ntrain_data_path = ""10_whole_foods/train""\ntest_data_path = ""10_whole_foods/test""\n\nimport os\nclass_names = sorted(os.listdir(train_data_path))\nclass_names\n']"
31123,31139,3,"['from tflite_model_maker.config import QuantizationConfig\nfrom tflite_model_maker.image_classifier import Dataloader\n\nimport matplotlib.pyplot as plt\n\ntrain_data_path = ""10_whole_foods/train""\ntest_data_path = ""10_whole_foods/test""\n\nimport os\nclass_names = sorted(os.listdir(train_data_path))\nclass_names\n']","['train_data_path = ""data/train""\ntest_data_path = ""data/test""\n\nimport os\nclass_names = sorted(os.listdir(train_data_path))\nclass_names\n']"
31139,31171,0,"['train_data_path = ""data/train""\ntest_data_path = ""data/test""\n\nimport os\nclass_names = sorted(os.listdir(train_data_path))\nclass_names\n']","['train_data = Dataloader.from_folder(train_data_path)\ntest_data = Dataloader.from_folder(test_data_path)\n\ntrain_data, test_data\n\n# Create model\nmodel = image_classifier.create(train_data)\n\nr=\'.\', tflite_filename:""food_not_food_model_v2.tflite"")\n']"
31171,31174,5,"['train_data = Dataloader.from_folder(train_data_path)\ntest_data = Dataloader.from_folder(test_data_path)\n\ntrain_data, test_data\n\n# Create model\nmodel = image_classifier.create(train_data)\n\nr=\'.\', tflite_filename:""food_not_food_model_v2.tflite"")\n']","['train_data = Dataloader.from_folder(train_data_path)\ntest_data = Dataloader.from_folder(test_data_path)\n\ntrain_data, test_data\n\n# Create model\nmodel = image_classifier.create(train_data)\n']"
31174,31191,0,"['train_data = Dataloader.from_folder(train_data_path)\ntest_data = Dataloader.from_folder(test_data_path)\n\ntrain_data, test_data\n\n# Create model\nmodel = image_classifier.create(train_data)\n']","['# Load image \nimage = tf.keras.utils.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.utils.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 2\npreds = model.predict_top_k(input_arr, k=5, batch_size=1)\npreds[0]\n']"
31191,31200,7,"['# Load image \nimage = tf.keras.utils.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.utils.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 2\npreds = model.predict_top_k(input_arr, k=5, batch_size=1)\npreds[0]\n']","['# Load image\nimage = tf.keras.utils.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.utils.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image \ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 2\npreds = model.predict_top_k{input_arr, k=2 batch_size=1)|\npreds[0]\n']"
31200,31216,0,"['# Load image\nimage = tf.keras.utils.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.utils.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image \ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 2\npreds = model.predict_top_k{input_arr, k=2 batch_size=1)|\npreds[0]\n']",['']
31216,31262,0,[''],"['      console.log(error);\n   }   \n\n   // // Prepare input tensors\n   // const img = tf.browswer.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   // const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes [output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";\n}']"
31262,31320,28,"['      console.log(error);\n   }   \n\n   // // Prepare input tensors\n   // const img = tf.browswer.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   image = tf.cast(image, \'int32\');  // Model requires uint8\n   const output = model.predict(image) ;\n   // const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync() [0]); // arraySync Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes [output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";\n}']","['   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   console.log(""converting image to different datatype..."");\n   image = tf.cast(image, ""uint32"");  // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\n']"
31320,31551,0,"['   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);\n\n   // // Run inference and get output tensors.\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   console.log(""converting image to different datatype..."");\n   image = tf.cast(image, ""uint32"");  // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\n']","['train_data_path = ""food-not-food/data/train""\ntest_data_path = ""food-not-food/data/train""\n\nimport os\nclass_names = sorted(os.listdir(train_data_path))\nclass_names\n']"
31551,31921,0,"['train_data_path = ""food-not-food/data/train""\ntest_data_path = ""food-not-food/data/train""\n\nimport os\nclass_names = sorted(os.listdir(train_data_path))\nclass_names\n']","['# Save the model\nmodel.export(export_dir=\'.\', tflite_filename=""food_not_food_model_v2.tflite"")\n']"
31921,32066,0,"['# Save the model\nmodel.export(export_dir=\'.\', tflite_filename=""food_not_food_model_v2.tflite"")\n']","['# Load image\nimage = tf.keras.preprocessing.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image to a batch.\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels\npreds = model.predict_top_k(input_arr, k=5, batch_size=1)\npreds[0]\n']"
32066,32110,4,"['# Load image\nimage = tf.keras.preprocessing.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image to a batch.\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels\npreds = model.predict_top_k(input_arr, k=5, batch_size=1)\npreds[0]\n']","['# Load image\nimage = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr]) # Conv\ninput_arr = tf.image.resize(input_arr, si\npreds = model.predict_top_k(input_arr, k=\npreds[0]\n']"
32110,32131,3,"['# Load image\nimage = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr]) # Conv\ninput_arr = tf.image.resize(input_arr, si\npreds = model.predict_top_k(input_arr, k=\npreds[0]\n']","['image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image to a batch.\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels\npreds = model.predict_top_k(input_arr, k=2, batch_size=1)\npreds [0]\n\ndict([(k, float(v)) for k, v in dict(preds[0]).items()])\n']"
32131,32351,0,"['image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image to a batch.\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels\npreds = model.predict_top_k(input_arr, k=2, batch_size=1)\npreds [0]\n\ndict([(k, float(v)) for k, v in dict(preds[0]).items()])\n']","['import os\nfood_image_paths = []\nfor dir, sub_dir, files os.walk(""101_food_classes_all_data""):\n   for file in files:\n      food_image_paths.append(os.path.join(dir, file))\nfood_image_paths\n']"
32351,32536,0,"['import os\nfood_image_paths = []\nfor dir, sub_dir, files os.walk(""101_food_classes_all_data""):\n   for file in files:\n      food_image_paths.append(os.path.join(dir, file))\nfood_image_paths\n']","['food_image_paths.remove(""101_food_classes_all_data/train/.DS_Store"")\n\n""101_food_classes_all_data/train/.DS_Store"" in food_image_paths\n']"
32536,32614,0,"['food_image_paths.remove(""101_food_classes_all_data/train/.DS_Store"")\n\n""101_food_classes_all_data/train/.DS_Store"" in food_image_paths\n']","['# Get random 30000 images\nimport random\nrandom.seed(42)\nrandom_30k_food_image_paths = random.sample(food_image_paths, k=30000)\nlen(random_30k_food_image_paths)\n']"
32614,32664,5,"['# Get random 30000 images\nimport random\nrandom.seed(42)\nrandom_30k_food_image_paths = random.sample(food_image_paths, k=30000)\nlen(random_30k_food_image_paths)\n']","['# Get random 30000 images\nimport random\nrandom.seed(42)\nrandom_38k_food_image_paths = random.sample(food_image_paths, k=38000)\nlen(random_38k_food_image_paths)\n']"
32664,32741,1,"['# Get random 30000 images\nimport random\nrandom.seed(42)\nrandom_38k_food_image_paths = random.sample(food_image_paths, k=38000)\nlen(random_38k_food_image_paths)\n']","['def create_train_test_list(image_list):\n   random.seed(42)\n   # image_list = [os.path.join(target_dir, img_path) for img_path in os.li\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list))\n   return train_image_list, test_im \n\ntrain_image_list, test_image_list = create_train_test_list(random_38k_food_i\nlen(train_image_list), len(test_image_list)\n']"
32741,32790,0,"['def create_train_test_list(image_list):\n   random.seed(42)\n   # image_list = [os.path.join(target_dir, img_path) for img_path in os.li\n   train_split = int(0.8 * len(image_list))\n   train_image_list = random.sample(image_list, train_split)\n   test_image_list = list(set(image_list).difference(set(train_image_list))\n   return train_image_list, test_im \n\ntrain_image_list, test_image_list = create_train_test_list(random_38k_food_i\nlen(train_image_list), len(test_image_list)\n']",['']
32790,32800,0,[''],"['image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image to a batch.\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels\npreds = model.predict_top_k(input_arr, k=2, batch_size=1)\npreds[0]\n\ndict([(k, float(v)) for k, v in dict(preds[0]).items()])\n']"
32800,32809,0,"['image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image to a batch.\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels\npreds = model.predict_top_k(input_arr, k=2, batch_size=1)\npreds[0]\n\ndict([(k, float(v)) for k, v in dict(preds[0]).items()])\n']","['# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      # copy2(image_path, dest_path)\n\nprint(test_images)\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_im\ncopy_images_to_file(image_list=test_images, target_dir=""data/test/food_imag\n']"
32809,32825,13,"['# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      # copy2(image_path, dest_path)\n\nprint(test_images)\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_im\ncopy_images_to_file(image_list=test_images, target_dir=""data/test/food_imag\n']","['train_images, test_images = create_train_test_list(random_38k_food_image_pa\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(|image_path, dest_path])]\n\n# print(test_images)\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_ima\n']"
32825,32838,12,"['train_images, test_images = create_train_test_list(random_38k_food_image_pa\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(|image_path, dest_path])]\n\n# print(test_images)\ncopy_images_to_file(image_list=train_images, target_dir=""data/train/food_ima\n']","['from shutil import copy3\ntrain_images, test_images = create_train_test_list(random_38k_food_image_pat\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\n# print(test_images)\n']"
32838,32840,7,"['from shutil import copy3\ntrain_images, test_images = create_train_test_list(random_38k_food_image_pat\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n\n# print(test_images)\n']","['ist(set(image_list).difference(set(train_image_list)))\nlist, test_image_list\nimage_list = create_train_test_list(random_38K_food_image_paths)\nlen(test_image_list)\n\ntrain_images, test_images = create_train_test_list(randon_38k_food_image_pa\n\n# Training images\ndef copy_images_to_file(image_list, target_dir): \n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n']"
32840,32844,6,"['ist(set(image_list).difference(set(train_image_list)))\nlist, test_image_list\nimage_list = create_train_test_list(random_38K_food_image_paths)\nlen(test_image_list)\n\ntrain_images, test_images = create_train_test_list(randon_38k_food_image_pa\n\n# Training images\ndef copy_images_to_file(image_list, target_dir): \n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n']","['from shutil import copy2\ntrain_images, test_image\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n']"
32844,32912,0,"['from shutil import copy2\ntrain_images, test_image\n\n# Training images\ndef copy_images_to_file(image_list, target_dir):\n   # target_dir = ""data/train/food_images/""\n   os.makedirs(target_dir, exist_ok=True)\n   for image_path in image_list:\n      image_filename = os.path.split(image_path)[-1]\n      # print(image_filename)\n      dest_path = os.path.join(target_dir, image_filename)\n      print(f""Copying {image_path} to {dest_path}"")\n      copy2(image_path, dest_path)\n']",['']
32912,32928,0,[''],"[""len(train_data), len(test_data)\n\n# Create model\ntf.get_logger().setLevel('INFO')\nmodel = image_classifier.create(train_data)\n""]"
32928,32928,0,"[""len(train_data), len(test_data)\n\n# Create model\ntf.get_logger().setLevel('INFO')\nmodel = image_classifier.create(train_data)\n""]","['train_data_path = ""food—not—food/data/train""\ntest_data_path = ""food-not-food/data/train""\n\nimport os\nclass_names = sorted(os.listdir(train_data_path))\nclass_names\n\n# Create data loader\ntrain_data = Dataloader.from_folder(train_data_path)\ntest_data = Dataloader.from_folder(test_data_path)\n']"
32928,32957,0,"['train_data_path = ""food—not—food/data/train""\ntest_data_path = ""food-not-food/data/train""\n\nimport os\nclass_names = sorted(os.listdir(train_data_path))\nclass_names\n\n# Create data loader\ntrain_data = Dataloader.from_folder(train_data_path)\ntest_data = Dataloader.from_folder(test_data_path)\n']","['# Evaluate the model\nloss, accuracy = model.evaluate(test_data)\n\n# Save the model\nmodel.export(export_dir=""."", tflite_filename=""food_not_food_model_v3.tflite""\n']"
32957,33188,0,"['# Evaluate the model\nloss, accuracy = model.evaluate(test_data)\n\n# Save the model\nmodel.export(export_dir=""."", tflite_filename=""food_not_food_model_v3.tflite""\n']","['   try {\n         const tfliteModel = await tflite.loadTFLiteModel();\n         //\n         https://storage.googleapis.com/food-vision-model-playground/food_not_food_mod\n         el_v1.tflite\n         // ""/food_not_food_model_v1.tflite""\n         ""/food_not_food_model_v2.tflite""\n         // ""/10_whole_foods_model_v0.tflite""\n      }; \n      model = tfliteModel; // assigning it to the global scale model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }  \n\n   // // Prepare input tensors\n   // const img = tf.browswer.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);']"
33188,33205,8,"['   try {\n         const tfliteModel = await tflite.loadTFLiteModel();\n         //\n         https://storage.googleapis.com/food-vision-model-playground/food_not_food_mod\n         el_v1.tflite\n         // ""/food_not_food_model_v1.tflite""\n         ""/food_not_food_model_v2.tflite""\n         // ""/10_whole_foods_model_v0.tflite""\n      }; \n      model = tfliteModel; // assigning it to the global scale model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }  \n\n   // // Prepare input tensors\n   // const img = tf.browswer.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);']","['SR,\n16 const tfliteModel = await tflite.loadTFLiteModel(\nmt 17 /7\nle_foods_model_v0.tiite https://storage.googleapis. com/food-vision-nodel-playground/\nelvi.tflite\nit food’ model v1:tite 18 // ""/food_not_food_model vi.tflite""\nt_food_model_v2.tite 19 ""/food_not_food_model_v2. tflite""\n20 // ""/10_vhole_foods_model_vd. tflite""\nB\n3 2 model = tfliteModel; // assigning it to the global scope model\ncan only be used within this scope\n23 // console.log(tfliteModel);\n24\n25 // Check if model loaded\n2 if (tfliteModel) {\n27 model_status.innerText = “Model loaded"";\n28 ¥\n29} catch (error) {\n30 console. log(error);\n31}\n32\n']"
33205,33213,0,"['SR,\n16 const tfliteModel = await tflite.loadTFLiteModel(\nmt 17 /7\nle_foods_model_v0.tiite https://storage.googleapis. com/food-vision-nodel-playground/\nelvi.tflite\nit food’ model v1:tite 18 // ""/food_not_food_model vi.tflite""\nt_food_model_v2.tite 19 ""/food_not_food_model_v2. tflite""\n20 // ""/10_vhole_foods_model_vd. tflite""\nB\n3 2 model = tfliteModel; // assigning it to the global scope model\ncan only be used within this scope\n23 // console.log(tfliteModel);\n24\n25 // Check if model loaded\n2 if (tfliteModel) {\n27 model_status.innerText = “Model loaded"";\n28 ¥\n29} catch (error) {\n30 console. log(error);\n31}\n32\n']","['   // // Prepare input tensors\n   // const img = tf.browswer.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n']"
33213,33240,28,"['   // // Prepare input tensors\n   // const img = tf.browswer.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);\n\n   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n']","['   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n']"
33240,33294,28,"['   // Run inference and get output tensors\n   // let outputTensor = tfliteModel.predict(input);\n   // console.log(outputTensor.dataSync());\n};\nloadModel();\n\n// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n']","['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      When reader is ready display image\n      reader.onload = function (event) {']"
33294,33371,33,"['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      When reader is ready display image\n      reader.onload = function (event) {']","['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      When reader is ready display image\n      reader.onload = function (event) {']"
33371,33496,25,"['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(output);\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      When reader is ready display image\n      reader.onload = function (event) {']","['   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(output_values..argMax().arraySync());\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n         const dataUrl = event.target.result;\n\n         // Create image object\n         const imageElement = new Image();\n         imageElement.src = dataUrl;']"
33496,33499,31,"['   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(output_values..argMax().arraySync());\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n         const dataUrl = event.target.result;\n\n         // Create image object\n         const imageElement = new Image();\n         imageElement.src = dataUrl;']","['   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(output_values.argMax().arraySync());\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n         const dataUrl = event.target.result;\n\n         // Create image object\n         const imageElement = new Image();\n         imageElement.src = dataUrl;']"
33499,33503,0,"['   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(output_values.argMax().arraySync());\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n         const dataUrl = event.target.result;\n\n         // Create image object\n         const imageElement = new Image();\n         imageElement.src = dataUrl;']",['']
33503,33503,0,[''],['']
33503,33594,0,[''],"['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess iamge\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(""Arg max:"")\n   console.log(output_values.argMax().arraySync());\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n']"
33594,33608,32,"['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess iamge\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(""Arg max:"")\n   console.log(output_values.argMax().arraySync());\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n']","['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   image = tf.cast(image, ""int32"");  // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.sigmoid(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   console.log(output.argMax().arraySync());\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if(fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();']"
33608,33666,32,"['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   image = tf.cast(image, ""int32"");  // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.sigmoid(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   console.log(output.argMax().arraySync());\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if(fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();']","['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(""Arg max:"")\n   console.log(output_values.argMax().arraySync());\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();']"
33666,33685,31,"['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(""Arg max:"")\n   console.log(output_values.argMax().arraySync());\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();']","['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   console.log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32"");  // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);\n   console.log(output_values);\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if(fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();']"
33685,33710,25,"['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to \n   be same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as\n   output thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFliteType(""uint8""));\n   console.log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32"");  // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);\n   console.log(output_values);\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if(fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();']","['   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(""Arg max:"")\n   console.log(output_values.argMax().arraySync());\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n         const dataURL = event.target.result;\n\n         // Create image object']"
33710,33723,28,"['   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.sigmoid(output.arraySync()(0]);\n   console.log(""Arg max:"")\n   console.log(output_values.argMax().arraySync());\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n         const dataURL = event.target.result;\n\n         // Create image object']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = output.arraySync()[0];\n   console.log(""Arg max:"")\n   console.log(output_values.argMax());\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']"
33723,33757,31,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = output.arraySync()[0];\n   console.log(""Arg max:"")\n   console.log(output_values.argMax());\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = output.arraySync()[0];\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']"
33757,33806,0,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = output.arraySync()[0];\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']","['image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image to a batch.\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels\npreds = model.predict_top_k(input_arr, k=2, batch_size=1)\npreds[0]\n']"
33806,33851,0,"['image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr]) # Convert single image to a batch.\ninput_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels\npreds = model.predict_top_k(input_arr, k=2, batch_size=1)\npreds[0]\n']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']"
33851,33884,31,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argmax(output);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']"
33884,33911,32,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argmax(output);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argMax(output);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']"
33911,33917,31,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argMax(output);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL\n ']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argMax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL']"
33917,34118,31,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argMax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argMax(output[0]);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL']"
34118,34159,31,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argMax(output[0]);\n   console.log(""Arg max:"")\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n         // Get data URL']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.argMax(output);\n   console.log(""Arg max:"")\n   // console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n        ']"
34159,34354,30,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   // const output_values = tf.argMax(output);\n   console.log(""Arg max:"")\n   // console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n        ']","['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argMax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   console.log(output);\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   // predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   // predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n']"
34354,34394,32,"['   same as model inputs\n   image = tf.expandDims(image)\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output \n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""Converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.argMax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   console.log(output);\n   console.log(output_values);\n   console.log(""Outputs:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use \n\n   // Update HTML\n   // predicted_class.innerText = classes[output_values.argMax().arraySync()];\n   // predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n   // Image uploading\n   const fileInput = document.getElementById(""file-input"");\n   const image = document.getElementById(""image"");\n\n   function getImage() {\n      if (!fileInput.files[0]) throw new Error(""Image not found"");\n      const file = fileInput.files[0];\n\n      // Get the data url from the image\n      const reader = new FileReader();\n\n      // When reader is ready display image\n      reader.onload = function (event) {\n']","['same as model inputs\nimage = tf.expandins(image)\nconsole. log(image) ;\n// console. log(model);\n\n// console. log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as ou\nthus we cast int32 in below line\n// console.log(tflite.getDTypeFromTFLiteType(""uint8""));\nconsole.log(""converting image to different datatype..."");\nimage = tf.cast(image, ""int32""); // Model requires uint8\nconsole.log(""model about to predict..."");\nconst output = model.predict(image);\nconst output_values = tf.argMax(output.arraySync()[0]).arraySync();\nconsole.log(Arg max:"")\nconsole.log(output);\nconsole.log(output_values);\nconsole.log(""Output:"")\nconsole.log(output.arraySync());\nconsole.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n// Update HTML\n// predicted_class.innerText = classes[output_values.argMax().arraySync()];\n// predicted_prob.innerText = output_values.max().arraySync() % 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n\n   //when reader is ready display image\n   reader.onload = function (event) {\n']"
34394,34424,1,"['same as model inputs\nimage = tf.expandins(image)\nconsole. log(image) ;\n// console. log(model);\n\n// console. log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as ou\nthus we cast int32 in below line\n// console.log(tflite.getDTypeFromTFLiteType(""uint8""));\nconsole.log(""converting image to different datatype..."");\nimage = tf.cast(image, ""int32""); // Model requires uint8\nconsole.log(""model about to predict..."");\nconst output = model.predict(image);\nconst output_values = tf.argMax(output.arraySync()[0]).arraySync();\nconsole.log(Arg max:"")\nconsole.log(output);\nconsole.log(output_values);\nconsole.log(""Output:"")\nconsole.log(output.arraySync());\nconsole.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n// Update HTML\n// predicted_class.innerText = classes[output_values.argMax().arraySync()];\n// predicted_prob.innerText = output_values.max().arraySync() % 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n\n   //when reader is ready display image\n   reader.onload = function (event) {\n']","['const classes = {\n  0: ""food"",\n  1: ""not_food""\n};\n\nconst status = document.getElementById(""status”);\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfis;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async() => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis.com/food-vision-model-playground/food_not_food_mod\n         el_v1.tflite\n         // ""/food_not_food_model_v1.tflite""\n         // ""/food_not_food_model_v3.tflite""\n         https://storage.googleapis. I\n         com/food-vision-model-playground/food_not_food_model_v3.tflite\n      }\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n']"
34424,34618,4,"['const classes = {\n  0: ""food"",\n  1: ""not_food""\n};\n\nconst status = document.getElementById(""status”);\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfis;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async() => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis.com/food-vision-model-playground/food_not_food_mod\n         el_v1.tflite\n         // ""/food_not_food_model_v1.tflite""\n         // ""/food_not_food_model_v3.tflite""\n         https://storage.googleapis. I\n         com/food-vision-model-playground/food_not_food_model_v3.tflite\n      }\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n']","['   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image) ;\n   // console. log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   // console. log(tflite.getDTypeFromTFLiteType(""uints""));\n   console.log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);\n   console.log(output_values);\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]1); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax.arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementByTd(""file-input"");\nconst image = document.getElementByTd(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n']"
34618,34651,31,"['   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image) ;\n   // console. log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   // console. log(tflite.getDTypeFromTFLiteType(""uints""));\n   console.log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);\n   console.log(output_values);\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]1); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes[output_values.argMax.arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementByTd(""file-input"");\nconst image = document.getElementByTd(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n']","['   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image) ;\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   console. log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);\n   console.log(output_values);\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes [output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementByTd(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[e];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n']"
34651,34849,1,"['   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image) ;\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   console. log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);\n   console.log(output_values);\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes [output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementByTd(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[e];\n\n   // Get the data url from the image\n   const reader = new FileReader();\n']","['[\n   {\n      ""origin"": [\n         ""*""\n      ],\n      ""responseHeader"": [\n         ""*"",\n      ],\n      ""method"": [\n         ""GET"",\n         ""POST"",\n         ""HEAD""\n      ],\n      ""maxAgeSeconds"": 3600\n   }\n]\n\n']"
34849,34885,1,"['[\n   {\n      ""origin"": [\n         ""*""\n      ],\n      ""responseHeader"": [\n         ""*"",\n      ],\n      ""method"": [\n         ""GET"",\n         ""POST"",\n         ""HEAD""\n      ],\n      ""maxAgeSeconds"": 3600\n   }\n]\n\n']","['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image) ;\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   console. log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);\n   console.log(output_values);\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes [output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementByTd(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();']"
34885,34926,32,"['// Function to classify image\nfunction classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image) ;\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));\n   console. log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);\n   console.log(output_values);\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class.innerText = classes [output_values.argMax().arraySync()];\n   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementByTd(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[0];\n\n   // Get the data url from the image\n   const reader = new FileReader();']","['function classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);|\n   console.log(output_values.arraySync());\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class. textContent = classes [output_values.argMax().arraySync()];\n   predicted_prob.textContent = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[el;\n\n   // Get the data url from the image\n   const reader = new FileReader();\n']"
34926,35040,1,"['function classifyImage(model, image) {\n   // Preprocess image\n   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be\n   same as model inputs\n   image = tf.expandDims(image);\n   console.log(image);\n   // console.log(model);\n\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output\n   thus we cast int32 in below line\n   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));\n   console.log(""converting image to different datatype..."");\n   image = tf.cast(image, ""int32""); // Model requires uint8\n   console.log(""model about to predict..."");\n   const output = model.predict(image);\n   const output_values = tf.softmax(output.arraySync()[0]);\n   console.log(""Arg max:"")\n   // console.log(output);|\n   console.log(output_values.arraySync());\n   console.log(""Output:"")\n   console.log(output.arraySync());\n   console.log(output.arraySync()[0]); // arraySync() Returns an array to use\n\n   // Update HTML\n   predicted_class. textContent = classes [output_values.argMax().arraySync()];\n   predicted_prob.textContent = output_values.max().arraySync() * 100 + ""%"";\n}\n\n// Image uploading\nconst fileInput = document.getElementById(""file-input"");\nconst image = document.getElementById(""image"");\n\nfunction getImage() {\n   if (!fileInput.files[0]) throw new Error(""Image not found"");\n   const file = fileInput.files[el;\n\n   // Get the data url from the image\n   const reader = new FileReader();\n']","['const classes = {\n   0: ""food"",\n   1: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod\n         el vl.tflite\n         // ""/food_not_food_model_v1.tflite""\n         // ""/food_not_food_model_v3.tflite""\n         ""https://storage.googleapis.\n         con/food-vis ion-model-playground/food_not_food_model_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n// // Prepare input tensors\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));']"
35040,35060,32,"['const classes = {\n   0: ""food"",\n   1: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod\n         el vl.tflite\n         // ""/food_not_food_model_v1.tflite""\n         // ""/food_not_food_model_v3.tflite""\n         ""https://storage.googleapis.\n         con/food-vis ion-model-playground/food_not_food_model_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n// // Prepare input tensors\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));']","['const classes = {\n   0: ""food"",\n   1: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod\n         el vl.tflite\n         // ""/food_not_food_model_v1.tflite""\n         // ""/food_not_food_model_v3.tflite""\n         ""https://storage.googleapis.\n         con/food-vis ion-model-playground/food_not_food_model_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n// // Prepare input tensors\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n']"
35060,35290,0,"['const classes = {\n   0: ""food"",\n   1: ""not_food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod\n         el vl.tflite\n         // ""/food_not_food_model_v1.tflite""\n         // ""/food_not_food_model_v3.tflite""\n         ""https://storage.googleapis.\n         con/food-vis ion-model-playground/food_not_food_model_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n// // Prepare input tensors\n// const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n']","['   <br>\n   <p>This line below will say loaded if the model is loaded:</p>\n   <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n   <!— Upload image —>\n   <br>\n   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n   <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input"" /></p>\n   <p><img id=""image"" width=""200"" /></p>\n\n   <p>Predicted class:</p>\n   <p id=""predicted_class""></p>\n   <p>Predicted probability:</p>\n   <p id=""predicted_prob""></p>\n\n   <script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js""\n   type=""text/javascript""></script> |\n<script\nsrc=""https://cdn. jsdelivr.net/npm/@tensorflow/tfjs—tflite@d.0.1-alpha.7/dist/tf-t\nflite.min.js""></script>\n\n   <script src=""script.js""></script>\n</body>\n</html>\n\n']"
35290,35332,0,"['   <br>\n   <p>This line below will say loaded if the model is loaded:</p>\n   <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n   <!— Upload image —>\n   <br>\n   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n   <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input"" /></p>\n   <p><img id=""image"" width=""200"" /></p>\n\n   <p>Predicted class:</p>\n   <p id=""predicted_class""></p>\n   <p>Predicted probability:</p>\n   <p id=""predicted_prob""></p>\n\n   <script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js""\n   type=""text/javascript""></script> |\n<script\nsrc=""https://cdn. jsdelivr.net/npm/@tensorflow/tfjs—tflite@d.0.1-alpha.7/dist/tf-t\nflite.min.js""></script>\n\n   <script src=""script.js""></script>\n</body>\n</html>\n\n']","['const classes = {\n   0: ""food"",\n   1: ""non-food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod\n         el_v1.tflite\n         //""/food_not_food_model_v1.tflite""\n         ""/food_not_food_model_v3.tflite""\n         //\n         ""https://storage.googleapis. com/food-vision-model-playground/food_not_food_mo\n         del_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status. innerText = “Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors\n']"
35332,35485,28,"['const classes = {\n   0: ""food"",\n   1: ""non-food""\n};\n\nconst status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         //\n         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod\n         el_v1.tflite\n         //""/food_not_food_model_v1.tflite""\n         ""/food_not_food_model_v3.tflite""\n         //\n         ""https://storage.googleapis. com/food-vision-model-playground/food_not_food_mo\n         del_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel\n      can only be used within this scope\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status. innerText = “Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // // Prepare input tensors\n']","['const status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         ""https://storage.googleapis.\n         com/food-vision-models-test/10_whole_foods_model_v@.tflite""\n         //\n         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod\n         el_v1.tflite\n         // ""/food_not_food_model_v1.tflite""\n\n         // ""/food_not_food_model_v3.tflite""|\n         //\n         ""https://storage.googleapis. con/food-vision-model-playground/food_not_food_mo\n         del_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tflitelodel\n      can only be used within this scope\n      // console.log(tflitetodel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127,5), 1);\n']"
35485,35911,0,"['const status = document.getElementById(""status"");\n\nif (status) {\n   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n}\n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         ""https://storage.googleapis.\n         com/food-vision-models-test/10_whole_foods_model_v@.tflite""\n         //\n         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod\n         el_v1.tflite\n         // ""/food_not_food_model_v1.tflite""\n\n         // ""/food_not_food_model_v3.tflite""|\n         //\n         ""https://storage.googleapis. con/food-vision-model-playground/food_not_food_mo\n         del_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tflitelodel\n      can only be used within this scope\n      // console.log(tflitetodel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n         model_status.innerText = ""Model loaded"";\n      }\n   } catch (error) {\n      console.log(error);\n   }\n\n   // Prepare input tensors.\n   // const img = tf.browser.fromPixels(document.querySelector(\'img\'));\n   // const input = tf.sub(tf.div(tf.expandDims(img), 127,5), 1);\n']","['   <title>Hello World - TensorFlow.js</title>\n   <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n</head>\n\n<body>\n   <h1>Food Not Food (£ or 89)</h1>\n   <p>This app will tell you if the image you upload is food or not.</p>\n   <p>Yes. That\'s it. </p>\n   <p>It\'1l use a computer vision machine learning model to classify your image as ""food"" or ""not food"".</p>\n   <br>\n   <p>The line below will say loaded if TensorFlow.js is loaded:</p>\n   <p id=""tfjs_status"">Awaiting TF.js load</p>\n\n   <br>\n   <p>This line below will say loaded if the model is loaded:</p>\n   <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n   <!— Upload image —>\n   <br>\n   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n']"
35911,36117,0,"['   <title>Hello World - TensorFlow.js</title>\n   <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />\n</head>\n\n<body>\n   <h1>Food Not Food (£ or 89)</h1>\n   <p>This app will tell you if the image you upload is food or not.</p>\n   <p>Yes. That\'s it. </p>\n   <p>It\'1l use a computer vision machine learning model to classify your image as ""food"" or ""not food"".</p>\n   <br>\n   <p>The line below will say loaded if TensorFlow.js is loaded:</p>\n   <p id=""tfjs_status"">Awaiting TF.js load</p>\n\n   <br>\n   <p>This line below will say loaded if the model is loaded:</p>\n   <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>\n\n   <!— Upload image —>\n   <br>\n   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>\n']","['{\n   {\n      ""origin"": [\n         ""https://food-not-food.vercel.app/""\n      ],\n      ""responseHeader"": [\n         ""*""\n      ],\n      ""method"": [\n         ""GET"",\n         ""POST"",\n         ""HEAD""\n      ],\n      ""maxAgeSeconds"": 3600\n   }\n}\n']"
36117,36162,2,"['{\n   {\n      ""origin"": [\n         ""https://food-not-food.vercel.app/""\n      ],\n      ""responseHeader"": [\n         ""*""\n      ],\n      ""method"": [\n         ""GET"",\n         ""POST"",\n         ""HEAD""\n      ],\n      ""maxAgeSeconds"": 3600\n   }\n}\n']","['   tfjs_status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;\n} \n\nlet model; // This is in global scope\n\nconst loadModel = async () => {\n   try {\n      const tfliteModel = await tflite.loadTFLiteModel(\n         // ""https://storage.googleapis.com/food-vision-models—test/10_whole_foods_model_vO.tflite""\n         // https://storage.googleapis.com/food-vision-model-playground/food_not_food_model_v1.tflite\n         // ""/food_not_food_model_v1.tflite""\n\n         // ""/food_not_food_model_v3.tflite""\n         ""https://storage.googleapis.com/food-vision-model-playground/food_not_food_model_v3.tflite""\n      );\n      model = tfliteModel; // assigning it to the global scope model as tfliteModel can only be used within this scop\n      // console.log(tfliteModel);\n\n      // Check if model loaded\n      if (tfliteModel) {\n']"
