eventID,videoID,timed_url,time,img_file,text_file,notes,code_text,coords
1,2,https://www.youtube.com/watch?t=11599&v=W5XNOmyJr6I,11599,screencapture-localhost-8000-2022-01-24-10_17_50.png,,code: data_exploration; tries just copying in the raw string again.,,675;226;421;130
8,2,https://www.youtube.com/watch?t=635&v=W5XNOmyJr6I,635,screencapture-localhost-8000-2022-01-19-14_47_05.png,,"git: add hotdog image; he hasn't really started yet, this is just a repo setup",,
9,2,https://www.youtube.com/watch?t=1333&v=W5XNOmyJr6I,1333,screencapture-localhost-8000-2022-01-20-11_26_30.png,,"goal: ""random images from imagenet for not food, random images from food101 for food""; This is pretty high level, but he transitions into starting to work on this quickly after this point",,
10,2,https://www.youtube.com/watch?t=1365&v=W5XNOmyJr6I,1365,screencapture-localhost-8000-2022-01-20-11_29_10.png,,"search: ""imagenet data downloader""; he's got this search pre-done and is returning to it. happened before the video started.",,
11,2,https://www.youtube.com/watch?t=1372&v=W5XNOmyJr6I,1372,screencapture-localhost-8000-2022-01-20-11_30_58.png,,"visit: imagenet downloader; ""this is what we want""",,
12,2,https://www.youtube.com/watch?t=1413&v=W5XNOmyJr6I,1413,screencapture-localhost-8000-2022-01-20-11_32_37.png,,"search: imagenet class list; downloader page talks about getting images from different classes. goal is to get not food, classes may play into that (my inference)",,
13,2,https://www.youtube.com/watch?t=1416&v=W5XNOmyJr6I,1416,screencapture-localhost-8000-2022-01-20-11_33_57.png,,visit: imagenet class labels; the goal here is to find out how many of these correspond to food,,
14,2,https://www.youtube.com/watch?t=1416&v=W5XNOmyJr6I,1416,screencapture-localhost-8000-2022-01-20-11_33_57.png,,"goal: ""how many of these are food?""; looking at the class labels",,
15,2,https://www.youtube.com/watch?t=1485&v=W5XNOmyJr6I,1485,screencapture-localhost-8000-2022-01-20-11_38_12.png,,visit: raw imagenet class labels list; intending to use this list to select classes,,
16,2,https://www.youtube.com/watch?t=1485&v=W5XNOmyJr6I,1485,screencapture-localhost-8000-2022-01-20-11_38_12.png,,"goal: ""how about we do some data processing on this?""; he presents a plan of downloading this list, selecting a large set of classes and then removing the food-related ones. He's also done some searching for food related words, perhaps to get a sense of where food might show up in the database - example keywords ""food, fruit, banana, apple""",,
17,2,https://www.youtube.com/watch?t=1551&v=W5XNOmyJr6I,1551,screencapture-localhost-8000-2022-01-20-12_43_00.png,,revisit: imagenet class list; wants to download the class list,,
18,2,https://www.youtube.com/watch?t=1555&v=W5XNOmyJr6I,1555,screencapture-localhost-8000-2022-01-20-12_43_50.png,,visit: imagenet class list download zip; downloading,,
19,2,https://www.youtube.com/watch?t=1696&v=W5XNOmyJr6I,1696,screencapture-localhost-8000-2022-01-20-12_46_44.png,,"git: ""add imagenet classes""; he's doing some via a ""deep learning"" machine that he's remoted into; I think here he's using git to transfer the file from one machine to the other.",,
20,2,https://www.youtube.com/watch?t=1721&v=W5XNOmyJr6I,1721,screencapture-localhost-8000-2022-01-20-12_49_22.png,,"goal: ""we want to write some python code. we want to get all of the classes in here that are not food""",,
21,2,https://www.youtube.com/watch?t=1831&v=W5XNOmyJr6I,1831,screencapture-localhost-8000-2022-01-20-13_03_52.png,,code: data_exploration; added imports,"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import csv
",675;226;421;130
22,2,https://www.youtube.com/watch?t=1831&v=W5XNOmyJr6I,1831,screencapture-localhost-8000-2022-01-20-13_03_52.png,,"run: testing imports, they worked",,
23,2,https://www.youtube.com/watch?t=1893&v=W5XNOmyJr6I,1893,screencapture-localhost-8000-2022-01-20-13_08_06.png,,code: data_exploration; read the data from imagenet classes file and append to an array.,"imagenet_classes = []
with open(""imagenet1000_clsidx_to_labels.txt"", “rb"") as f:
   imagenet_classes.append(f.readlines())
",666;263;649;106
24,2,https://www.youtube.com/watch?t=1908&v=W5XNOmyJr6I,1908,screencapture-localhost-8000-2022-01-20-13_10_33.png,,"run: testing reading from the file; seems to work, array is defined",,
25,2,https://www.youtube.com/watch?t=1914&v=W5XNOmyJr6I,1914,screencapture-localhost-8000-2022-01-20-13_12_29.png,,"goal: "" we don't necessarily want that...we want each one as a line""; currently output is structured as an object.",,
26,2,https://www.youtube.com/watch?t=1897&v=W5XNOmyJr6I,1897,screencapture-localhost-8000-2022-01-20-13_29_35.png,,output: listing of imagenet classes; he evaluated imagenet_classes,,
27,2,https://www.youtube.com/watch?t=1901&v=W5XNOmyJr6I,1901,screencapture-localhost-8000-2022-01-20-13_31_01.png,,"code: data_exploration; ""maybe we don't want to read it as bytes""","imagenet_classes = []
with open(""imagenet1000_clsidx_to_labels.txt"", ""r"") as f:
   imagenet_classes.append(f.readlines())

imagenet_classes
",660;263;658;229
29,2,https://www.youtube.com/watch?t=1908&v=W5XNOmyJr6I,1908,screencapture-localhost-8000-2022-01-20-13_34_12.png,,output: now imagenet classes aren't in byte form,,
30,2,https://www.youtube.com/watch?t=1928&v=W5XNOmyJr6I,1928,screencapture-localhost-8000-2022-01-20-13_35_50.png,,code: data_exploration; assign the output directly rather than appending results of readLines.,"with open(""imagenet1000_clsidx_to_labels.txt"", “r"") as f:
   imagenet_classes = f.readlines()

imagenet_classes
",660;293;667;199
31,2,https://www.youtube.com/watch?t=1929&v=W5XNOmyJr6I,1929,screencapture-localhost-8000-2022-01-20-13_36_52.png,,output: listing of imagenet classes,,
32,2,https://www.youtube.com/watch?t=1951&v=W5XNOmyJr6I,1951,screencapture-localhost-8000-2022-01-20-13_37_49.png,,"goal: ""there's a better way to do this""",,
33,2,https://www.youtube.com/watch?t=1951&v=W5XNOmyJr6I,1951,screencapture-localhost-8000-2022-01-20-13_37_49.png,,search: python how to read a dictionary from txt; search is tied to previous goal statement,,
34,2,https://www.youtube.com/watch?t=1957&v=W5XNOmyJr6I,1957,screencapture-localhost-8000-2022-01-20-13_39_12.png,,"visit: how to read a dictionary from a file in Python; ""dictionary from a file""",,
35,2,https://www.youtube.com/watch?t=1976&v=W5XNOmyJr6I,1976,screencapture-localhost-8000-2022-01-20-13_40_16.png,,"visit: literal_eval (method docs); ""is this in the python standard library?""",,
36,2,https://www.youtube.com/watch?t=1982&v=W5XNOmyJr6I,1982,screencapture-localhost-8000-2022-01-20-13_41_04.png,,"revisit: how to read a dictionary from a file in Python; ""ok, we just want read""",,
37,2,https://www.youtube.com/watch?t=1993&v=W5XNOmyJr6I,1993,screencapture-localhost-8000-2022-01-20-13_41_54.png,,revisit: how to read a dictionary from a file in Python; he's copying the literal_eval method call,,
38,2,https://www.youtube.com/watch?t=2009&v=W5XNOmyJr6I,2009,screencapture-localhost-8000-2022-01-20-13_56_38.png,,code: data_exploration; added import of ast and literal_eval method call,"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import csv
import ast

with open(""imagenet1000_clsidx_to_labels.txt"", ""r"") as f:
   imagenet_classes = ast.literal_eval(f.read())

imagenet_classes
",531;241;664;416
39,2,https://www.youtube.com/watch?t=2013&v=W5XNOmyJr6I,2013,screencapture-localhost-8000-2022-01-20-13_57_44.png,,"output: ""ok beautiful we've got a.."" listing of the classnames in dictionary form",,
40,2,https://www.youtube.com/watch?t=2090&v=W5XNOmyJr6I,2090,screencapture-localhost-8000-2022-01-20-14_00_08.png,,"goal: ""how do we edit a dictionary?...let's loop through this""",,
41,2,https://www.youtube.com/watch?t=2120&v=W5XNOmyJr6I,2120,screencapture-localhost-8000-2022-01-20-14_01_16.png,,code: data_exploration; looping through class items and looking for descriptors that contain banana.,"for k, v in imagenet_classes.items():
   if v.contains(""banana""):|
      print(k)
",534;398;430;103
42,2,https://www.youtube.com/watch?t=2120&v=W5XNOmyJr6I,2120,screencapture-localhost-8000-2022-01-20-14_01_16.png,,"output: 'str' object has no attribute ""contains""",,
43,2,https://www.youtube.com/watch?t=2120&v=W5XNOmyJr6I,2120,screencapture-localhost-8000-2022-01-20-14_01_16.png,,"output: ""str"" object has no attribute ""contains""",,
44,2,https://www.youtube.com/watch?t=2132&v=W5XNOmyJr6I,2132,screencapture-localhost-8000-2022-01-20-14_05_08.png,,search: python check if string contains string; in response to error about non-existent contains method,,
45,2,https://www.youtube.com/watch?t=2142&v=W5XNOmyJr6I,2142,screencapture-localhost-8000-2022-01-20-14_06_18.png,,"visit: does python have a string ""contains"" substring method?;",,
46,2,https://www.youtube.com/watch?t=2157&v=W5XNOmyJr6I,2157,screencapture-localhost-8000-2022-01-20-15_08_08.png,,"code: data_exploration; changed to if ""banana"" in v","for k, v in imagenet_classes.items():
   if ""banana"" in v:
      print(k)
",549;404;436;97
47,2,https://www.youtube.com/watch?t=2160&v=W5XNOmyJr6I,2160,screencapture-localhost-8000-2022-01-20-15_09_08.png,,output: 954; 954 ok. so banana is in the 954th class.,,
48,2,https://www.youtube.com/watch?t=2169&v=W5XNOmyJr6I,2169,screencapture-localhost-8000-2022-01-20-15_10_12.png,,search: imagenet food classes; I think that he's looking for a list of food words that he can use to filter the list,,
49,2,https://www.youtube.com/watch?t=2183&v=W5XNOmyJr6I,2183,screencapture-localhost-8000-2022-01-20-15_15_15.png,,"visit: food image classification; ""no way"" this is a medium article done by someone who has basically done this same problem",,
50,2,https://www.youtube.com/watch?t=2318&v=W5XNOmyJr6I,2318,screencapture-localhost-8000-2022-01-20-15_18_38.png,,search: python list of common eaten foods; he's looking for a way to get food based keywords,,
51,2,https://www.youtube.com/watch?t=2322&v=W5XNOmyJr6I,2322,screencapture-localhost-8000-2022-01-21-10_01_46.png,,visit: wikipedia list of common eaten foods; top link,,
52,2,https://www.youtube.com/watch?t=2328&v=W5XNOmyJr6I,2328,screencapture-localhost-8000-2022-01-21-10_02_48.png,,"search: python list of commonly eaten foods; ""nope"" on wikipedia page.",,
53,2,https://www.youtube.com/watch?t=2364&v=W5XNOmyJr6I,2364,screencapture-localhost-8000-2022-01-21-10_06_09.png,,"visit: stackoverflow question - list of common foods; ""here we go""",,
54,2,https://www.youtube.com/watch?t=2417&v=W5XNOmyJr6I,2417,screencapture-localhost-8000-2022-01-21-10_07_50.png,,"visit: usda foods list; ""this is beautiful, we're just going to combine a bunch of data here""",,
55,2,https://www.youtube.com/watch?t=2430&v=W5XNOmyJr6I,2430,screencapture-localhost-8000-2022-01-21-10_09_58.png,,visit: usda food data central;,,
56,2,https://www.youtube.com/watch?t=2446&v=W5XNOmyJr6I,2446,screencapture-localhost-8000-2022-01-21-10_10_43.png,,revisit: stackoverflow question - list of common foods;,,
57,2,https://www.youtube.com/watch?t=2446&v=W5XNOmyJr6I,2446,screencapture-localhost-8000-2022-01-21-10_10_43.png,,"goal: ""let's try the nltk first and then we'll come back""",,
58,2,https://www.youtube.com/watch?t=2457&v=W5XNOmyJr6I,2457,screencapture-localhost-8000-2022-01-21-10_25_25.png,,search: wordnet subset downloader; this is based on the words around the nltk example,,
59,2,https://www.youtube.com/watch?t=2505&v=W5XNOmyJr6I,2505,screencapture-localhost-8000-2022-01-21-10_27_03.png,,visit: stack overflow - what does nltk download 'wordnet' accomplish?;,,
60,2,https://www.youtube.com/watch?t=2525&v=W5XNOmyJr6I,2525,screencapture-localhost-8000-2022-01-21-10_28_08.png,,visit: nltk documentation; he's skimmed the stack overflow download explanations,,
61,2,https://www.youtube.com/watch?t=2525&v=W5XNOmyJr6I,2525,screencapture-localhost-8000-2022-01-21-10_28_08.png,,"goal: ""so let's install nltk""",,
62,2,https://www.youtube.com/watch?t=2565&v=W5XNOmyJr6I,2565,screencapture-localhost-8000-2022-01-21-10_29_58.png,,"goal: ""let's try this out. let's install nltk""",,
63,2,https://www.youtube.com/watch?t=2577&v=W5XNOmyJr6I,2577,screencapture-localhost-8000-2022-01-21-10_33_37.png,,"visit: installing nltk; ""what's the recommended...""",,
64,2,https://www.youtube.com/watch?t=2603&v=W5XNOmyJr6I,2603,screencapture-localhost-8000-2022-01-21-10_34_54.png,,"goal: ""so we need to install nltk""; he's perused the page and has highlighted the pip installation instructions",,
65,2,https://www.youtube.com/watch?t=2622&v=W5XNOmyJr6I,2622,screencapture-localhost-8000-2022-01-21-10_36_21.png,,"goal: ""and we're going to download....""; after installing the library you need to download the datasets to work with, which is essentially step 2 of installation",,
66,2,https://www.youtube.com/watch?t=2675&v=W5XNOmyJr6I,2675,screencapture-localhost-8000-2022-01-21-10_38_46.png,,"other: he's recording notes about the process in the notes file as he goes, which seems related to the code story.",,
67,2,https://www.youtube.com/watch?t=2707&v=W5XNOmyJr6I,2707,screencapture-localhost-8000-2022-01-21-11_19_06.png,,revisit: stackoverflow question - list of common foods; copying the nltk example code.,,
68,2,https://www.youtube.com/watch?t=2707&v=W5XNOmyJr6I,2707,screencapture-localhost-8000-2022-01-21-11_19_06.png,,"goal: ""let's now figure out what this does""",,
69,2,https://www.youtube.com/watch?t=2751&v=W5XNOmyJr6I,2751,screencapture-localhost-8000-2022-01-21-11_21_31.png,,code: data_exploration; copies in the nltk code,"from nltk.corpus import wordnet as wn
food = wn.synset('food.n.02"")
list(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))
",531;506;928;106
70,2,https://www.youtube.com/watch?t=2751&v=W5XNOmyJr6I,2751,screencapture-localhost-8000-2022-01-21-11_21_31.png,,output: squiggly line under ntlk call; leads him to conclude he needs to import.,,
71,2,https://www.youtube.com/watch?t=2744&v=W5XNOmyJr6I,2744,screencapture-localhost-8000-2022-01-21-11_29_01.png,,code: data_exploration; adds nltk import,"import nltk
",531;341;193;58
72,2,https://www.youtube.com/watch?t=2744&v=W5XNOmyJr6I,2744,screencapture-localhost-8000-2022-01-21-11_29_01.png,,output: error on importing nltk,,
73,2,https://www.youtube.com/watch?t=2760&v=W5XNOmyJr6I,2760,screencapture-localhost-8000-2022-01-21-11_29_01.png,,"goal: ""we're going to have to do some environment refreshing""; I assume he thinks that since it's installed, it may just be that the IDE hasn't realized it's there yet",,
74,2,https://www.youtube.com/watch?t=2806&v=W5XNOmyJr6I,2806,screencapture-localhost-8000-2022-01-21-11_32_42.png,,"search: conda how to install in current env with pip; ntlk not in installed packages, but lists as installed when he tries to re-install. is available as a site package.",,
75,2,https://www.youtube.com/watch?t=2808&v=W5XNOmyJr6I,2808,screencapture-localhost-8000-2022-01-21-11_35_12.png,,visit: stackoverflow - using pip to install packages to Anaconda environment;,,
76,2,https://www.youtube.com/watch?t=2824&v=W5XNOmyJr6I,2824,screencapture-localhost-8000-2022-01-21-11_36_32.png,,"goal: ""conda install pip - that's what I need""",,
77,2,https://www.youtube.com/watch?t=2907&v=W5XNOmyJr6I,2907,screencapture-localhost-8000-2022-01-21-11_38_58.png,,"output: ""no module nltk""; ""classic""",,
78,2,https://www.youtube.com/watch?t=2942&v=W5XNOmyJr6I,2942,screencapture-localhost-8000-2022-01-21-11_40_05.png,,"output: nltk now imports; ""oh I had to restart the kernel""",,
79,2,https://www.youtube.com/watch?t=3003&v=W5XNOmyJr6I,3003,screencapture-localhost-8000-2022-01-21-11_41_36.png,,"output: list of foods; ""Oh look at this, we have a list of foods. This is wonderful""",,
80,2,https://www.youtube.com/watch?t=3028&v=W5XNOmyJr6I,3028,screencapture-localhost-8000-2022-01-21-11_42_42.png,,code: data_exploration; made a variable to save the returned food list.,"import nltk

from nltk.corpus import wordnet as wn
food = wn.synset('food.n.02')
food_list = list(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))

food_list
",540;191;1039;338
81,2,https://www.youtube.com/watch?t=3072&v=W5XNOmyJr6I,3072,screencapture-localhost-8000-2022-01-21-11_45_47.png,,"other: ""got a list of foods"" - updates the notes file.",,
82,2,https://www.youtube.com/watch?t=3089&v=W5XNOmyJr6I,3089,screencapture-localhost-8000-2022-01-21-11_46_36.png,,"goal: from notes: ""..filter imagenet data classes and remove any class that contains a food""",,
83,2,https://www.youtube.com/watch?t=3148&v=W5XNOmyJr6I,3148,screencapture-localhost-8000-2022-01-21-11_48_44.png,,"goal: ""let's strip the strings from here, make everything lower case, and remove punctuation""; I've paraphrased a bit. He's referring to the imagenet class descriptions now and I think will then take those words and look for them ""in"" the list of foods.",,
84,2,https://www.youtube.com/watch?t=3291&v=W5XNOmyJr6I,3291,screencapture-localhost-8000-2022-01-21-13_05_03.png,,"code: data_exploration; initial code to lower case and attempt to remove ""_"" with incorrect method","for food_item in food_list:
   print((food_item.lower().strip(""_"")) .
",540;332;445;79
85,2,https://www.youtube.com/watch?t=3291&v=W5XNOmyJr6I,3291,screencapture-localhost-8000-2022-01-21-13_05_03.png,,output: the food list still contains _ so strip did not do what he hoped.,,
87,2,https://www.youtube.com/watch?t=3376&v=W5XNOmyJr6I,3376,screencapture-localhost-8000-2022-01-21-13_07_56.png,,output: food names split into sub arrays,,
88,2,https://www.youtube.com/watch?t=3420&v=W5XNOmyJr6I,3420,screencapture-localhost-8000-2022-01-21-13_09_57.png,,code: data_exploration; re-writes loop in a syntax I'm not familiar with,"# Remove punctuation and lower
food_list = [food_item.lower().split(""_"") for food_item in food_list]
food_list
",537;241;751;88
89,2,https://www.youtube.com/watch?t=3420&v=W5XNOmyJr6I,3420,screencapture-localhost-8000-2022-01-21-13_09_57.png,,output: behavior still the same -subarrays after splitting on _,,
90,2,https://www.youtube.com/watch?t=3458&v=W5XNOmyJr6I,3458,screencapture-localhost-8000-2022-01-21-13_11_42.png,,code: data_exploration; not totally sure what he's trying to do here.,"# Remove punctuation and lower
food_list = [food for sublist in food_item.lower().split(""_"") for food_item in food_list]
food_list
",537;386;973;91
91,2,https://www.youtube.com/watch?t=3458&v=W5XNOmyJr6I,3458,screencapture-localhost-8000-2022-01-21-13_11_42.png,,output: doesn't work,,
92,2,https://www.youtube.com/watch?t=3493&v=W5XNOmyJr6I,3493,screencapture-localhost-8000-2022-01-21-13_17_16.png,,"search: python create a list from list of lists; ""I always get this mixed up""",,
93,2,https://www.youtube.com/watch?t=3495&v=W5XNOmyJr6I,3495,screencapture-localhost-8000-2022-01-21-13_21_02.png,,"visit: stackoverflow how to make a flat list out of a list of lists; he's looking up the syntax to flatten his split lists into a single list. (which I'm not sure is a good idea, but...)",,
94,2,https://www.youtube.com/watch?t=3612&v=W5XNOmyJr6I,3612,screencapture-localhost-8000-2022-01-21-13_24_19.png,,code: data_exploration; flatten list attempt with example copied and commented above,"# flat_list = [item for sublist in t for item in sublist] 
flat_food_list = [food for food_sub_list in food_list for food in food_sub_list]
flat_food_list
",537;377;877;100
95,2,https://www.youtube.com/watch?t=3612&v=W5XNOmyJr6I,3612,screencapture-localhost-8000-2022-01-21-13_24_19.png,,"output: flat list; ""did we make it? we made it""",,
96,2,https://www.youtube.com/watch?t=3625&v=W5XNOmyJr6I,3625,screencapture-localhost-8000-2022-01-21-13_25_34.png,,goal: we've got a list of flat foods. now let's do the same for imagenet.,,
97,2,https://www.youtube.com/watch?t=3703&v=W5XNOmyJr6I,3703,screencapture-localhost-8000-2022-01-21-13_27_39.png,,code: data_exploration; trying to do the same for the imagenet ones - iterate through and lower them then is searching for them in food list. doesn't work because they aren't clean strings yet.,"for k, v in imagenet_classes:
   if v.lower() in flat_food_list:
      print(k)
",537;383;421;100
98,2,https://www.youtube.com/watch?t=3706&v=W5XNOmyJr6I,3706,screencapture-localhost-8000-2022-01-21-13_29_19.png,,output: can't unpack non-iterable int object; doesn't work,,
99,2,https://www.youtube.com/watch?t=3711&v=W5XNOmyJr6I,3711,screencapture-localhost-8000-2022-01-21-13_31_27.png,,"code: data_exploration; ""oh we need items""","for k, v in imagenet_classes.items():
   if v.lower() in flat_food_list:
      print(k)
",540;380;412;94
100,2,https://www.youtube.com/watch?t=3711&v=W5XNOmyJr6I,3711,screencapture-localhost-8000-2022-01-21-13_31_27.png,,"output: a list of indices for classes with food in them; ""hey there we go!""",,
101,2,https://www.youtube.com/watch?t=3795&v=W5XNOmyJr6I,3795,screencapture-localhost-8000-2022-01-21-13_47_24.png,,code: data_exploration; lowering and splitting the class entries.,"# Check ImageNet classes for foods
for k, v in imagenet_classes.items():
   print(v.lower().split("",""))
   if v.lower() in flat_food_list:
      print(k, v)

",540;326;424;151
102,2,https://www.youtube.com/watch?t=3795&v=W5XNOmyJr6I,3795,screencapture-localhost-8000-2022-01-21-13_47_24.png,,"output: lower case, and now have sub-arrays.",,
103,2,https://www.youtube.com/watch?t=3803&v=W5XNOmyJr6I,3803,screencapture-localhost-8000-2022-01-21-13_47_24.png,,"goal: ""I want the items from the list""",,
104,2,https://www.youtube.com/watch?t=3821&v=W5XNOmyJr6I,3821,screencapture-localhost-8000-2022-01-21-13_49_44.png,,code: data_exploration; maybe we can do a straight up comparison,"# Check ImageNet classes for foods
for k, v in imagenet_classes.items():
   print(v.lower().split("",""))
   if v.lower().split("","") in flat_food_list:
      print(k, v)
",531;473;517;151
105,2,https://www.youtube.com/watch?t=3821&v=W5XNOmyJr6I,3821,screencapture-localhost-8000-2022-01-21-13_49_44.png,,output: no that did not work,,
106,2,https://www.youtube.com/watch?t=4078&v=W5XNOmyJr6I,4078,screencapture-localhost-8000-2022-01-21-14_02_28.png,,search: get items from a list; it seems to have added python to it for him in that the results are all python based.,,
107,2,https://www.youtube.com/watch?t=4193&v=W5XNOmyJr6I,4193,screencapture-localhost-8000-2022-01-21-14_05_14.png,,code: data_exploration; trying to find a clever way to determine whether the array of strings is in the list of foods.,"[""string_1"", ""string_2""] in ""string_ 1""
",543;395;439;58
108,2,https://www.youtube.com/watch?t=4193&v=W5XNOmyJr6I,4193,screencapture-localhost-8000-2022-01-21-14_05_14.png,,output: list in list comparison does not work,,
109,2,https://www.youtube.com/watch?t=4175&v=W5XNOmyJr6I,4175,screencapture-localhost-8000-2022-01-21-14_06_48.png,,"goal: ""we want to extract those strings""",,
110,2,https://www.youtube.com/watch?t=4273&v=W5XNOmyJr6I,4273,screencapture-localhost-8000-2022-01-21-14_09_19.png,,code: data_exploration; commented strategy in pseudocode. trying to strip out spaces on array.,"# Check ImageNet classes for foods

# Look at imagenet classes

for k, v in imagenet_classes.items():
   # Get value from imagenet classes (string)
   print(v.lower().split("","").strip("" ""))
   # See if value appears s flat_food_list
   if v.lower().split("","") in flat_food_list:
      print(k,v)
",531;275;553;244
111,2,https://www.youtube.com/watch?t=4274&v=W5XNOmyJr6I,4274,screencapture-localhost-8000-2022-01-21-14_09_19.png,,output: list object has no attribute strip; can't use strip on the list of strings.,,
113,2,https://www.youtube.com/watch?t=4354&v=W5XNOmyJr6I,4354,screencapture-localhost-8000-2022-01-21-14_42_55.png,,output: does remove whitespace,"# Check ImageNet classes for foods

# Look at imagenet classes
for k, v in imagenet_classes.items():
   # Get value from imagenet classes (string)
   # print(v.lower().split("",""))
   print([space_word.strip("" "") for space_word in v.lower().split("","")])
   # See if value appears in flat_food_list
   if v.lower().split("","") in flat_food_list:
      print(k, v)
",540;257;796;284
114,2,https://www.youtube.com/watch?t=4354&v=W5XNOmyJr6I,4354,screencapture-localhost-8000-2022-01-21-14_42_55.png,,"goal: ""ok now we've got a way to do that, we can turn that into a set""",,
115,2,https://www.youtube.com/watch?t=4409&v=W5XNOmyJr6I,4409,screencapture-localhost-8000-2022-01-21-14_45_43.png,,code: data_exploration; trying out set intersection,"set([""string_1"", ""string_2""]).intersection(""string_1"")]
",528;476;607;49
116,2,https://www.youtube.com/watch?t=4409&v=W5XNOmyJr6I,4409,screencapture-localhost-8000-2022-01-21-14_45_43.png,,output: doesn't work - intersection is nothing but should be string 1,,
117,2,https://www.youtube.com/watch?t=4422&v=W5XNOmyJr6I,4422,screencapture-localhost-8000-2022-01-21-14_47_19.png,,code: data_exploration; turns string 1 into a set,"set([""string_1"", ""string_2""]).intersection((set[""string_1""])
",543;263;646;55
118,2,https://www.youtube.com/watch?t=4422&v=W5XNOmyJr6I,4422,screencapture-localhost-8000-2022-01-21-14_47_19.png,,output: intersection still null; huh!?,,
119,2,https://www.youtube.com/watch?t=4429&v=W5XNOmyJr6I,4429,screencapture-localhost-8000-2022-01-21-14_48_23.png,,code: data_exploration; tries with intersect. Intersect is not a method,"set([""string_1"", ""string_2""]).intersect(set[""string_1""])
",534;269;616;46
120,2,https://www.youtube.com/watch?t=4429&v=W5XNOmyJr6I,4429,screencapture-localhost-8000-2022-01-21-14_48_23.png,,output: set object has no attribute intersect.,,
121,2,https://www.youtube.com/watch?t=4466&v=W5XNOmyJr6I,4466,screencapture-localhost-8000-2022-01-21-14_54_51.png,,search: python set intersection; he's tried several variations on intersection now looking for an example,,
122,2,https://www.youtube.com/watch?t=4468&v=W5XNOmyJr6I,4468,screencapture-localhost-8000-2022-01-21-14_56_12.png,,visit: Python set intersection method; skims examples,,
124,2,https://www.youtube.com/watch?t=4497&v=W5XNOmyJr6I,4497,screencapture-localhost-8000-2022-01-21-14_57_58.png,,output: still returns empty set.,"intersect_str = set([""string_1"", ""string_2""]).intersection(set(""string_1""))
intersect_str
",534;554;829;64
125,2,https://www.youtube.com/watch?t=4515&v=W5XNOmyJr6I,4515,screencapture-localhost-8000-2022-01-21-14_59_12.png,,"code: data_exploration; added square brackets around ""string 1""","intersect_str = set([""string_1"", ""string_2""]).intersection(set([""string_1""])) 
intersect_str
",534;368;850;70
126,2,https://www.youtube.com/watch?t=4515&v=W5XNOmyJr6I,4515,screencapture-localhost-8000-2022-01-21-14_59_12.png,,"output: that then returns ""string 1""",,
129,2,https://www.youtube.com/watch?t=4574&v=W5XNOmyJr6I,4574,screencapture-localhost-8000-2022-01-21-15_01_14.png,,output: now in set form.,"# Look at imagenet classes
for k, v in imagenet_classes.items():
   # Get value from imagenet classes (string)
   # print(v.lower(),split("",""))
   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])
   print([imagenet_class_set])
   # See if value appears in flat_food_list
   if v.lower().split("","") in flat_food_list:
      print(k, v) I
",534;211;1003;253
130,2,https://www.youtube.com/watch?t=4596&v=W5XNOmyJr6I,4596,screencapture-localhost-8000-2022-01-21-15_03_56.png,,code: data_exploration; adds set intersect,"# Look at imagenet classes
for k, v in imagenet_classes.items():
   # Get value from imagenet classes (string)
   # print(v.lower().split("",""))
   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])
   print([imagenet_class_set]) |
   # See if value appears jin flat_food_list
   if imagenet_class_set.intersection(flat_food_list):
      print(k, v)
",537;220;1000;260
131,2,https://www.youtube.com/watch?t=4598&v=W5XNOmyJr6I,4598,screencapture-localhost-8000-2022-01-21-15_05_27.png,,output: appears to work - outputs 8 hen in the viewable output.,,
134,2,https://www.youtube.com/watch?t=4608&v=W5XNOmyJr6I,4608,screencapture-localhost-8000-2022-01-21-15_14_16.png,,"output: there's now a list of indices and image classes that are seen as ""food""",,
135,2,https://www.youtube.com/watch?t=4627&v=W5XNOmyJr6I,4627,screencapture-localhost-8000-2022-01-21-15_15_59.png,,"goal: ""imagenet food classes...we want to filter these out.",,
136,2,https://www.youtube.com/watch?t=4657&v=W5XNOmyJr6I,4657,screencapture-localhost-8000-2022-01-22-14_39_39.png,,output: these are the classes to filter out; interestingly some of them have artifacts from word separation  like bowtie...not always pasta.,,
137,2,https://www.youtube.com/watch?t=4734&v=W5XNOmyJr6I,4734,screencapture-localhost-8000-2022-01-22-14_42_00.png,,goal: what classes shouldn't be there?; he recognizes that not all of the classes identified are actually related to food. proposing a manual filter.,,
138,2,https://www.youtube.com/watch?t=4746&v=W5XNOmyJr6I,4746,screencapture-localhost-8000-2022-01-22-14_44_15.png,,search: ruffed grouse; trying to determine whether this should be food or not.,,
139,2,https://www.youtube.com/watch?t=4760&v=W5XNOmyJr6I,4760,screencapture-localhost-8000-2022-01-22-14_45_00.png,,search: ruffed grouse images; is this food or a bird?,,
140,2,https://www.youtube.com/watch?t=4922&v=W5XNOmyJr6I,4922,screencapture-localhost-8000-2022-01-22-14_48_22.png,,"search: cardoon; ""who knows what a cardoon is?""",,
141,2,https://www.youtube.com/watch?t=5083&v=W5XNOmyJr6I,5083,screencapture-localhost-8000-2022-01-22-14_58_35.png,,"goal: listed in comments - remove non-food from food classes list; filter non-foods from imagenet classes, download images; paraphrasing a bit",,
142,2,https://www.youtube.com/watch?t=5527&v=W5XNOmyJr6I,5527,screencapture-localhost-8000-2022-01-22-15_07_27.png,,code: data_exploration; has defined an array of non-food classes to remove from the NLTK created list.,"len(imagenet_food_classes)


# What classes shouldn't be there? — Going through the imagenet_food_classes
non_food_classes_manual_sort = [457, 494, 567, 626, 723, 738, 760, 923, 972,

imagenet_classes
",168;392;802;428
143,2,https://www.youtube.com/watch?t=5583&v=W5XNOmyJr6I,5583,screencapture-localhost-8000-2022-01-22-15_09_20.png,,code: data_exploration; look at first 5 food classes.,"# What classes shouldn't be there? — Going through the imagenet_food_classes
non_food_classes_manual_sort = [457, 494, 567, 626, 723, 738, 760, 923, 972,

list(imagenet_food_classes) [:5]

imagenet_manual_fitlered_food_classes = {}
",168;229;808;416
144,2,https://www.youtube.com/watch?t=5583&v=W5XNOmyJr6I,5583,screencapture-localhost-8000-2022-01-22-15_09_20.png,,output: showing the key values for the first five food classes,,
145,2,https://www.youtube.com/watch?t=5696&v=W5XNOmyJr6I,5696,screencapture-localhost-8000-2022-01-22-15_12_09.png,,"code: data_exploration; made a new filtered list; iterating through the foods list, adding the ones that are not also in the manual list of non-foods.","imagenet_manual_fitlered_food_classes = {}
for k, v in imagenet_food_classes.items():
   if k not in non_food_classes_manual_sort: # don't won't keys that aren't food (from the manual sort)
      imagenet_manual_fitlered_food_classes[k] = v
imagenet_manual_fitlered_food_classes
",540;581;1126;151
146,2,https://www.youtube.com/watch?t=5735&v=W5XNOmyJr6I,5735,screencapture-localhost-8000-2022-01-22-15_14_18.png,,"output: these are the filtered ""food"" classes; I believe this is the final foods list.",,
147,2,https://www.youtube.com/watch?t=5786&v=W5XNOmyJr6I,5786,screencapture-localhost-8000-2022-01-22-15_17_05.png,,goal: get list of food and non-food classes from imagenet; this is listed through his comments in jupyter.,,
148,2,https://www.youtube.com/watch?t=5861&v=W5XNOmyJr6I,5861,screencapture-localhost-8000-2022-01-22-15_20_56.png,,code: data_exploration; looking at the food class keys; this seems kind of redundant.,"# Get food class keys
food_class_keys = list(imagenet_manual_fitlered_food_classes.keys())
food_class_keys [:10]

imagenet_non_food_classes = {}
",537;332;763;362
149,2,https://www.youtube.com/watch?t=5890&v=W5XNOmyJr6I,5890,screencapture-localhost-8000-2022-01-22-15_22_16.png,,code: data_exploration; looking at the number of imagenet classes available. I think he's just trying to build a picture of the overall dataspace.,"# How many classes do we have?
len(imagenet_classes)

imagenet_non_food_classes = {}
",537;362;358;253
150,2,https://www.youtube.com/watch?t=5889&v=W5XNOmyJr6I,5889,screencapture-localhost-8000-2022-01-22-15_23_18.png,,"goal: ""now we want to remove the ones that are non-food"";",,
151,2,https://www.youtube.com/watch?t=5939&v=W5XNOmyJr6I,5939,screencapture-localhost-8000-2022-01-22-15_24_47.png,,code: data_exploration; create dictionary of non-food classes.,"imagenet_non_food_classes = {}
for k, v in imagenet_classes.items():
   if k not in food_class_keys:
      imagenet_non_food_classes[k] = v
imagenet_non_food_classes
",543;299;454;166
152,2,https://www.youtube.com/watch?t=5978&v=W5XNOmyJr6I,5978,screencapture-localhost-8000-2022-01-22-15_26_11.png,,"goal: added imagenet photos that are food to the images of foods set. I don't think this is a goal he intends to pursue right now, more of a note for later.",,
153,2,https://www.youtube.com/watch?t=6012&v=W5XNOmyJr6I,6012,screencapture-localhost-8000-2022-01-22-15_27_39.png,,"search: chickadee images; ""is that food?""",,
154,2,https://www.youtube.com/watch?t=6074&v=W5XNOmyJr6I,6074,screencapture-localhost-8000-2022-01-22-15_30_42.png,,"goal: ""so now let's see how our imagenet downloader works",,
155,2,https://www.youtube.com/watch?t=6141&v=W5XNOmyJr6I,6141,screencapture-localhost-8000-2022-01-22-15_32_19.png,,goal: spelling out next goals in the notes documents - essentially downloading from imagenet and food101 to assemble the dataset; ,,
156,2,https://www.youtube.com/watch?t=6191&v=W5XNOmyJr6I,6191,screencapture-localhost-8000-2022-01-22-15_34_04.png,,other: at this point he goes and closes all of the tabs with the resources related to what he's done up to this point,,
157,2,https://www.youtube.com/watch?t=6195&v=W5XNOmyJr6I,6195,screencapture-localhost-8000-2022-01-22-15_34_52.png,,revisit: imagenet downloader; he's had this stashed for quite a while and is now coming back to it.,,
158,2,https://www.youtube.com/watch?t=6227&v=W5XNOmyJr6I,6227,screencapture-localhost-8000-2022-01-22-15_36_05.png,,visit: csv overview of the imagenet classes; he gets to this b/c the example code seems to use a numeric key for each class that doesn't correspond with the key that he's just gotten for each.,,
159,2,https://www.youtube.com/watch?t=6431&v=W5XNOmyJr6I,6431,screencapture-localhost-8000-2022-01-22-15_40_39.png,,"other: ""I should have read the docs on this. But why read the docs when you can just spend multiple hours figuring things out?""",,
160,2,https://www.youtube.com/watch?t=6434&v=W5XNOmyJr6I,6434,screencapture-localhost-8000-2022-01-22-15_51_24.png,,visit: words.txt; link from imagenet downloader page,,
161,2,https://www.youtube.com/watch?t=6444&v=W5XNOmyJr6I,6444,screencapture-localhost-8000-2022-01-22-15_51_24.png,,revisit: classes in imagenet (csv overview); I think he's going to redo the filtering using this instead of his imagenet list of classes approach from before. I personally wonder whether his key is one of the entries in the table and could therefore be used to get the numeric code with just some csv lookup.,,
162,2,https://www.youtube.com/watch?t=6458&v=W5XNOmyJr6I,6458,screencapture-localhost-8000-2022-01-22-15_53_58.png,,visit: raw csv of imagenet classes; this is just plain text,,
163,2,https://www.youtube.com/watch?t=6474&v=W5XNOmyJr6I,6474,screencapture-localhost-8000-2022-01-22-15_54_50.png,,revisit: imagenet downloader; he's pointing out the codes in the example code and saying he didn't realize they were necessary,,
164,2,https://www.youtube.com/watch?t=6491&v=W5XNOmyJr6I,6491,screencapture-localhost-8000-2022-01-22-15_55_39.png,,"visit: downloader.py; ""let's read the script"" I think he's starting to look for an approach that isn't start again from the csv.",,
165,2,https://www.youtube.com/watch?t=6542&v=W5XNOmyJr6I,6542,screencapture-localhost-8000-2022-01-22-15_57_22.png,,"goal: ""need imagenet keys""; I think he's still pondering the approach",,
166,2,https://www.youtube.com/watch?t=6583&v=W5XNOmyJr6I,6583,screencapture-localhost-8000-2022-01-22-16_01_26.png,,goal: in markdown - reiterating that we need the numeric class codes.,,
167,2,https://www.youtube.com/watch?t=6629&v=W5XNOmyJr6I,6629,screencapture-localhost-8000-2022-01-22-16_03_03.png,,revisit: raw csv of imagenet classes; he's just getting the url here to use in reading the csv using pandas.,,
169,2,https://www.youtube.com/watch?t=6699&v=W5XNOmyJr6I,6699,screencapture-localhost-8000-2022-01-22-16_04_54.png,,output: head of the csv file to get a sense of what the data looks like.,"import pandas as csv

df = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet—Datasets—Downloader/master/classes_in_imagenet.csv"")
df.head()
",543;211;1279;121
170,2,https://www.youtube.com/watch?t=6743&v=W5XNOmyJr6I,6743,screencapture-localhost-8000-2022-01-22-16_06_49.png,,"code: data_exploration; df[""classname""] - what do these look like?","df[""class_name""]
",531;287;214;49
173,2,https://www.youtube.com/watch?t=6771&v=W5XNOmyJr6I,6771,screencapture-localhost-8000-2022-01-22-16_11_11.png,,output: error - it isn't a string,"df[""class_name""].lower()
",537;434;295;46
175,2,https://www.youtube.com/watch?t=6775&v=W5XNOmyJr6I,6775,screencapture-localhost-8000-2022-01-22-16_11_54.png,,output: works,"df[""class_name""].str.lower()
",534;434;334;49
176,2,https://www.youtube.com/watch?t=6870&v=W5XNOmyJr6I,6870,screencapture-localhost-8000-2022-01-22-16_14_11.png,,goal: filter dataframe from food classes.,,
178,2,https://www.youtube.com/watch?t=6919&v=W5XNOmyJr6I,6919,screencapture-localhost-8000-2022-01-22-16_16_54.png,,output: Stringmethods not callable; I'm not sure what the valid syntax here is.,,
180,2,https://www.youtube.com/watch?t=6927&v=W5XNOmyJr6I,6927,screencapture-localhost-8000-2022-01-22-16_24_28.png,,output: TypeError - float;,"# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].str.contains(""food"")]
df_non_food
",534;383;622;94
181,2,https://www.youtube.com/watch?t=6944&v=W5XNOmyJr6I,6944,screencapture-localhost-8000-2022-01-22-16_25_49.png,,"code: data_exploration; he's confused by the float error so is exploring df[""classname""]","# Filter dataframe from food classes
df_non_food = df [~df[""class_name""].str.contains(""food"")]
df_non_food
",519;623;679;100
183,2,https://www.youtube.com/watch?t=6947&v=W5XNOmyJr6I,6947,screencapture-localhost-8000-2022-01-22-16_27_06.png,,"output: length is less than the number of entries, meaning that there are some duplicates.",,
185,2,https://www.youtube.com/watch?t=6959&v=W5XNOmyJr6I,6959,screencapture-localhost-8000-2022-01-22-16_28_59.png,,"output: there are no duplicates. ""Hmmm""
","len(df)

len(df.drop_duplicates())

len(df[""class_name""].unique())
",534;263;370;392
186,2,https://www.youtube.com/watch?t=6979&v=W5XNOmyJr6I,6979,screencapture-localhost-8000-2022-01-22-16_30_15.png,,code: data_exploration; df.info to explore more,"df.info()
",675;226;421;130
188,2,https://www.youtube.com/watch?t=6996&v=W5XNOmyJr6I,6996,screencapture-localhost-8000-2022-01-22-16_32_11.png,,output: cannot mask with non-boolean array containing NA/NaN values,"# Filter dataframe from food classes
df_non_food = df[df[""class name""].str.contains(""food"")]
df_non_food
",537;275;613;91
189,2,https://www.youtube.com/watch?t=6996&v=W5XNOmyJr6I,6996,screencapture-localhost-8000-2022-01-22-16_33_04.png,,"goal: ""Ah, how many NaNs are in here?","flat_food_list[:5]
",549;317;199;55
190,2,https://www.youtube.com/watch?t=7007&v=W5XNOmyJr6I,7007,screencapture-localhost-8000-2022-01-22-16_38_21.png,,code: data_exploration; df.isna - trying to find the nans,"len(df)

df.isna()
",534;353;136;214
194,2,https://www.youtube.com/watch?t=7020&v=W5XNOmyJr6I,7020,screencapture-localhost-8000-2022-01-22-16_40_17.png,,"output: the length is shorter by 2, but there's still something else going on.","len(df)

len(df.dropna())

len(df[""class_name""].unique())

df.info()
",537;257;346;554
195,2,https://www.youtube.com/watch?t=7034&v=W5XNOmyJr6I,7034,screencapture-localhost-8000-2022-01-22-16_41_53.png,,goal: remove NaNs.,,
196,2,https://www.youtube.com/watch?t=7041&v=W5XNOmyJr6I,7041,screencapture-localhost-8000-2022-01-22-16_43_25.png,,code: data_exploration; remove the nans in place,"len(df)

# Remove NaN's
df.dropna(inplace=True)

len(df[""class_name""].unique())

df.info()
",543;193;337;533
197,2,https://www.youtube.com/watch?t=7045&v=W5XNOmyJr6I,7045,screencapture-localhost-8000-2022-01-22-16_44_11.png,,"output: re-evaluates the classname contains food code, which now doesn't generate an error; ""we're on team""",,
199,2,https://www.youtube.com/watch?t=7072&v=W5XNOmyJr6I,7072,screencapture-localhost-8000-2022-01-22-16_48_09.png,,"output: Series has no attribute ""contains""","# Filter dataframe from food classes
df_non_food = df[df[""class_name""].str.lower().contains(""food"")]
df_non_food
",534;380;703;97
200,2,https://www.youtube.com/watch?t=7097&v=W5XNOmyJr6I,7097,screencapture-localhost-8000-2022-01-22-16_49_36.png,,goal: let's lower all the strings,,
202,2,https://www.youtube.com/watch?t=7119&v=W5XNOmyJr6I,7119,screencapture-localhost-8000-2022-01-22-16_50_25.png,,output: does not generate an error,,
203,2,https://www.youtube.com/watch?t=7129&v=W5XNOmyJr6I,7129,screencapture-localhost-8000-2022-01-22-16_54_16.png,,output: evaluates it through to where the food check is and it seems to be ok,,
205,2,https://www.youtube.com/watch?t=7133&v=W5XNOmyJr6I,7133,screencapture-localhost-8000-2022-01-22-16_55_45.png,,output: classnames now appear to be non-food.,"# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].str.contains(""food"")]
df_non_food
",537;380;622;103
206,2,https://www.youtube.com/watch?t=7150&v=W5XNOmyJr6I,7150,screencapture-localhost-8000-2022-01-22-16_57_18.png,,goal: how many did we filter out with that?,,
207,2,https://www.youtube.com/watch?t=7163&v=W5XNOmyJr6I,7163,screencapture-localhost-8000-2022-01-22-16_58_43.png,,"output: this is old output, but he looks back at info results to see the original size and concludes that 19 classes have been filtered out with the word ""food""",,
209,2,https://www.youtube.com/watch?t=7190&v=W5XNOmyJr6I,7190,screencapture-localhost-8000-2022-01-22-17_00_10.png,,output: there's no isin method,"# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].str.isin(flat_food_list)]
df_nan_food

len(df_non_food)

""food"" in flat_food_list
",537;380;664;392
211,2,https://www.youtube.com/watch?t=7193&v=W5XNOmyJr6I,7193,screencapture-localhost-8000-2022-01-22-17_01_43.png,,output: that appears to work,"# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].isin(flat_food_list)]
df_non_food
",543;380;610;97
212,2,https://www.youtube.com/watch?t=7213&v=W5XNOmyJr6I,7213,screencapture-localhost-8000-2022-01-22-17_03_29.png,,"output: looking at the size of the results ""we filtered out about a thousand with that""",,
213,2,https://www.youtube.com/watch?t=7277&v=W5XNOmyJr6I,7277,screencapture-localhost-8000-2022-01-22-21_00_15.png,,"search: dataframe filter column by strings in list; he hasn't quite articulated a goal here, but has noted that the classnames might contain other characters and that currently isin will require a perfect match.",,
214,2,https://www.youtube.com/watch?t=7279&v=W5XNOmyJr6I,7279,screencapture-localhost-8000-2022-01-22-21_01_59.png,,visit: stackoverflow - filter out rows based on list of strings in pandas;,,
215,2,https://www.youtube.com/watch?t=7412&v=W5XNOmyJr6I,7412,screencapture-localhost-8000-2022-01-22-21_04_53.png,,"goal: I think we've removed enough classes, actually. Let's start to download some data.",,
216,2,https://www.youtube.com/watch?t=7456&v=W5XNOmyJr6I,7456,screencapture-localhost-8000-2022-01-22-21_06_16.png,,code: data_exploration; defining data frames for food and non-food.,,675;226;421;130
217,2,https://www.youtube.com/watch?t=7456&v=W5XNOmyJr6I,7456,screencapture-localhost-8000-2022-01-22-21_06_16.png,,"output: 20898 non-food classes, 941 food classes in the respective sets.","# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].isin(flat_food_list)]
df_food = df[df[""class_name""].isin(flat_food_list)]
len(df_non_food), len(df_food)

list(df[""class_name""])
",534;353;622;293
218,2,https://www.youtube.com/watch?t=7470&v=W5XNOmyJr6I,7470,screencapture-localhost-8000-2022-01-22-21_07_49.png,,code: data_exploration; looking at what's in the food class.,"# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].isin(flat_food_list)]
df_food = df[df[""class_name""].isin(flat_food_list)]
len(df_non_food), len(df_food)

list(df_food.class_name) 
",537;196;616;277
219,2,https://www.youtube.com/watch?t=7470&v=W5XNOmyJr6I,7470,screencapture-localhost-8000-2022-01-22-21_07_49.png,,"goal: ""and now we can remove some of these""; I'm guessing he's going to do a manual removal like before to get rid of some of the rest of them.",,
220,2,https://www.youtube.com/watch?t=7518&v=W5XNOmyJr6I,7518,screencapture-localhost-8000-2022-01-22-21_10_21.png,,"code: data_exploration; prints just the first 10 items in the food list. ""that's close enough to being just all food"" though there are some obvious non-foods in the list like puppy and cup and refrigerator.","# Filter dataframe from food classes
df_non_food = df [~df[""class_name""].isin(flat_food_list)]
df_food = df[df[""class_name""].isin(flat_food_list)]
len(df_non_food), len(df_food)
",531;193;628;121
221,2,https://www.youtube.com/watch?t=7555&v=W5XNOmyJr6I,7555,screencapture-localhost-8000-2022-01-22-21_12_09.png,,goal: TODO- remove extra classes that aren't food.,,
222,2,https://www.youtube.com/watch?t=7609&v=W5XNOmyJr6I,7609,screencapture-localhost-8000-2022-01-22-21_13_37.png,,"goal: ""ok let's start tto remove some of these from...""; he's just scrolled through the list and noticed some of the obvious non-foods like ball and refrigerator.",,
223,2,https://www.youtube.com/watch?t=7618&v=W5XNOmyJr6I,7618,screencapture-localhost-8000-2022-01-22-21_14_57.png,,code: data_exploration; printing out flat food list (top 10) not really sure why,"flat_food_list[:10]
",534;425;247;58
224,2,https://www.youtube.com/watch?t=7647&v=W5XNOmyJr6I,7647,screencapture-localhost-8000-2022-01-22-21_16_03.png,,code: data_exploration; declaring non-food list.,,675;226;421;130
225,2,https://www.youtube.com/watch?t=7647&v=W5XNOmyJr6I,7647,screencapture-localhost-8000-2022-01-22-21_16_03.png,,"goal: ""ok we're going to spend 10 minutes removing non-foods from this list""",,
226,2,https://www.youtube.com/watch?t=7754&v=W5XNOmyJr6I,7754,screencapture-localhost-8000-2022-01-22-21_19_28.png,,"search: periwinkle; ""what is a periwinkle?""",,
228,2,https://www.youtube.com/watch?t=8351&v=W5XNOmyJr6I,8351,screencapture-localhost-8000-2022-01-22-21_30_33.png,,code: data_exploration; middle of the list,"# Manually removing not foods from flat_food_list
not_food_list = [""ball"",
   'puppy',
   'dog',
   'bar',
   'blade',
   'garden',
   'hand', 
   'head',
   'jacket',
   'junk',
   'key',
   'leg',
   'oven',
   'pin',

",147;434;787;398
229,2,https://www.youtube.com/watch?t=8351&v=W5XNOmyJr6I,8351,screencapture-localhost-8000-2022-01-22-21_31_45.png,,code: data_exploration; end of list,"'pilot',
'runner',
'smith',
'ash',
'sand']
",204;185;154;145
230,2,https://www.youtube.com/watch?t=8400&v=W5XNOmyJr6I,8400,screencapture-localhost-8000-2022-01-22-21_33_03.png,,goal: in comments - filter out the manual non-foods from the list and then download the images,,
231,2,https://www.youtube.com/watch?t=9282&v=W5XNOmyJr6I,9282,,,code: data_exploration; printing top 5 non-foods - I think this is a way to close out the creation of that array.,,675;226;421;130
232,2,https://www.youtube.com/watch?t=9314&v=W5XNOmyJr6I,9314,screencapture-localhost-8000-2022-01-23-15_38_16.png,,"goal: ""let's recreate our actual non-food dataframe again""",,
233,2,https://www.youtube.com/watch?t=9353&v=W5XNOmyJr6I,9353,screencapture-localhost-8000-2022-01-23-15_39_34.png,,code: data_exploration; removing the non-food manual list from the food dataframe,"# Next
# Filter out non-food items from dataframe (manually sorted)
# Donwload ImageNet Food & Non—food class images
# Make dataset of food and not food

# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].isin(flat_food_list)]
df_food = df[df[""class_name""].isin(flat_food_list)]
df_food = df[~df[""class_name""].isin(not_food_list)] # remove even more not food items
len(df_non_food), len(df_food) |
",138;247;955;353
234,2,https://www.youtube.com/watch?t=9372&v=W5XNOmyJr6I,9372,screencapture-localhost-8000-2022-01-23-15_41_35.png,,output: length of df_food dataframe,,
235,2,https://www.youtube.com/watch?t=9372&v=W5XNOmyJr6I,9372,screencapture-localhost-8000-2022-01-23-15_41_35.png,,code: data_exploration; printing length of food dataframe,"len(df_food)

list(df_food.class_name) [:5]

list(df_food.class_name)
",165;266;439;383
237,2,https://www.youtube.com/watch?t=9459&v=W5XNOmyJr6I,9459,screencapture-localhost-8000-2022-01-23-15_43_42.png,,output: looking at df_food results,"# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].isin(ﬂat_food_list)]
df_food = df[df[""class_name""].isin(flat_food_list)]
df_food = df_food[~df[""class_name""].isin(not_food list)] # remove even more not food items
len(df_non_food), len(df_food)

len(df_food)

list(df_food.class_name) [:5]
",165;244;961;491
238,2,https://www.youtube.com/watch?t=9510&v=W5XNOmyJr6I,9510,screencapture-localhost-8000-2022-01-23-15_46_19.png,,goal: get list of non-food and food class keys,,
239,2,https://www.youtube.com/watch?t=9636&v=W5XNOmyJr6I,9636,screencapture-localhost-8000-2022-01-23-15_49_47.png,,code: data_exploration; this is a first attempt to get at the class identifiers for use in downloading,"imagenet_food_class_ids = df_food[[""synid"", ""class_name""]].to_dict()
imagenet_food_class_ids
",165;467;763;82
240,2,https://www.youtube.com/watch?t=9672&v=W5XNOmyJr6I,9672,screencapture-localhost-8000-2022-01-23-15_51_15.png,,code: data_exploration; removing class name piece,"imagenet_food_class_ids = df_food[""synid""].tolist()
imagenet_food_class_ids
",162;404;562;73
241,2,https://www.youtube.com/watch?t=9672&v=W5XNOmyJr6I,9672,screencapture-localhost-8000-2022-01-23-15_51_15.png,,output: now just printing the numeric class identifiers,,
242,2,https://www.youtube.com/watch?t=9704&v=W5XNOmyJr6I,9704,screencapture-localhost-8000-2022-01-23-15_58_34.png,,code: data_exploration; trying to make a class_name to numeric id dictionary,"imagenet_food_class_ids = df_food[""synid""].tolist()
imagenet_food_class_names = df[""class_names""].tolist()
imagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))
imagenet_food_class_ids_and_names_dict
",675;226;421;130
243,2,https://www.youtube.com/watch?t=9708&v=W5XNOmyJr6I,9708,screencapture-localhost-8000-2022-01-23-15_59_34.png,,output: error - classnames key doesn't exist,,
244,2,https://www.youtube.com/watch?t=9712&v=W5XNOmyJr6I,9712,screencapture-localhost-8000-2022-01-23-16_00_23.png,,code: data_exploration; fixed key name,,675;226;421;130
245,2,https://www.youtube.com/watch?t=9712&v=W5XNOmyJr6I,9712,screencapture-localhost-8000-2022-01-23-16_00_23.png,,output: dictionary now looks reasonable,"imagenet_food_class_ids = df_food[""synid""].tolist()
imagenet_food_class_names = df[""class_name""].tolist()
imagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))
imagenet_food_class_ids_and_names_dict
",162;350;1111;124
246,2,https://www.youtube.com/watch?t=9735&v=W5XNOmyJr6I,9735,screencapture-localhost-8000-2022-01-23-16_01_22.png,,"goal: ""so now let's do the same but for non-food","imagenet_food_class_ids = df_food[""synid""].tolist()
imagenet_food_class_names = df[""class_name""].tolist()
imagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))
imagenet_food_class_ids_and_names_dict
",162;641;1090;130
247,2,https://www.youtube.com/watch?t=9762&v=W5XNOmyJr6I,9762,screencapture-localhost-8000-2022-01-23-16_02_42.png,,code: data_exploration; drive by fix he realized after mmodifying for non-food below,"imagenet_food_class_ids = df_food[""synid""].tolist()
imagenet_food_class_names = df_food[""class_name""].tolist()
imagenet_food_class_ids_and_names_d 
imagenet_food_class_ids_and_names_d 

",159;560;1135;127
248,2,https://www.youtube.com/watch?t=9767&v=W5XNOmyJr6I,9767,screencapture-localhost-8000-2022-01-23-16_03_40.png,,code: data_exploration; now have classname -> numeric id dict for non-foods,,675;226;421;130
249,2,https://www.youtube.com/watch?t=9767&v=W5XNOmyJr6I,9767,screencapture-localhost-8000-2022-01-23-16_03_40.png,,output: dictionary looks right,"imagenet_non_food_class_ids = df_non_food[""synid""].tolist()
imagenet_non_food_class_names = df_non_food[""class_name""].tolist()
imagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))
imagenet_non_food_class_ids_and_names_dict
",159;440;1231;121
250,2,https://www.youtube.com/watch?t=9791&v=W5XNOmyJr6I,9791,screencapture-localhost-8000-2022-01-23-16_12_22.png,,code: data_exploration; printing length of the dictionaries,"imagenet_food_class_ids = df_food[""synid""].tolist()
imagenet_food_class_names = df_food[""class_name""].tolist()
imagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))
len(imagenet_food_class_ids_and_names_dict)


imagenet_non_food_class_ids = df_non_food[""synid""].tolist()
imagenet_non_food_class_names = df_non_food[""class_name""].tolist()
imagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))
len(imagenet_non_food_class_ids_and_names_dict) 
",168;352;1222;379
251,2,https://www.youtube.com/watch?t=9791&v=W5XNOmyJr6I,9791,screencapture-localhost-8000-2022-01-23-16_12_22.png,,"output: lengths - 21Kish non-foods, 800 ish foods.","imagenet_food_class_ids = df_food[""synid""].tolist()
imagenet_food_class_names = df_food[""class_name""].tolist()
imagenet_food_class_ids_and_names_dict = dict(zip(imagenet_food_class_ids, imagenet_food_class_names))
len(imagenet_food_class_ids_and_names_dict)

imagenet_non_food_class_ids = df_non_food[""synid""].tolist()
imagenet_non_food_class_names = df_non_food[""class_name""].tolist()
imagenet_non_food_class_ids_and_names_dict = dict(zip(imagenet_non_food_class_ids, imagenet_non_food_class_names))
len(imagenet_non_food_class_ids_and_names_dict) |
",168;353;1216;371
252,2,https://www.youtube.com/watch?t=9800&v=W5XNOmyJr6I,9800,screencapture-localhost-8000-2022-01-23-16_13_24.png,,goal: so who wants to now download some data,,
253,2,https://www.youtube.com/watch?t=9842&v=W5XNOmyJr6I,9842,screencapture-localhost-8000-2022-01-23-16_14_33.png,,revisit: imagenet downloader; let's get the downloader script,,
254,2,https://www.youtube.com/watch?t=9967&v=W5XNOmyJr6I,9967,screencapture-localhost-8000-2022-01-23-16_28_08.png,,visit: Downloading the ImageNet; this is a blog post that details the download script process,,
255,2,https://www.youtube.com/watch?t=10168&v=W5XNOmyJr6I,10168,screencapture-localhost-8000-2022-01-23-16_32_42.png,,visit: imagenet downloader; getting the url to clone the downloader repo,,
256,2,https://www.youtube.com/watch?t=10399&v=W5XNOmyJr6I,10399,screencapture-localhost-8000-2022-01-23-16_40_10.png,,"visit: imagenet downloader; ""So how do we use this?"" He's cloned it's git repo and set it up within his project.",,
257,2,https://www.youtube.com/watch?t=10405&v=W5XNOmyJr6I,10405,screencapture-localhost-8000-2022-01-23-16_41_03.png,,"revisit: downloader.py; perusing what it's doing, I imagine.",,
258,2,https://www.youtube.com/watch?t=10424&v=W5XNOmyJr6I,10424,screencapture-localhost-8000-2022-01-23-16_43_08.png,,"goal: ""we need to create a folder of images""",,
259,2,https://www.youtube.com/watch?t=10791&v=W5XNOmyJr6I,10791,screencapture-localhost-8000-2022-01-23-21_25_21.png,,search: python how to pass list as command line argument; he's downloaded a few test images using a downloader downloader.py script and is now trying to figure out how to connect his dictionary of numeric codes with that download script,,
260,2,https://www.youtube.com/watch?t=10801&v=W5XNOmyJr6I,10801,screencapture-localhost-8000-2022-01-23-21_26_48.png,,visit: how to pass an entire list as command line argument in python;,,
261,2,https://www.youtube.com/watch?t=10917&v=W5XNOmyJr6I,10917,screencapture-localhost-8000-2022-01-24-09_43_37.png,,code: data_exploration; making a list of keys,,675;226;421;130
262,2,https://www.youtube.com/watch?t=10917&v=W5XNOmyJr6I,10917,screencapture-localhost-8000-2022-01-24-09_43_37.png,,goal: we want to pass this list of keys,"len(imagenet_non_food_class_ids_and_names_dict)

list(imagenet_food_class_ids_and_names_dict.keys())
",519;196;553;211
263,2,https://www.youtube.com/watch?t=10949&v=W5XNOmyJr6I,10949,screencapture-localhost-8000-2022-01-24-09_44_49.png,,goal: we want to somehow parse this giant list to this command.,,
264,2,https://www.youtube.com/watch?t=11083&v=W5XNOmyJr6I,11083,screencapture-localhost-8000-2022-01-24-09_47_31.png,,output: is able to run downloader script from within the jupyter notebook.,,
265,2,https://www.youtube.com/watch?t=11142&v=W5XNOmyJr6I,11142,screencapture-localhost-8000-2022-01-24-09_49_44.png,,code: data_exploration; has defined a test list array and is attempting to pass that as a command line argument,"test_list_images = ['n13918387',
 'n13919547']

!python ImageNet-Datasets-Downloader/downloader.py \
   -data_root test_images \ 
   -use_class_list=True \
   -number_of_classes test_list_images \
   -images_per_class 10|
",135;350;598;293
266,2,https://www.youtube.com/watch?t=11144&v=W5XNOmyJr6I,11144,screencapture-localhost-8000-2022-01-24-09_51_25.png,,output: error but didn't change argument name for classlist rather than number of classes,,
267,2,https://www.youtube.com/watch?t=11241&v=W5XNOmyJr6I,11241,screencapture-localhost-8000-2022-01-24-09_55_42.png,,code: data_exploration; formatting the array so that it looks like the correct output.,,675;226;421;130
268,2,https://www.youtube.com/watch?t=11241&v=W5XNOmyJr6I,11241,screencapture-localhost-8000-2022-01-24-09_55_42.png,,output: looks like the format for the downloader script,"test_list_images = ['n13918387', 'n13919547']
empty_string = """"
for item in test_list_images:
   empty_string += "" "" + item
empty_string

!python ImageNet-Datasets—Downloader/downloader.py \
   -data_root test_images \
   -use_class_list=True \
   -number_of_classes test_list_images \
   -images_per_class 10
",162;260;583;422
269,2,https://www.youtube.com/watch?t=11294&v=W5XNOmyJr6I,11294,screencapture-localhost-8000-2022-01-24-09_58_06.png,,code: data_exploration; calling downloader again with string representation of array.,,675;226;421;130
270,2,https://www.youtube.com/watch?t=11294&v=W5XNOmyJr6I,11294,screencapture-localhost-8000-2022-01-24-09_58_06.png,,"output: same error, but argname is still wrong.","!python ImageNet-Datasets—Downloader/downloader.py \
   -data_root test_images \
   -use_class_list=True \
   -number_of_classes empty_string \
   -images_per_class 10
",156;253;598;157
271,2,https://www.youtube.com/watch?t=11309&v=W5XNOmyJr6I,11309,screencapture-localhost-8000-2022-01-24-09_59_09.png,,goal: we need a way to pass in a python list.,,
272,2,https://www.youtube.com/watch?t=11323&v=W5XNOmyJr6I,11323,screencapture-localhost-8000-2022-01-24-09_59_50.png,,search: how to pass python list to command line,,
273,2,https://www.youtube.com/watch?t=11338&v=W5XNOmyJr6I,11338,screencapture-localhost-8000-2022-01-24-10_02_18.png,,"visit: pass list as a command line argument in python; he has this up as a split screen, code on one side, web on the other.",,
274,2,https://www.youtube.com/watch?t=11370&v=W5XNOmyJr6I,11370,screencapture-localhost-8000-2022-01-24-10_04_46.png,,revisit: stackoverflow pass list as command line arg.; he's got this open in another tab and just goes back,,
275,2,https://www.youtube.com/watch?t=11416&v=W5XNOmyJr6I,11416,screencapture-localhost-8000-2022-01-24-10_06_44.png,,visit: python command line arguments;,,
276,2,https://www.youtube.com/watch?t=11467&v=W5XNOmyJr6I,11467,screencapture-localhost-8000-2022-01-24-10_08_23.png,,visit: downloader script (in IDE now); I think he may be thinking he needs to modify it to eval the input it gets?,,
277,2,https://www.youtube.com/watch?t=11509&v=W5XNOmyJr6I,11509,screencapture-localhost-8000-2022-01-24-10_09_50.png,,search: pass string from file to python command line; interestingly he's looking at the correct argument in the downloader file and that spurs this question,,
278,2,https://www.youtube.com/watch?t=11517&v=W5XNOmyJr6I,11517,screencapture-localhost-8000-2022-01-24-10_11_26.png,,visit: passing strings as python command-line arguments;,,
279,2,https://www.youtube.com/watch?t=11568&v=W5XNOmyJr6I,11568,screencapture-localhost-8000-2022-01-24-10_14_56.png,,code: data_exploration; trying another variation on passing a list - this time in raw string from.,"!python ImageNet-Datasets—Downloader/downloader.py \
   -data_root test_images \
   -use_class_list=True \
   -number_of_classes n13918387 n13919547 \
   -images_per_class 10
",510;235;595;154
280,2,https://www.youtube.com/watch?t=11585&v=W5XNOmyJr6I,11585,screencapture-localhost-8000-2022-01-24-10_16_10.png,,code: data_exploration; finally fixes the arg name!,"!python ImageNet-Datasets-Downloader/downloader.py \
   -data_root test_images \
   -use_class_list=True \
   -class_list empty_string[1:] \
   -images_per_class 10
",516;311;568;154
281,2,https://www.youtube.com/watch?t=11585&v=W5XNOmyJr6I,11585,screencapture-localhost-8000-2022-01-24-10_16_10.png,,"output: error - can't find emptystring (his var); it looks like the python namespace isn't accessible in the command space, even when running in jupyter (my guess)",,
283,2,https://www.youtube.com/watch?t=11599&v=W5XNOmyJr6I,11599,screencapture-localhost-8000-2022-01-24-10_17_50.png,,output: that seems to start downloading images.,"!python ImageNet-Datasets—Downloader/downloader.py \
   -data_root test_images \
   -use_class_list=True \
   -class_list n13918387 n13919547 \|
   -images_per_class 10
",522;244;562;148
284,2,https://www.youtube.com/watch?t=11624&v=W5XNOmyJr6I,11624,screencapture-localhost-8000-2022-01-24-10_19_03.png,,code: data_exploration; tries adding $ in front of variable access; I think this is a suggestion from the stream,"!python ImageNet-Datasets—Downloader/downloader.py \
   -data_root test_images \
   -use_class_list=True \
   -class_list $empty_string[1:] \
   -images_per_class 10
",519;317;568;148
285,2,https://www.youtube.com/watch?t=11624&v=W5XNOmyJr6I,11624,screencapture-localhost-8000-2022-01-24-10_19_03.png,,"output: this does not work, but does seem to somehow pass the value, so there might be promise there",,
286,2,https://www.youtube.com/watch?t=11661&v=W5XNOmyJr6I,11661,screencapture-localhost-8000-2022-01-24-10_24_21.png,,code: data_exploration; removes the [1:] after empty string,,675;226;421;130
287,2,https://www.youtube.com/watch?t=11661&v=W5XNOmyJr6I,11661,screencapture-localhost-8000-2022-01-24-10_24_21.png,,output: seems to be downloading images,"!python ImageNet-Datasets—Downloader/downloader.py \
   -data_root test_images \
   -use_class_list=True \
   -class_list $empty_string \
   -images_per_class 10
",522;272;574;142
288,2,https://www.youtube.com/watch?t=11720&v=W5XNOmyJr6I,11720,screencapture-localhost-8000-2022-01-24-10_24_21.png,,goal: I'd like to export those [numeric ids] to a text file and then can you use what's in a text file in here [the command line argument for the classes list],,
289,2,https://www.youtube.com/watch?t=11744&v=W5XNOmyJr6I,11744,screencapture-localhost-8000-2022-01-24-10_27_17.png,,search: python use contexts of txt file in command line;,,
290,2,https://www.youtube.com/watch?t=11747&v=W5XNOmyJr6I,11747,screencapture-localhost-8000-2022-01-24-10_27_47.png,,visit: execute a command by reading contents of a text file;,,
291,2,https://www.youtube.com/watch?t=11817&v=W5XNOmyJr6I,11817,screencapture-localhost-8000-2022-01-24-10_50_10.png,,goal: get strings to download images,,
292,2,https://www.youtube.com/watch?t=11867&v=W5XNOmyJr6I,11867,screencapture-localhost-8000-2022-01-24-10_51_37.png,,code: data_exploration; starting to try to get the list of strings for food classes.,"# Get food string class IDs
food_class_id_list = list(imagenet_food_class_ids_and_names_dict.keys())
food_class_id_list[:10]
",507;404;784;91
293,2,https://www.youtube.com/watch?t=11867&v=W5XNOmyJr6I,11867,screencapture-localhost-8000-2022-01-24-10_51_37.png,,output: printing first 10 numeric keys.,,
294,2,https://www.youtube.com/watch?t=11909&v=W5XNOmyJr6I,11909,screencapture-localhost-8000-2022-01-24-10_53_10.png,,code: data_exploration; modified to get food and non-food lists.,,675;226;421;130
295,2,https://www.youtube.com/watch?t=11909&v=W5XNOmyJr6I,11909,screencapture-localhost-8000-2022-01-24-10_53_10.png,,output: both print as expected.,"# Get food and non-food string class IDs
food_class_id_list = list(imagenet_food_class_ids_and_names_dict.keys()) |
non_food_class_id_list = list(imagenet_non_food_class_ids_and_names_dict.keys())
food_class_id_list[:5], non_food_class_id_list[:5]
",513;362;862;124
296,2,https://www.youtube.com/watch?t=11935&v=W5XNOmyJr6I,11935,screencapture-localhost-8000-2022-01-24-10_54_22.png,,goal: write function to turn list of strings into a single long list to be executed on command line,,
297,2,https://www.youtube.com/watch?t=12044&v=W5XNOmyJr6I,12044,screencapture-localhost-8000-2022-01-24-10_59_56.png,,code: data_exploration; function to convert the lists into a long string - basically a cleaned version of the emptystring experiment earlier.,"def convert_list_to_long_string(targ_list):
   long_string = """"
   for item in targ_list:
   long_string += "" "" + item
   long_string = long_string[1:]
   return long_string

food_class_id_string = convert_list_to_long_string(food_class_id_list)
non_food_class_id_string = convert_list_to_long_string(non_food_class_id_list)
food_class_id_string[:10], non_food_class_id_string[:10]
",510;196;835;274
298,2,https://www.youtube.com/watch?t=12044&v=W5XNOmyJr6I,12044,screencapture-localhost-8000-2022-01-24-10_59_56.png,,output: appears to work,"def convert_list_to_long_string(targ_list):
   long_string = """"
   for item in targ_list:
      long_string += "" "" + item
   long_string = long_string[1:]
   return long_string

food_class_id_string = convert_list_to_long_string(food_class_id_list)
non_food_class_id_string = convert_list_to_long_string(non_food_class_id_list)
food_class_id_string[:10], non_food_class_id_string[:10]

food_class_id_string|
",513;193;841;434
299,2,https://www.youtube.com/watch?t=12087&v=W5XNOmyJr6I,12087,screencapture-localhost-8000-2022-01-24-11_01_54.png,,goal: want to pass the textfile to the downloader command and have it read. is there a way to do that?; I'm not sure why this is necessary unless there's some kind of limit on the num of characters that can happen in a command line command.,,
300,2,https://www.youtube.com/watch?t=12114&v=W5XNOmyJr6I,12114,screencapture-localhost-8000-2022-01-24-11_03_32.png,,goal: the downloader script with a bogus text file. He poses to the stream - can we do that? someone let me know.,,
301,2,https://www.youtube.com/watch?t=12187&v=W5XNOmyJr6I,12187,screencapture-localhost-8000-2022-01-24-11_05_26.png,,"goal: ""let's just start downloading and we can fix this up later""",,
303,2,https://www.youtube.com/watch?t=12424&v=W5XNOmyJr6I,12424,screencapture-localhost-8000-2022-01-24-11_18_52.png,,code: data_exploration; command to download the non_food images - will potentially result in 200K images.,"!mkdir data/non_food_images/

len(non_food_class_id_list)

!python ImageNet-Datasets—Downloader/downloader.py \
   -data_root data/non_food_images \
   -use_class_list=True \
   -class_list $non_food_class_id_string \ 
   -images_per_class 10
",519;250;571;443
304,2,https://www.youtube.com/watch?t=12432&v=W5XNOmyJr6I,12432,screencapture-localhost-8000-2022-01-24-11_19_58.png,,output: argument list too long; well I guess that answers the question about whether or not there's a size limit on command line commands.,,
305,2,https://www.youtube.com/watch?t=12479&v=W5XNOmyJr6I,12479,screencapture-localhost-8000-2022-01-24-11_21_26.png,,search: maximum length of python arg list; so how long is it allowed to be?,,
306,2,https://www.youtube.com/watch?t=12493&v=W5XNOmyJr6I,12493,screencapture-localhost-8000-2022-01-24-11_22_16.png,,"goal: ""I have an idea. We're just going to download random classes and then we're going to filter it on the backend. Yes, that's a great idea!""",,
307,2,https://www.youtube.com/watch?t=12533&v=W5XNOmyJr6I,12533,screencapture-localhost-8000-2022-01-24-11_23_51.png,,revisit: imagenet downloader; he's looking back and syntax for random class downloading.,,
308,2,https://www.youtube.com/watch?t=12572&v=W5XNOmyJr6I,12572,screencapture-localhost-8000-2022-01-24-11_25_06.png,,revisit: imagenet downloader; getting the example back for reference,,
309,2,https://www.youtube.com/watch?t=12742&v=W5XNOmyJr6I,12742,screencapture-localhost-8000-2022-01-24-11_30_35.png,,other: he has started the image download process,,
310,2,https://www.youtube.com/watch?t=12742&v=W5XNOmyJr6I,12742,screencapture-localhost-8000-2022-01-24-11_30_35.png,,"goal: ""we can filter this on the backend""",,
311,2,https://www.youtube.com/watch?t=13140&v=W5XNOmyJr6I,13140,screencapture-localhost-8000-2022-01-24-11_38_09.png,,"goal: while this is downloading images, let's start to build a model",,
312,2,https://www.youtube.com/watch?t=13153&v=W5XNOmyJr6I,13153,screencapture-localhost-8000-2022-01-24-11_38_57.png,,"goal: we also need images of food, so we should get the food 101 dataset",,
313,2,https://www.youtube.com/watch?t=13207&v=W5XNOmyJr6I,13207,screencapture-localhost-8000-2022-01-24-11_40_23.png,,"goal: do I have tensorflow - let's start looking into this; he's commented that after image downloading, the model building is the biggest part.",,
314,2,https://www.youtube.com/watch?t=13226&v=W5XNOmyJr6I,13226,screencapture-localhost-8000-2022-01-24-11_41_27.png,,code: model_building; tensor flow import,,675;226;421;130
315,2,https://www.youtube.com/watch?t=13226&v=W5XNOmyJr6I,13226,screencapture-localhost-8000-2022-01-24-11_41_27.png,,output: tensor flow does appear to be installed.,import tensorflow as tf,
316,2,https://www.youtube.com/watch?t=13232&v=W5XNOmyJr6I,13232,screencapture-localhost-8000-2022-01-24-11_43_07.png,,code: model_building; tensor flow list of physical devices,"import tensorflow as tf

tf.config.list_physical_devices()
",522;229;381;259
317,2,https://www.youtube.com/watch?t=13232&v=W5XNOmyJr6I,13232,screencapture-localhost-8000-2022-01-24-11_43_07.png,,output: tf sees cpu and gpu,"import tensorflow as tf

tf.config.list_physical_devices()
",519;235;373;247
318,2,https://www.youtube.com/watch?t=13242&v=W5XNOmyJr6I,13242,screencapture-localhost-8000-2022-01-24-11_43_07.png,,goal: we need to silence the tensor flow warnings,,
319,2,https://www.youtube.com/watch?t=13259&v=W5XNOmyJr6I,13259,screencapture-localhost-8000-2022-01-24-11_44_55.png,,goal: do we have gradio,"import gradio as gr
",495;335;298;79
320,2,https://www.youtube.com/watch?t=13259&v=W5XNOmyJr6I,13259,screencapture-localhost-8000-2022-01-24-11_44_55.png,,code: model_building; import gradio,,675;226;421;130
321,2,https://www.youtube.com/watch?t=13259&v=W5XNOmyJr6I,13259,screencapture-localhost-8000-2022-01-24-11_44_55.png,,output: gradio is not available,,
322,2,https://www.youtube.com/watch?t=13314&v=W5XNOmyJr6I,13314,screencapture-localhost-8000-2022-01-24-12_34_28.png,,goal: let's turn off tensor flow warnings.,,
323,2,https://www.youtube.com/watch?t=13331&v=W5XNOmyJr6I,13331,screencapture-localhost-8000-2022-01-24-12_35_19.png,,"other: this is another mass tab closing moment, which for him at least seems to occur in the transition between one thing and the next, although could be a lagging indicator.",,
324,2,https://www.youtube.com/watch?t=13341&v=W5XNOmyJr6I,13341,screencapture-localhost-8000-2022-01-24-12_36_25.png,,search: turn off tensorflow warnings;,,
325,2,https://www.youtube.com/watch?t=13375&v=W5XNOmyJr6I,13375,screencapture-localhost-8000-2022-01-24-12_37_30.png,,visit: Disable Tensorflow debugging information; stackoverflow page,,
326,2,https://www.youtube.com/watch?t=13371&v=W5XNOmyJr6I,13371,screencapture-localhost-8000-2022-01-24-12_38_40.png,,code: model_building; added setLevel to tf to decrease the number of messages,"import tensorflow as tf
tf.get_logger().setLevel('INFO')

tf.config.list_physical_devices()
",516;205;385;202
327,2,https://www.youtube.com/watch?t=13371&v=W5XNOmyJr6I,13371,screencapture-localhost-8000-2022-01-24-12_38_40.png,,output: fewer messages,,
328,2,https://www.youtube.com/watch?t=13389&v=W5XNOmyJr6I,13389,screencapture-localhost-8000-2022-01-24-12_41_00.png,,code: model_building; checking for tflite modelmaker,,675;226;421;130
329,2,https://www.youtube.com/watch?t=13389&v=W5XNOmyJr6I,13389,screencapture-localhost-8000-2022-01-24-12_41_00.png,,output: yes tflitemodelmaker available,"import tflite model_maker
",504;359;412;49
330,2,https://www.youtube.com/watch?t=13433&v=W5XNOmyJr6I,13433,screencapture-localhost-8000-2022-01-24-12_43_30.png,,search: tensorflow load images;,,
331,2,https://www.youtube.com/watch?t=13435&v=W5XNOmyJr6I,13435,screencapture-localhost-8000-2022-01-24-12_44_16.png,,"visit: Load and preprocess images; ""we're going to use something similar to this""",,
332,2,https://www.youtube.com/watch?t=13451&v=W5XNOmyJr6I,13451,screencapture-localhost-8000-2022-01-24-12_45_17.png,,"search: keras image dataset from directory; here I think he is drawing on existing knowledge - while a follow on search, it's not one that pulled info from the previous one.",,
333,2,https://www.youtube.com/watch?t=13454&v=W5XNOmyJr6I,13454,screencapture-localhost-8000-2022-01-24-12_55_21.png,,visit: keras image dataset from directory; there was actually a mention to karas on the previous page that I missed.,,
334,2,https://www.youtube.com/watch?t=13485&v=W5XNOmyJr6I,13485,screencapture-localhost-8000-2022-01-24-12_57_27.png,,search: tensorflow convert saved model to tflite model; he seems to be trying to make rough connections between pieces of the process here that he'll then come back to.,,
335,2,https://www.youtube.com/watch?t=13488&v=W5XNOmyJr6I,13488,screencapture-localhost-8000-2022-01-24-12_58_27.png,,visit: tensorflow lite converter;,,
336,2,https://www.youtube.com/watch?t=13561&v=W5XNOmyJr6I,13561,screencapture-localhost-8000-2022-01-24-13_00_10.png,,"goal: ""let's start building a model - a sample one""",,
337,2,https://www.youtube.com/watch?t=13636&v=W5XNOmyJr6I,13636,screencapture-localhost-8000-2022-01-24-13_15_36.png,,"goal: ""since our model will be binary, let's just make a model for aircraft or anvil""",,
338,2,https://www.youtube.com/watch?t=13648&v=W5XNOmyJr6I,13648,screencapture-localhost-8000-2022-01-24-13_16_22.png,,"goal: ""let's create a small dataset""",,
339,2,https://www.youtube.com/watch?t=13836&v=W5XNOmyJr6I,13836,screencapture-localhost-8000-2022-01-24-13_21_06.png,,"goal: ""let's do aircraft vs anvil""",,
340,2,https://www.youtube.com/watch?t=13927&v=W5XNOmyJr6I,13927,screencapture-localhost-8000-2022-01-24-13_24_11.png,,code: model_building; listing files in the model test dir.,"!ls data/model_test_images/
",513;344;343;52
341,2,https://www.youtube.com/watch?t=13927&v=W5XNOmyJr6I,13927,screencapture-localhost-8000-2022-01-24-13_24_11.png,,output: now have directories for aircraft and anvil,,
342,2,https://www.youtube.com/watch?t=13946&v=W5XNOmyJr6I,13946,screencapture-localhost-8000-2022-01-24-13_25_17.png,,code: model_building; os.walk - not totally sure what this is supposed to accomplish,"import os
os.walk(data/model_test_images/)
",507;326;397;70
343,2,https://www.youtube.com/watch?t=13946&v=W5XNOmyJr6I,13946,screencapture-localhost-8000-2022-01-24-13_25_17.png,,output: invalid syntax.,,
344,2,https://www.youtube.com/watch?t=13970&v=W5XNOmyJr6I,13970,screencapture-localhost-8000-2022-01-24-13_29_11.png,,"goal: we need to make a git ignore, let's add to git ignore. I think this is b/c of a message that popped up about the number of files (presumably due to the images being downloaded)",,
345,2,https://www.youtube.com/watch?t=13999&v=W5XNOmyJr6I,13999,screencapture-localhost-8000-2022-01-24-13_30_43.png,,code: gitignore; adding the image folders,"# Rope project settings
.ropeproject

# mkdocs documentation
/site

#mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# Image folders
data/imagenet_images/*
data/food_images/*
data/non_food_images/*
",498;161;331;485
346,2,https://www.youtube.com/watch?t=14017&v=W5XNOmyJr6I,14017,screencapture-localhost-8000-2022-01-24-13_31_40.png,,"other: git commit ""update gitignore to add image folders"" or something to that effect",,
347,2,https://www.youtube.com/watch?t=14027&v=W5XNOmyJr6I,14027,screencapture-localhost-8000-2022-01-24-13_32_34.png,,goal: so now we're going to build a model,,
348,2,https://www.youtube.com/watch?t=14065&v=W5XNOmyJr6I,14065,screencapture-localhost-8000-2022-01-24-13_33_50.png,,code: model_building; going through directories and printing file names,"import os
for dirs, sub_dirs, files in os.walk(""data/model_test_images/""):
   print(files)
",519;299;691;97
349,2,https://www.youtube.com/watch?t=14091&v=W5XNOmyJr6I,14091,screencapture-localhost-8000-2022-01-24-13_36_11.png,,code: model_building; listing the files in anvil,"os.listdir(""data/model_test_images/anvil"")
",513;332;469;67
350,2,https://www.youtube.com/watch?t=14121&v=W5XNOmyJr6I,14121,screencapture-localhost-8000-2022-01-24-13_37_16.png,,"code: model_building; listing files, dirs, subdirs","import os
for dirs, sub_dirs, files in os.walk(""data/model_test_images/""):
   print(dirs)
   print(sub_dirs)
   print(files)
",516;250;688;145
351,2,https://www.youtube.com/watch?t=14121&v=W5XNOmyJr6I,14121,screencapture-localhost-8000-2022-01-24-13_37_16.png,,output: all seem to be there.,,
352,2,https://www.youtube.com/watch?t=14165&v=W5XNOmyJr6I,14165,screencapture-localhost-8000-2022-01-24-13_38_53.png,,"revisit: keras image dataset from directory; ""does this make test size?""",,
353,2,https://www.youtube.com/watch?t=14207&v=W5XNOmyJr6I,14207,screencapture-localhost-8000-2022-01-24-13_40_17.png,,"goal: ""let's move some random files into train and test - so let's create train and test""; he's got a header that corresponds to this too",,
354,2,https://www.youtube.com/watch?t=14267&v=W5XNOmyJr6I,14267,screencapture-localhost-8000-2022-01-24-13_42_04.png,,code: model_building; making test and train directories,"!mkdir data/model_test_images/train
!mkdir data/model_test_images/test

import os
for dirs, sub_dirs, files in os.walk(""data/model_test_images/""):
   print(dirs)
   print(sub_dirs)
   print(files)
",513;263;694;296
355,2,https://www.youtube.com/watch?t=14290&v=W5XNOmyJr6I,14290,screencapture-localhost-8000-2022-01-24-13_53_10.png,,goal: we want aircraft and anvil in here (test and train) but we want random images,,
356,2,https://www.youtube.com/watch?t=14365&v=W5XNOmyJr6I,14365,screencapture-localhost-8000-2022-01-24-13_55_49.png,,code: model_building; getting a list of aircraft images,"aircraft_images = os.listdir(""data/model_test_images/aircraft"")
aircraft_images
",510;296;697;70
357,2,https://www.youtube.com/watch?t=14363&v=W5XNOmyJr6I,14363,screencapture-localhost-8000-2022-01-24-13_55_49.png,,goal: we want to get random indexes from this and then move the rest,,
358,2,https://www.youtube.com/watch?t=14373&v=W5XNOmyJr6I,14373,screencapture-localhost-8000-2022-01-24-13_55_49.png,,code: model_building; num of aircraft images,,675;226;421;130
359,2,https://www.youtube.com/watch?t=14373&v=W5XNOmyJr6I,14373,screencapture-localhost-8000-2022-01-24-13_55_49.png,,output: 53 aircraft images,"aircraft_images = os.listdir(""data/model_test_images/aircraft"")
aircraft_images
",510;293;706;82
360,2,https://www.youtube.com/watch?t=14395&v=W5XNOmyJr6I,14395,screencapture-localhost-8000-2022-01-24-13_58_21.png,,code: model_building; figuring out the size of the training/test sets,"aircraft_images = os.listdir(""data/model_test_images/aircraft"")
len(aircraft_images)

train_split = int(0.8 * len(aircraft_images))
train_split
",519;281;682;253
361,2,https://www.youtube.com/watch?t=14449&v=W5XNOmyJr6I,14449,screencapture-localhost-8000-2022-01-24-14_00_20.png,,code: model_building; attempting to make a set the length of aircraft images.,"import numpy as np

train_idx = np.range(len(aircraft_images))
train_idx
",513;272;493;118
362,2,https://www.youtube.com/watch?t=14453&v=W5XNOmyJr6I,14453,screencapture-localhost-8000-2022-01-24-14_02_50.png,,output: numpy does not have a range attribute,,
363,2,https://www.youtube.com/watch?t=14478&v=W5XNOmyJr6I,14478,screencapture-localhost-8000-2022-01-25-09_53_38.png,,code: model_building; range->arange,"import numpy as np

train_idx = np.arange(len(aircraft_images))
train_idx
",516;272;520;124
364,2,https://www.youtube.com/watch?t=14478&v=W5XNOmyJr6I,14478,screencapture-localhost-8000-2022-01-25-09_53_38.png,,output: prints out numbered list up to # of aircraft images,,
365,2,https://www.youtube.com/watch?t=14543&v=W5XNOmyJr6I,14543,screencapture-localhost-8000-2022-01-25-09_55_58.png,,goal: get random indexes of certain number from list of images,,
366,2,https://www.youtube.com/watch?t=14557&v=W5XNOmyJr6I,14557,screencapture-localhost-8000-2022-01-25-09_56_49.png,,"search: python random select k; ""what's the random choice in python?""",,
367,2,https://www.youtube.com/watch?t=14561&v=W5XNOmyJr6I,14561,screencapture-localhost-8000-2022-01-25-09_57_26.png,,visit: python random sample() to choose multiple items from any sequence;,,
368,2,https://www.youtube.com/watch?t=14572&v=W5XNOmyJr6I,14572,screencapture-localhost-8000-2022-01-25-09_58_12.png,,search: python random seed;,,
369,2,https://www.youtube.com/watch?t=14603&v=W5XNOmyJr6I,14603,screencapture-localhost-8000-2022-01-25-10_00_38.png,,code: model_building; getting a sample of 10 aircraft images,,675;226;421;130
370,2,https://www.youtube.com/watch?t=14603&v=W5XNOmyJr6I,14603,screencapture-localhost-8000-2022-01-25-10_00_38.png,,output: listing of 10 random aircraft images,"import random
random.sample(aircraft_images, 10)
",510;235;391;79
371,2,https://www.youtube.com/watch?t=14608&v=W5XNOmyJr6I,14608,screencapture-localhost-8000-2022-01-25-10_01_31.png,,code: model_building; setting the random seed for the aircraft images,"import random
random.seed(42)
random.sample(aircraft_images, 10)
",501;292;441;112
372,2,https://www.youtube.com/watch?t=14608&v=W5XNOmyJr6I,14608,screencapture-localhost-8000-2022-01-25-10_01_31.png,,output: set of 10 images with that random seed,"import random
random.seed(42)
random.sample(aircraft_images, 10)
",516;293;388;100
373,2,https://www.youtube.com/watch?t=14730&v=W5XNOmyJr6I,14730,screencapture-localhost-8000-2022-01-25-10_04_59.png,,code: model_building; trying to set up test and train lists,"import random
random.seed(42)

train_split = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = aircraft_images not in train_image_list
",504;196;700;202
374,2,https://www.youtube.com/watch?t=14730&v=W5XNOmyJr6I,14730,screencapture-localhost-8000-2022-01-25-10_04_59.png,,output: not in seems to return a boolean rather than the set of things not in that list,,
375,2,https://www.youtube.com/watch?t=14747&v=W5XNOmyJr6I,14747,screencapture-localhost-8000-2022-01-25-10_29_59.png,,goal: I want to get the ones that are not in...,,
377,2,https://www.youtube.com/watch?t=14769&v=W5XNOmyJr6I,14769,screencapture-localhost-8000-2022-01-25-10_32_00.png,,output: error - list is an unhashable type,"import random
random. seed(42)

train_split = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = set([train_image_list]).difference(set([aircraft_images]))
test_image_list
",519;326;814;235
378,2,https://www.youtube.com/watch?t=14784&v=W5XNOmyJr6I,14784,screencapture-localhost-8000-2022-01-25-10_34_09.png,,code: model_building; removes the [] around the lists,"train_sptit = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = set(train_image_list).difference(set(aircraft_images))
test_image_list
",501;199;811;127
379,2,https://www.youtube.com/watch?t=14784&v=W5XNOmyJr6I,14784,screencapture-localhost-8000-2022-01-25-10_34_09.png,,output: returns the empty set; I think they may need to be ordered the other way,"train_split = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = set(train_image_list).difference(set(aircraft_images))
test_image_list

test_image_list
",522;191;775;332
381,2,https://www.youtube.com/watch?t=14810&v=W5XNOmyJr6I,14810,screencapture-localhost-8000-2022-01-25-10_35_38.png,,output: that seems to work - we now get a test image list.,,
382,2,https://www.youtube.com/watch?t=14827&v=W5XNOmyJr6I,14827,screencapture-localhost-8000-2022-01-25-10_43_32.png,,code: model_building; making the test image list into a list,"random.seed(42)

train_split = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = list(set(aircraft_images).difference(set(train_image_list)))
test_image_list
",519;187;835;211
383,2,https://www.youtube.com/watch?t=14827&v=W5XNOmyJr6I,14827,screencapture-localhost-8000-2022-01-25-10_43_32.png,,output: test image list is a list,"random.seed(42)

train_split = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = list(set(aircraft_images).difference(set(train_image_list)))
test_image_list
",522;191;835;196
384,2,https://www.youtube.com/watch?t=14845&v=W5XNOmyJr6I,14845,screencapture-localhost-8000-2022-01-25-10_44_41.png,,code: model_building; printing the length of training and test sets,"import random
random.seed(42)

train_split = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = list(set(aircraft_images).difference(set(train_image_list)))
len(train_image_list), len(test_image_list)",519;247;835;247
385,2,https://www.youtube.com/watch?t=14845&v=W5XNOmyJr6I,14845,screencapture-localhost-8000-2022-01-25-10_44_41.png,,output: they are both what we expect (42 and 11) so we have a training and test set for aircraft,"import random
random.seed(42)

train_split = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = list(set(aircraft_images).difference(set(train_image_list)))
len(train_image_list), len(test_image_list)
",516;250;838;229
388,2,https://www.youtube.com/watch?t=14979&v=W5XNOmyJr6I,14979,screencapture-localhost-8000-2022-01-25-10_50_51.png,,output: seems to work as expected,"   train_image_List = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list

train_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")
len(train_image_list), len(test_image_list)
",516;188;1003;163
389,2,https://www.youtube.com/watch?t=15040&v=W5XNOmyJr6I,15040,screencapture-localhost-8000-2022-01-25-10_52_39.png,,code: model_building; moving towards just using a list of directories,"target_dirs = os.listdir(""data/model_test_images"")
target_dirs

import random
def create_train_test_list(target_dir):
   random.seed(42)
   image_list = os.listdir(target_dir)
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
",507;286;838;391
390,2,https://www.youtube.com/watch?t=15040&v=W5XNOmyJr6I,15040,screencapture-localhost-8000-2022-01-25-10_52_39.png,,"output: current directories seem a little odd - airplane, anvil, test and train.","target_dirs = os.listdir(""data/model_test_images"")
target_dirs

import random
def create_train_test_list(target_dir):
   random.seed(42)
   image_list = os.listdir(target_dir)
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test image list = list(set(image_list).difference(set(train_image_list)))
",516;284;838;386
391,2,https://www.youtube.com/watch?t=15062&v=W5XNOmyJr6I,15062,screencapture-localhost-8000-2022-01-25-10_53_56.png,,goal: model_building; create a function to move images,,
392,2,https://www.youtube.com/watch?t=15156&v=W5XNOmyJr6I,15156,screencapture-localhost-8000-2022-01-25-10_57_57.png,,code: model_building; has rearranged his directories a bit,"target_dirs = os.listdir(""data/model_test_images_split/)
target_dirs

import random
def create_train_test_list(target_dir):
   random.seed(42)
   image_list = os.listdir(target_dir)
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test image list = list(set(image_list).difference(set(train_image_list)))
",513;284;835;389
393,2,https://www.youtube.com/watch?t=15182&v=W5XNOmyJr6I,15182,screencapture-localhost-8000-2022-01-25-10_58_55.png,,code: model_building; now back to creating a function to move the images. I'm a little confused here as I assume you'd want a test/train for each class you intend to use - he seems to be trying to put it all into a single directory,"# Create a function to move images
for image_dir in os.listdir(""model_test_images""):
   print(image_dir)
",516;302;547;91
394,2,https://www.youtube.com/watch?t=15226&v=W5XNOmyJr6I,15226,screencapture-localhost-8000-2022-01-25-11_00_49.png,,code: model_building; progress on the image moving function,"# Create a function to move images
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   print(image_dir)

test_image_list
",516;247;472;341
395,2,https://www.youtube.com/watch?t=15273&v=W5XNOmyJr6I,15273,screencapture-localhost-8000-2022-01-25-11_03_21.png,,"code: model_building; now trying to loop through the classes in the target directories, but missing a /","# Create a function to move images
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir): 
   print(image_dir)
   train_image_list, test_image_list = create 
   len(train_image_list), len(test_image_list)

test_image_list
",504;241;526;398
396,2,https://www.youtube.com/watch?t=15273&v=W5XNOmyJr6I,15273,screencapture-localhost-8000-2022-01-25-11_04_21.png,,output: no directory data/model_test_imagesanvil...missing a / and I'm not sure the subdirectory exists,,
398,2,https://www.youtube.com/watch?t=15352&v=W5XNOmyJr6I,15352,screencapture-localhost-8000-2022-01-25-11_13_57.png,,code: model_building; now printing directory and the length of each set.,"for image_dir in os.listdir(data_dir):
   print(image_dir)
   print(os.path.join(data_dir, image_dir))
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   print(len(train_image_list), len(test_image_list))
",519;199;1032;139
399,2,https://www.youtube.com/watch?t=15352&v=W5XNOmyJr6I,15352,screencapture-localhost-8000-2022-01-25-11_13_57.png,,output: seems to create a reasonable test/train set for both dirs.,"for image_dir in os.listdir(data_dir):
   print(image_dir)
   print(os.path.join(data_dir, image_dir))
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   print(len(train_image_list), len(test_image_list))
",519;188;1033;145
400,2,https://www.youtube.com/watch?t=15376&v=W5XNOmyJr6I,15376,screencapture-localhost-8000-2022-01-25-11_15_20.png,,code: model_building; printing entries in train image list,"# Create a function to move images
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   print(image_dir)
   print(os.path.join(data_dir, image_dir))
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   print(len(train_image_list), len(test_image_list))
   print(train_image_list[:5])
",507;247;1047;253
401,2,https://www.youtube.com/watch?t=15376&v=W5XNOmyJr6I,15376,screencapture-localhost-8000-2022-01-25-11_15_20.png,,output: we get just the image names,,
402,2,https://www.youtube.com/watch?t=15376&v=W5XNOmyJr6I,15376,screencapture-localhost-8000-2022-01-25-11_15_20.png,,"goal: ""We actually want the full path there""","# Create a function to move images
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   print(image_dir)
   print(os.path.join(data_dir, image_dir))
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   print(len(train_image_list), len(test_image_list))
   print(train_image_list[:5])
",519;244;1036;253
404,2,https://www.youtube.com/watch?t=15424&v=W5XNOmyJr6I,15424,screencapture-localhost-8000-2022-01-25-11_20_39.png,,output: directories are part of the file listing.,,
406,2,https://www.youtube.com/watch?t=15536&v=W5XNOmyJr6I,15536,screencapture-localhost-8000-2022-01-25-11_23_07.png,,output: sensible directory is printed,"# Create a function to move images
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   print(image_dir)
   print(os.path.join(data_dir, image_dir))
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   print(len(train_image_list), len(test_image_list))
   print(train_image_list[:5])
   for image_path in train_image_list[:5]:
      dest_dir = os.path.join(target_dir, image_dir)
      print(dest_dir)
",519;257;1030;326
407,2,https://www.youtube.com/watch?t=15558&v=W5XNOmyJr6I,15558,screencapture-localhost-8000-2022-01-25-11_24_41.png,,goal: we're making training and test sets here - comments to copy training images and copy testing images.,,
408,2,https://www.youtube.com/watch?t=15577&v=W5XNOmyJr6I,15577,screencapture-localhost-8000-2022-01-25-11_27_05.png,,code: model_building; adding train to the image destination path,"print(image_dir)
print(os.path.join(data_dir, image_dir))
train_image_list, test_image_list = create_train_ 
print(len(train_image_list), len(test_image_list)
print(train_image_list[:5]) 

# Copy training images 
for image_path in train_image_list[:5]: 
   dest_dir = os.path.join(target_dir, ""train"", image_dir)
   print(dest_dir)

# Copy testing images
",543;191;715;311
409,2,https://www.youtube.com/watch?t=15579&v=W5XNOmyJr6I,15579,screencapture-localhost-8000-2022-01-25-11_27_53.png,,"output: now have ""train"" in the destination path",,
410,2,https://www.youtube.com/watch?t=15620&v=W5XNOmyJr6I,15620,screencapture-localhost-8000-2022-01-25-11_37_26.png,,code: model_building; getting the image name from the path and adding it to the destination path.,"print(image_dir)
print(os.path.join(data_dir, image_dir))
train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
print(len(train_image_list), len(test_image_list))
print(train_image_list[:5])

# Copy training images
for image_path in train_image_list[:5]:
   image_file_name = os.path.split(image_path) [-1]
   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(dest_dir)

# Copy testing images
",543;199;1021;350
411,2,https://www.youtube.com/watch?t=15622&v=W5XNOmyJr6I,15622,screencapture-localhost-8000-2022-01-25-11_38_03.png,,output: filename now at end of destination,,
412,2,https://www.youtube.com/watch?t=15634&v=W5XNOmyJr6I,15634,,,code: model_building; do the same for model test - except forgets to replace train with test in the dest path,,675;226;421;130
413,2,https://www.youtube.com/watch?t=15636&v=W5XNOmyJr6I,15636,screencapture-localhost-8000-2022-01-25-11_39_18.png,,output: dest path still says train,"print(os.path.join(data_dir, image_dir))
train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
print(len(train_image_list), len(test_image_list))
print(train_image_list[:5])

# Copy training images
for image_path in train_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(dest_dir)

# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(dest_dir)
",552;196;1003;425
416,2,https://www.youtube.com/watch?t=15644&v=W5XNOmyJr6I,15644,screencapture-localhost-8000-2022-01-25-11_41_58.png,,output: now test ones say test,,
417,2,https://www.youtube.com/watch?t=15656&v=W5XNOmyJr6I,15656,screencapture-localhost-8000-2022-01-25-12_14_58.png,,code: model_building; removing a bunch of print statements,"data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   # print(image_dir)
   # print(os.path.join(data_dir, image_dir))
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   # print(len(train_image_list), len(test_image_list))

# Copy training images 
for image_path in train_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(dest_dir)

# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest dir = os.path.ioin(target_dir, ""test"", image_dir, image_file_name)
",519;191;1036;485
418,2,https://www.youtube.com/watch?t=15679&v=W5XNOmyJr6I,15679,screencapture-localhost-8000-2022-01-25-12_16_10.png,,code: model_building; adding print statement moving target to dest,"data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   # print(image_dir)
   # print(os.path.join(data_dir, image_dir))
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   # print(len(train_image_list), len(test_image_list))

# Copy training images
for image_path in train_image_list[:5]:
   image_file_name = os.path.split(image_path) [-1]
   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(f""Moving: {image_path} to {dest_dir}"")

# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest dir = os.path.ioin(target_dir, ""test"", image_dir, image_file_name)
",516;193;1033;476
420,2,https://www.youtube.com/watch?t=15687&v=W5XNOmyJr6I,15687,screencapture-localhost-8000-2022-01-25-12_18_09.png,,output: resulting moving messages,,
421,2,https://www.youtube.com/watch?t=15705&v=W5XNOmyJr6I,15705,screencapture-localhost-8000-2022-01-25-12_19_53.png,,code: model_building; formatting print statement for readability,"print(f""Moving: {image_path} to {dest_dir}"")

# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)
   print(f""Moving: \n{image_path} to \n{dest_dir}"")
",552;196;823;205
422,2,https://www.youtube.com/watch?t=15719&v=W5XNOmyJr6I,15719,screencapture-localhost-8000-2022-01-25-12_20_57.png,,code: model_building; replacing moving with copying in print msg,"train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
# print(len(train_image_list), len(test_image_list))

# Copy training images
for image_path in train_image_list[:5]:
   image_file_name = os.path.split(image_path) [-1]
   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print{(f“Copying: {image_path} to {dest_dir}"")

# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path) [-1]
   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)
   print{(f""Copying: \n{image_path} to \n{dest_dir}"")]
",561;191;985;380
423,2,https://www.youtube.com/watch?t=15821&v=W5XNOmyJr6I,15821,screencapture-localhost-8000-2022-01-25-12_23_14.png,,search: python shutil copy; he's got everything set up to do the copy so now looking up the right method I guess,,
424,2,https://www.youtube.com/watch?t=15825&v=W5XNOmyJr6I,15825,screencapture-localhost-8000-2022-01-25-12_24_04.png,,visit: How do I copy a file in python;,,
425,2,https://www.youtube.com/watch?t=15863&v=W5XNOmyJr6I,15863,screencapture-localhost-8000-2022-01-25-12_25_12.png,,"code: model_building; adding in copy command, renaming var name for consistency","# Copy training images
for image_path in train_image_list[:5]:
   image_file_name = os.path.split(image_path) [-1]
   dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(f""Copying: {image_path} to {dest_path}"") 

# Copy testing images 
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path) [-1]
   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)
   print(f""Copying: \n{image_path} to \n{dest_path} ]
   copy2(image_path, dest_path)
",546;217;853;326
427,2,https://www.youtube.com/watch?t=15868&v=W5XNOmyJr6I,15868,screencapture-localhost-8000-2022-01-25-12_27_44.png,,output: error - no such file or directory in the destination,,
428,2,https://www.youtube.com/watch?t=15938&v=W5XNOmyJr6I,15938,screencapture-localhost-8000-2022-01-25-12_29_29.png,,code: model_building; make target directory,"for image_dir in os.listdir(data_dir): 
   # Make target directory
   os.makdirs(os.path.join(target_dir, image_dir), exists_ok=True)
   # print(image_dir)
   # print(os.path.join(data_dir, image_dir))

   # Make training and test lists of target images
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   # print(len(train_image_list), len(test_image_list))

   # Copy training images
   for image_path in train_image_list[:5]:
      image_file_name = os.path.split(image_path)[-1] 
      dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)
      print(f""Copying: {image_path} to {dest_path}"") :
      copy2(image_path, dest_path) }

   # Copy testing images 
",507;193;1054;470
429,2,https://www.youtube.com/watch?t=15941&v=W5XNOmyJr6I,15941,screencapture-localhost-8000-2022-01-25-12_30_02.png,,output: os has no attribute makdirs,,
430,2,https://www.youtube.com/watch?t=15947&v=W5XNOmyJr6I,15947,screencapture-localhost-8000-2022-01-25-12_31_03.png,,code: model_building; fix makdirs,"# Create a function to move images
from shutil import copy2
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   # Make target directory
   os.makedirs(os.path.join(target_dir, image dir), exists_ok=True)
   # print(image_dir)
   # print(os.path.join(data_dir, image_dir))

   # Make training and test lists of target images
",510;365;748;308
431,2,https://www.youtube.com/watch?t=15949&v=W5XNOmyJr6I,15949,screencapture-localhost-8000-2022-01-25-12_34_03.png,,output: exists_ok doesn't exist.,,
433,2,https://www.youtube.com/watch?t=15946&v=W5XNOmyJr6I,15946,screencapture-localhost-8000-2022-01-25-12_36_02.png,,output: directory still doesn't exist,,
434,2,https://www.youtube.com/watch?t=16172&v=W5XNOmyJr6I,16172,screencapture-localhost-8000-2022-01-25-12_40_04.png,,code: model_building; new helper function to make the necessary directories and move the files,"def copy_images_to_file(img_path_list, target_dir, train=True):
   if train:
      # Make target directory
      os.makedirs(os.path.join(target_dir, ""train""), exist_ok=True)
   else:
      os.makedirs(os.path.join(target_dir, ""test""), exist_ok=True)

   # Copy images
   for image_path in train_image_list[:5]:
      image_file_name = os.path.split(image_path) [-1]
      dest_path = os.path.join(target_dir, image_dir, image_file_name)
      print(f""Copying: {image_path} to {dest_path}"")
      copy2(image_path, dest_path)
",558;214;778;362
435,2,https://www.youtube.com/watch?t=16246&v=W5XNOmyJr6I,16246,screencapture-localhost-8000-2022-01-25-12_41_53.png,,code: model_building; cleaning up method a little,"      # Make target directory
      split_dir = ""train""
      os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)
   else:
      split_dir = ""test""
      os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)

   # Copy images
   for image_path in train_image_list[:5]:
      image_file_name = os.path.split(image_path) [-1]
      dest_path = os.path.join(target_dir, image_dir, image_file_name)
      print(f""Copying: {image_path} to (dest_path}"")
      copy2(image_path, dest_path)

# Copy testing images
for image_path in test_image_list[:5]:
",558;199;787;473
436,2,https://www.youtube.com/watch?t=16250&v=W5XNOmyJr6I,16250,screencapture-localhost-8000-2022-01-25-12_42_37.png,,code: model_building; adding split dir to the dest path,"         # Make target directory
         split_dir = ""train""
         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)
      else:
         split_dir = ""test""
         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)

      # Copy images
      for image_path in train_image_list[:5]:
         image_file_name = os.path.split(image_path) [-1]
         dest_path = os.path.join(target_dir, image_dir, split_dir, image_file_name)
         print(f""Copying: {image_path} to {dest_path}"")
         copy2(image_path, dest_path)I

   # Copy testing images
   for image path in test_image_list[:5]:
",561;191;895;482
437,2,https://www.youtube.com/watch?t=16283&v=W5XNOmyJr6I,16283,screencapture-localhost-8000-2022-01-25-12_43_53.png,,code: model_building; moves completed function out of the current code block and to its own (was defined kind of in the middle of another function),"      # Copy images
      for image_path in img_path_list[:5]:
         image_file_name = os.path.split(image_path) [-1]
         dest_path = os.path.join(target_dir, image_dir, split_dir, image_file_name)
         print(f""Copying: {image_path} to {dest_path}"")
         copy2(image_path, dest_path)

# Create a function to move images
from shutil import copy2
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   # print(image_dir)
   # print(os.path.join(data_dir, image_dir))
",516;193;931;470
439,2,https://www.youtube.com/watch?t=16422&v=W5XNOmyJr6I,16422,,,code: model_building; fixing for test examples,,675;226;421;130
440,2,https://www.youtube.com/watch?t=16424&v=W5XNOmyJr6I,16424,screencapture-localhost-8000-2022-01-25-12_49_20.png,,code: model_building; deleting old copy testing code,"   # Copy testing images
   copy_images_to_file(img_path_list=test_image_list,
      target_dir=target_dir,
      train=False)
",549;238;556;133
441,2,https://www.youtube.com/watch?t=16424&v=W5XNOmyJr6I,16424,screencapture-localhost-8000-2022-01-25-12_50_55.png,,output: file not found error copying first anvil file over,,
442,2,https://www.youtube.com/watch?t=16432&v=W5XNOmyJr6I,16432,screencapture-localhost-8000-2022-01-25-12_51_36.png,,output: no such file or directory anvil/train/file,,
443,2,https://www.youtube.com/watch?t=16463&v=W5XNOmyJr6I,16463,screencapture-localhost-8000-2022-01-25-12_54_21.png,,code: model_building; adding a dir to make,"def copy_images_to_file(img_path_list, target_dir, train=True):
      if train:
         # Make target directory
         split_dir = ""train""
         dir_to_make = os.path.join(target_dir, split_dir) 
         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)
      else:
         split_dir = ""test""
         os.makedirs(os.path.join(target_dir, split_dir), exist_ok=True)

      # Copy images
      for image_path in img_path_list[:5]:
",510;332;817;335
445,2,https://www.youtube.com/watch?t=16587&v=W5XNOmyJr6I,16587,screencapture-localhost-8000-2022-01-25-13_50_29.png,,output: no such file or directory,test_image_list,
446,2,https://www.youtube.com/watch?t=16688&v=W5XNOmyJr6I,16688,screencapture-localhost-8000-2022-01-25-13_52_41.png,,code: model_building; moving mkdirs around,"data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   # print(image_dir)
   # print(os.path.join(data_dir, image_dir))
   for split_dir in [""train"", ""test""]:
      os.makedirs(os.path.join(target_dir, image_dir, split_dir))

   # Make training and test lists of target images
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   # print(len(train_image_list), len(test_image_list)) 

   # Copy training images
   copy_images_to_file(img_path_list=train_image_list,
      target_dir=target_dir,
      train=True)

# Copy testing images
",510;196;1057;473
447,2,https://www.youtube.com/watch?t=16695&v=W5XNOmyJr6I,16695,screencapture-localhost-8000-2022-01-25-13_53_28.png,,code: model_building; adding exist_ok option to mkdirs,"data_dir = ""data/model_test_images"" 
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   # print(image_dir) 
   # print(os.path.join(data_dir, image_dir))
   for split_dir in [""train"", ""test""]: 
      os.makedirs(os.path.join(target_dir, image_dir, split_dir), exist_ok=True)

   # Make training and test lists of target images
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   # print(len(train_image_list), len(test_image_list))

   # Copy training images
   copy_images_to_file(img_path_list=train_image_list,
      target_dir=target_dir,
      train=True)
",522;193;1036;437
448,2,https://www.youtube.com/watch?t=16696&v=W5XNOmyJr6I,16696,screencapture-localhost-8000-2022-01-25-13_54_09.png,,output: seems to be copying now.,,
449,2,https://www.youtube.com/watch?t=16733&v=W5XNOmyJr6I,16733,screencapture-localhost-8000-2022-01-25-13_55_40.png,,"goal: ""Oh no, we need the reverse!""; he's put test and train into each class, but wants to have a test and train at the top level with the classes airplane and anvil underneath that.",,
451,2,https://www.youtube.com/watch?t=16829&v=W5XNOmyJr6I,16829,screencapture-localhost-8000-2022-01-25-14_04_42.png,,code: model_building; remove some of the mkdir logic split into test and train and print target_dir.,"def copy_images_to_file(img_path_list, target_dir, train=True):
   if train:
      print(target_dir)
      os.makedirs(os.p 
else:
   split_dir = ""tes
   os.makedirs(os.p

   #Copy images
   for image_path in im 
      image_file_name 
      dest_path = os.p
      print(f""Copying: 
      copy2(image_path, dest_path)
",516;272;961;389
452,2,https://www.youtube.com/watch?t=16832&v=W5XNOmyJr6I,16832,screencapture-localhost-8000-2022-01-25-14_05_49.png,,output: split_dir has no value (due to deleted code),,
453,2,https://www.youtube.com/watch?t=16922&v=W5XNOmyJr6I,16922,screencapture-localhost-8000-2022-01-25-14_08_26.png,,code: model_building; complete reversal of the two directories,"def copy_images_to_file(img_path_list, target_dir, train=True):
   if train:
      split_dir = ""train""
   else:
      split_dir = ""test"" 

   # Copy images
   for image_path in img_path_list[:5]:
      image_file_name = os.path.split(image_path) [-1]
      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)
      print(f""Copying: {image_path} to {dest_path}"")
      copy2(image_path, dest_path)
",519;257;934;332
454,2,https://www.youtube.com/watch?t=16924&v=W5XNOmyJr6I,16924,screencapture-localhost-8000-2022-01-25-14_09_08.png,,output: seems to move files to the right spot test/anvil/file,,
455,2,https://www.youtube.com/watch?t=16963&v=W5XNOmyJr6I,16963,screencapture-localhost-8000-2022-01-25-14_10_33.png,,code: model_building; remove commented code,"target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   for split_dir in [""train"", ""test""]:
      os.makedirs(os.path.join(target_dir, split_dir, image_dir), exist_ok=True)

   # Make training and test lists of target images
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   # print(len(train_image_list), len(test_image_list))

   # Copy training images
   copy_images_to_file(img_path_list=train_image_list,
      target_dir=target_dir,
      train=True)

   # Copy testing images
      copy_images_to_file(img_path_list=test_image_list,
         target_dir=target_dir,
         train=False)
",510;193;1066;473
457,2,https://www.youtube.com/watch?t=17021&v=W5XNOmyJr6I,17021,screencapture-localhost-8000-2022-01-25-14_14_50.png,,code: model_building; removed some unused code so now there's nothing after the code that moves images to test/train dirs.,"
",675;226;421;130
458,2,https://www.youtube.com/watch?t=17052&v=W5XNOmyJr6I,17052,screencapture-localhost-8000-2022-01-25-14_16_15.png,,"goal: outlining the next steps 1)make model datasets, 2) build model, 3)evaluate model, 4)convert to tflite for deployment",,
459,2,https://www.youtube.com/watch?t=17389&v=W5XNOmyJr6I,17389,screencapture-localhost-8000-2022-01-25-14_28_57.png,,goal: now let's build a model...so we need to load the data,,
460,2,https://www.youtube.com/watch?t=17410&v=W5XNOmyJr6I,17410,screencapture-localhost-8000-2022-01-25-14_29_47.png,,code: model_building; start by importing tensorflow - do I have tensorflow? he previously checked this,"import tensorflow as tf
",516;344;280;58
461,2,https://www.youtube.com/watch?t=17487&v=W5XNOmyJr6I,17487,screencapture-localhost-8000-2022-01-25-14_31_58.png,,code: model_building; define train and test dir and print them,,675;226;421;130
462,2,https://www.youtube.com/watch?t=17487&v=W5XNOmyJr6I,17487,screencapture-localhost-8000-2022-01-25-14_31_58.png,,output: they seem to be defined,"train_dir = ""data/model_test_images_split/train""
test_dir = ""data/model_test_images_split/test""
train_dir, test_dir
",519;299;523;91
463,2,https://www.youtube.com/watch?t=17588&v=W5XNOmyJr6I,17588,screencapture-localhost-8000-2022-01-25-14_40_39.png,,revisit: keras image dataset from directory; he found this at the beginning in his preparation to switch over to the model building part of the process,,
465,2,https://www.youtube.com/watch?t=17649&v=W5XNOmyJr6I,17649,screencapture-localhost-8000-2022-01-25-14_43_07.png,,output: lots of tf output,"# Load in data
train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,
   batch_size=32,
   image_size=(224, 224)
)

test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,
   batch_size=32,
   image_size=(224, 224)
)

train_data = test_data
",156;350;793;317
466,2,https://www.youtube.com/watch?t=17649&v=W5XNOmyJr6I,17649,screencapture-localhost-8000-2022-01-25-14_43_56.png,,"goal: ""we want to get rid of the..."" tensorflow bonus info",,
468,2,https://www.youtube.com/watch?t=17671&v=W5XNOmyJr6I,17671,screencapture-localhost-8000-2022-01-25-14_46_01.png,,output: seems to have found everything correctly,"   image_size=(224, 224)
}

train_data, test_data
",162;196;406;109
469,2,https://www.youtube.com/watch?t=17708&v=W5XNOmyJr6I,17708,screencapture-localhost-8000-2022-01-25-14_47_15.png,,"goal: build a first model with a small amount of data (aircraft, anvil)",,
471,2,https://www.youtube.com/watch?t=17740&v=W5XNOmyJr6I,17740,screencapture-localhost-8000-2022-01-25-14_48_22.png,,code: model_building; prefetching all of the data - lucky we got a big dog GPU because this is going to be....,"train_data = train_data.prefetch(tf.data.AUTOTUNE)
test_data = test_data.prefetch(tf.data.AUTOTUNE)
",165;317;553;76
472,2,https://www.youtube.com/watch?t=17789&v=W5XNOmyJr6I,17789,screencapture-localhost-8000-2022-01-25-14_50_05.png,,"search: efficient net B0; autocompletion isn't cooperating at the moment ""let's just go to the docs""",,
473,2,https://www.youtube.com/watch?t=17791&v=W5XNOmyJr6I,17791,screencapture-localhost-8000-2022-01-25-14_50_53.png,,search: images efficient net B0; not sure yet why we want an image here,,
474,2,https://www.youtube.com/watch?t=17802&v=W5XNOmyJr6I,17802,screencapture-localhost-8000-2022-01-25-15_00_16.png,,"visit: EfficientNet: Improving Accuracy and Efficiency through AutoML and Model Scaling; ""this is efficientnet - it's a convolutional neural network""",,
475,2,https://www.youtube.com/watch?t=17824&v=W5XNOmyJr6I,17824,screencapture-localhost-8000-2022-01-25-15_02_07.png,,other: closing a bunch of tabs in that task switch pattern we saw before,,
476,2,https://www.youtube.com/watch?t=17833&v=W5XNOmyJr6I,17833,screencapture-localhost-8000-2022-01-25-15_02_53.png,,search: tensorflow efficientnetb0;,,
477,2,https://www.youtube.com/watch?t=17836&v=W5XNOmyJr6I,17836,screencapture-localhost-8000-2022-01-25-15_03_31.png,,visit: tf.keras.application.efficientnet.EfficientNetB0;,,
478,2,https://www.youtube.com/watch?t=17894&v=W5XNOmyJr6I,17894,screencapture-localhost-8000-2022-01-25-15_05_04.png,,code: model_building; getting tensorflow model- this is largely pre-trained on imagenet data.,"base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model
",162;235;739;67
479,2,https://www.youtube.com/watch?t=17891&v=W5XNOmyJr6I,17891,screencapture-localhost-8000-2022-01-25-15_06_31.png,,output: downloading from googleapis,,
480,2,https://www.youtube.com/watch?t=18026&v=W5XNOmyJr6I,18026,screencapture-localhost-8000-2022-01-25-15_10_38.png,,search: tensorflow functional api; he's got half written code on the left and is looking for the syntax for something,,
481,2,https://www.youtube.com/watch?t=18058&v=W5XNOmyJr6I,18058,screencapture-localhost-8000-2022-01-25-15_12_02.png,,code: model_building; initial model building code.,"base_model = tf.keras.applications.EfficientNetB0(include_top=False)

# Make model untrainable
base_model.trainable = False

# Build a functional model
input = tf.keras.layers.Input(shape=(224, 223, 3))
x = base_model(input)
x = tf.keras.layers.GlobalAveragePooling2D() (x)
",159;320;739;260
482,2,https://www.youtube.com/watch?t=18058&v=W5XNOmyJr6I,18058,screencapture-localhost-8000-2022-01-25-15_12_02.png,,revisit: tf.keras.application.efficientnet.EfficientNetB0;,,
483,2,https://www.youtube.com/watch?t=18063&v=W5XNOmyJr6I,18063,screencapture-localhost-8000-2022-01-26-09_48_57.png,,search: tensorflow functional api; this is actually a revisit of an earlier search where he didn't use the results but didn't close them either.,,
484,2,https://www.youtube.com/watch?t=18064&v=W5XNOmyJr6I,18064,screencapture-localhost-8000-2022-01-26-09_49_59.png,,visit: tensorflow functional api;,,
485,2,https://www.youtube.com/watch?t=18148&v=W5XNOmyJr6I,18148,screencapture-localhost-8000-2022-01-26-09_52_19.png,,revisit: tf.keras.applications.efficientnet.EfficientNetB0; this is in support of explaining the significance of the include top False option in response to a chat question from an audience member,,
486,2,https://www.youtube.com/watch?t=18253&v=W5XNOmyJr6I,18253,screencapture-localhost-8000-2022-01-26-09_56_07.png,,"revisit: tf.keras.applications.efficientnet.EfficientNetB0; ""could we use?.."" he's started to define an output layer in the code.",,
487,2,https://www.youtube.com/watch?t=18261&v=W5XNOmyJr6I,18261,screencapture-localhost-8000-2022-01-26-09_57_36.png,,"goal: ""should we use efficientnet B2? Oh we'll compare them, that's what we'll use weights and biases for""",,
489,2,https://www.youtube.com/watch?t=18321&v=W5XNOmyJr6I,18321,screencapture-localhost-8000-2022-01-26-10_06_04.png,,output: error - inputs to a layer should be tensors,,
490,2,https://www.youtube.com/watch?t=18331&v=W5XNOmyJr6I,18331,screencapture-localhost-8000-2022-01-26-10_06_52.png,,"revisit: tf.keras.applications.efficientnet.EfficientNetB0; ""inputs to a layer should be tensors, why is that not working?""",,
491,2,https://www.youtube.com/watch?t=18337&v=W5XNOmyJr6I,18337,,,code: model_building; removes input from the path to Input,,675;226;421;130
492,2,https://www.youtube.com/watch?t=18338&v=W5XNOmyJr6I,18338,screencapture-localhost-8000-2022-01-26-10_08_37.png,,output: error - Input to a layer should be tensors; same error as before,"base_model = tf.keras.applications.EfficientNetB@(include_top=False)

# Make model untrainable
base_model.trainable = False

# Build a functional model
input_layer = tf.keras.Input(shape=(224, 223, 3))
x = base_model(input)
x = tf.keras.layers.GlobalAveragePooling2D() (x)
output_layer = tf.keras.layers.Dense(1)(x)

# Construct model
model_1 = tf.keras.Model(input_layer, output_layer)
model_1
",153;232;751;371
494,2,https://www.youtube.com/watch?t=18354&v=W5XNOmyJr6I,18354,screencapture-localhost-8000-2022-01-26-10_18_21.png,,output: successfully print a model - doesn't really say much yet,"base_model = tf.keras.applications.EfficientNetB0(include_top=False)

# Make model untrainable
base_model.trainable = False

# Build a functional model
input_layer = tf.keras.Input(shape=(224, 223, 3))
x = base_model(input_layer)
x = tf.keras.
output_layer

# Construct model
model_1 = tf.keras.Model(input_layer, output_layer)
model_1
",159;293;745;380
495,2,https://www.youtube.com/watch?t=18361&v=W5XNOmyJr6I,18361,screencapture-localhost-8000-2022-01-26-10_20_23.png,,"goal: ""now let's have a look at our model""",,
496,2,https://www.youtube.com/watch?t=18374&v=W5XNOmyJr6I,18374,screencapture-localhost-8000-2022-01-26-10_21_06.png,,goal: what's keras utils?,,
497,2,https://www.youtube.com/watch?t=18377&v=W5XNOmyJr6I,18377,screencapture-localhost-8000-2022-01-26-10_21_45.png,,search: keras plot model;,,
498,2,https://www.youtube.com/watch?t=18381&v=W5XNOmyJr6I,18381,screencapture-localhost-8000-2022-01-26-10_22_12.png,,visit: keras model plotting utilities;,,
499,2,https://www.youtube.com/watch?t=18394&v=W5XNOmyJr6I,18394,screencapture-localhost-8000-2022-01-26-10_23_23.png,,code: model_building; trying to plot model1,"tf.keras.utils.plot_model(model_1)
",147;331;405;58
500,2,https://www.youtube.com/watch?t=18394&v=W5XNOmyJr6I,18394,screencapture-localhost-8000-2022-01-26-10_23_23.png,,output: error - need to install pydot,"tf.keras.utils.plot_model(model_1)
",165;317;385;61
501,2,https://www.youtube.com/watch?t=18405&v=W5XNOmyJr6I,18405,screencapture-localhost-8000-2022-01-26-10_24_19.png,,code: model_building; pip install pydot,"tf.keras.utils.plot_model(model_1)

!pip install pydot
",156;220;394;305
502,2,https://www.youtube.com/watch?t=18428&v=W5XNOmyJr6I,18428,screencapture-localhost-8000-2022-01-26-10_25_23.png,,goal: lets's start getting weights and biases ready,,
503,2,https://www.youtube.com/watch?t=18485&v=W5XNOmyJr6I,18485,screencapture-localhost-8000-2022-01-26-10_26_47.png,,"visit: graphviz; this comes from a link in error message - need to install both pydot and graphviz ""oh I have to install a bunch of different things""",,
504,2,https://www.youtube.com/watch?t=18529&v=W5XNOmyJr6I,18529,screencapture-localhost-8000-2022-01-26-10_28_24.png,,search: weights and biases tensor flow; he seems to be wanting to lump all of the installation madness together.,,
505,2,https://www.youtube.com/watch?t=18535&v=W5XNOmyJr6I,18535,screencapture-localhost-8000-2022-01-26-10_29_27.png,,visit: Visualizing TensorFlow2 models with Weights and Biases;,,
506,2,https://www.youtube.com/watch?t=18557&v=W5XNOmyJr6I,18557,screencapture-localhost-8000-2022-01-26-10_30_22.png,,visit: tf2 CNN with W&B; link from previous page,,
507,2,https://www.youtube.com/watch?t=18577&v=W5XNOmyJr6I,18577,screencapture-localhost-8000-2022-01-26-10_31_53.png,,"other: copying a section of code; ""we want hyperparameters defaults config""",,
508,2,https://www.youtube.com/watch?t=18632&v=W5XNOmyJr6I,18632,screencapture-localhost-8000-2022-01-26-10_33_36.png,,code: model_building; installing pydot and wandb via pip,"!pip install pydot
!pip install wandb

import tensorflow as tf
tf.get_logger().setLevel('INFO')
",165;232;367;407
509,2,https://www.youtube.com/watch?t=18645&v=W5XNOmyJr6I,18645,screencapture-localhost-8000-2022-01-26-10_42_33.png,,"output: they seem to install ok; pydot already there, wandb generates lots of text, but all seems ok",,
510,2,https://www.youtube.com/watch?t=18646&v=W5XNOmyJr6I,18646,screencapture-localhost-8000-2022-01-26-10_43_40.png,,revisit: tf2 CNN with W&B; not sure what he's looking for exactly,,
511,2,https://www.youtube.com/watch?t=18666&v=W5XNOmyJr6I,18666,screencapture-localhost-8000-2022-01-26-10_46_18.png,,code: model_building; import wandb,"import wandb
",159;461;175;49
512,2,https://www.youtube.com/watch?t=18705&v=W5XNOmyJr6I,18705,screencapture-localhost-8000-2022-01-26-10_47_24.png,,"goal: ""we're going to get weights and biases working so we can compare two models""",,
513,2,https://www.youtube.com/watch?t=18718&v=W5XNOmyJr6I,18718,screencapture-localhost-8000-2022-01-26-10_49_02.png,,"revisit: Visualizing TensorFlow 2 models with Weights and Biases; ""how do they do that here""",,
514,2,https://www.youtube.com/watch?t=18748&v=W5XNOmyJr6I,18748,screencapture-localhost-8000-2022-01-26-10_51_47.png,,search: weights and biases tensor flow guide;,,
515,2,https://www.youtube.com/watch?t=18755&v=W5XNOmyJr6I,18755,screencapture-localhost-8000-2022-01-26-10_52_30.png,,"visit: Introduction to TensorFlow with Weights and Biases; ""what's this one saying""",,
516,2,https://www.youtube.com/watch?t=18776&v=W5XNOmyJr6I,18776,screencapture-localhost-8000-2022-01-26-10_53_28.png,,visit: WandB fashionMNIST tensorflow; I'm not sure what this page is about,,
517,2,https://www.youtube.com/watch?t=19063&v=W5XNOmyJr6I,19063,screencapture-localhost-8000-2022-01-26-10_59_24.png,,visit: weights and biases page; this is through his account that he has set up.,,
518,2,https://www.youtube.com/watch?t=19071&v=W5XNOmyJr6I,19071,screencapture-localhost-8000-2022-01-26-11_00_06.png,,revisit: WandB fashionMNIST tensorflow; this seems to be a set of steps about how to setup. he's just finished creating account as directed and is maybe returning to see what to do next,,
519,2,https://www.youtube.com/watch?t=19137&v=W5XNOmyJr6I,19137,screencapture-localhost-8000-2022-01-26-11_02_18.png,,code: model_building; initializing wandb - he's leveraging example code from a fashion scenario,"import wandb
wandb.init(project=""100k-livestream-video"", sync_tensorboard=True)
",159;269;718;88
520,2,https://www.youtube.com/watch?t=19158&v=W5XNOmyJr6I,19158,screencapture-localhost-8000-2022-01-26-11_03_38.png,,output: that seems to have run successfully,,
521,2,https://www.youtube.com/watch?t=19194&v=W5XNOmyJr6I,19194,screencapture-localhost-8000-2022-01-26-11_05_01.png,,revisit: tf2 CNN with W&B; he's muttering about the use of tf1,,
522,2,https://www.youtube.com/watch?t=19223&v=W5XNOmyJr6I,19223,screencapture-localhost-8000-2022-01-26-11_20_52.png,,search: weights and biases sync tensorboard;,,
523,2,https://www.youtube.com/watch?t=19230&v=W5XNOmyJr6I,19230,screencapture-localhost-8000-2022-01-26-11_21_41.png,,visit: TensorBoard;,,
524,2,https://www.youtube.com/watch?t=19252&v=W5XNOmyJr6I,19252,screencapture-localhost-8000-2022-01-26-11_24_02.png,,visit: Configure Experiments with wandb.config; this is a link from the documentation,,
525,2,https://www.youtube.com/watch?t=19265&v=W5XNOmyJr6I,19265,screencapture-localhost-8000-2022-01-26-11_24_53.png,,visit: Quickstart; also a tensorflow docs page,,
526,2,https://www.youtube.com/watch?t=19267&v=W5XNOmyJr6I,19267,screencapture-localhost-8000-2022-01-26-11_25_27.png,,"visit: TensorFlow; ""this is what I want""",,
527,2,https://www.youtube.com/watch?t=19303&v=W5XNOmyJr6I,19303,screencapture-localhost-8000-2022-01-26-11_26_36.png,,visit: tf-cnn-fashion; this seems to be a github associated with the fashion example project,,
528,2,https://www.youtube.com/watch?t=19351&v=W5XNOmyJr6I,19351,screencapture-localhost-8000-2022-01-26-11_28_25.png,,"code: model_building; he's just called plot model - ""this is what's happening now""",,675;226;421;130
529,2,https://www.youtube.com/watch?t=19351&v=W5XNOmyJr6I,19351,screencapture-localhost-8000-2022-01-26-11_28_25.png,,output:  image of the layers and how they are connected.,"tf.keras.utils.plot_model(model_l)
",147;241;493;79
530,2,https://www.youtube.com/watch?t=19360&v=W5XNOmyJr6I,19360,screencapture-localhost-8000-2022-01-26-11_30_00.png,,"code: model_building; added include shapes option ""do we have include shapes""","model_1 = tf.keras.Model(input_layer, output_layer)

tf.keras.utils.plot_model(model_1, include_shapes=True)
",150;193;640;199
531,2,https://www.youtube.com/watch?t=19360&v=W5XNOmyJr6I,19360,screencapture-localhost-8000-2022-01-26-11_30_00.png,,output: no it seems we do not have include shapes,"model_1 = tf.keras.Model(input_layer, output_layer)

tf.keras.utils.plot_model(model_1, include_shapes=True)
",153;188;622;184
532,2,https://www.youtube.com/watch?t=19366&v=W5XNOmyJr6I,19366,screencapture-localhost-8000-2022-01-26-11_30_49.png,,search: tensorflow keras plot model;,,
533,2,https://www.youtube.com/watch?t=19388&v=W5XNOmyJr6I,19388,screencapture-localhost-8000-2022-01-26-11_31_35.png,,visit: tf.keras.utils.plot_model;,,
534,2,https://www.youtube.com/watch?t=19395&v=W5XNOmyJr6I,19395,screencapture-localhost-8000-2022-01-26-11_36_10.png,,code: model_building; changed include shapes to show shapes,"model_1 = tf.keras.Model(input_layer, output_layer)

tf.keras.utils.plot_model(model_1, show_shapes=True)
",150;190;607;184
535,2,https://www.youtube.com/watch?t=19395&v=W5XNOmyJr6I,19395,screencapture-localhost-8000-2022-01-26-11_36_10.png,,output: that adds some details to the output image,,
536,2,https://www.youtube.com/watch?t=19464&v=W5XNOmyJr6I,19464,screencapture-localhost-8000-2022-01-26-11_38_26.png,,goal: let's compile the model; he's wondering about the connection to weights and biases - whether that will just happen,,
537,2,https://www.youtube.com/watch?t=19484&v=W5XNOmyJr6I,19484,screencapture-localhost-8000-2022-01-26-11_39_37.png,,"goal: ""we need an output activation""...because it's sigmoid. did someone miss that?",,
538,2,https://www.youtube.com/watch?t=19488&v=W5XNOmyJr6I,19488,screencapture-localhost-8000-2022-01-26-11_40_18.png,,code: model_building; adding activation to the output layer declaration,"input_tayer = tf.keras.input(shape=(224, 243, 3)) 
x = base_model(input_layer)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
output_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)

# Construct model
model_1 = tf.keras.Model(input_layer, output_layer)
",165;191;688;187
540,2,https://www.youtube.com/watch?t=19534&v=W5XNOmyJr6I,19534,screencapture-localhost-8000-2022-01-26-11_41_39.png,,goal: now let's fit the model,"# Compile model
model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),
   optimizer=tf.keras.optimizers.Adam(),
   metrics=[""accuracy""]
)
",159;329;637;151
541,2,https://www.youtube.com/watch?t=19559&v=W5XNOmyJr6I,19559,screencapture-localhost-8000-2022-01-26-11_50_54.png,,goal: create early stopping callback,,
542,2,https://www.youtube.com/watch?t=19607&v=W5XNOmyJr6I,19607,screencapture-localhost-8000-2022-01-26-11_52_08.png,,code: model_building; early stopping calls setup and the beginning of the model.fit call (still incomplete),"# Create EarlyStopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(patience=5,
   monitor=""val_loss""
)

# fit model
history_1 = model_1.fit(train_data,
  epochs=25,
)
",156;269;664;329
543,2,https://www.youtube.com/watch?t=19639&v=W5XNOmyJr6I,19639,screencapture-localhost-8000-2022-01-26-11_53_38.png,,code: model_building; model.fit attempt #1 ready to run,"# Create EarlyStopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(patience=5,
   monitor=""val_loss""
)

# Fit model
history_1 = model_1.fit((train_data,
   epochs=25,
   validation_data=test_data,
   callbacks=[early_stopping])
",165;263;655;365
544,2,https://www.youtube.com/watch?t=19664&v=W5XNOmyJr6I,19664,screencapture-localhost-8000-2022-01-26-11_54_35.png,,code: model_building; let's give the model a name,"yer = tf.keras.input(shape=(224, 223, 3))
_model(input_layer)
eras. layers.GlobalAveragePooling2D()(x)
ayer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)

act model
= tf.keras.Model(input_layer, output_layer, name=""EfficientNetB0-V1"")
",159;191;757;187
545,2,https://www.youtube.com/watch?t=19672&v=W5XNOmyJr6I,19672,screencapture-localhost-8000-2022-01-26-11_56_31.png,,code: model_building; change the # of epochs from 25 to 50,"# Create EarlyStopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(patience=5,
   monitor=""val_loss""
)

# Fit model
history_1 = model_1.fit(train_data,
   epochs=50,
   validation_data=test_data,
   callhacks:[early_stapping])
",159;266;664;359
546,2,https://www.youtube.com/watch?t=19682&v=W5XNOmyJr6I,19682,screencapture-localhost-8000-2022-01-26-11_58_30.png,,output: error - the first fit fails,"
",
547,2,https://www.youtube.com/watch?t=19691&v=W5XNOmyJr6I,19691,screencapture-localhost-8000-2022-01-26-11_58_30.png,,output: input 0 is incompatible with layer expected shape 224 223 3 vs 224 224 3; this is a typo he made ages ago. and is kind of interesting because that code won't have been accessed in a while so it represents a return that is only loosely task based,,
548,2,https://www.youtube.com/watch?t=19708&v=W5XNOmyJr6I,19708,screencapture-localhost-8000-2022-01-26-12_05_00.png,,code: model_building; changes 223 to 224 in Input declaration,"base_model = tf.keras.applications.EfficientNetB@(include_top=False)

# Make model untrainable
base_model.trainable = False

# Build a functional model
input_layer = tf.keras.Input(shape=(224, 224, 3))
x = base_model(input_layer)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
output_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)

# Construct model 
model_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetBo-
",159;244;799;347
550,2,https://www.youtube.com/watch?t=19735&v=W5XNOmyJr6I,19735,screencapture-localhost-8000-2022-01-26-12_06_07.png,,output: basic performance statistics.,"model_1.evaluate(test_data)
",159;416;319;58
551,2,https://www.youtube.com/watch?t=19769&v=W5XNOmyJr6I,19769,screencapture-localhost-8000-2022-01-26-12_08_52.png,,"revisit: tf2 CNN with W&B; ""there's no clear statement here that tells me how to use a log""",,
552,2,https://www.youtube.com/watch?t=19832&v=W5XNOmyJr6I,19832,screencapture-localhost-8000-2022-01-26-12_11_28.png,,"output: he's re-run the training process and now gets 95% accuracy, not sure why it's different this time.",,
553,2,https://www.youtube.com/watch?t=19841&v=W5XNOmyJr6I,19841,screencapture-localhost-8000-2022-01-26-13_02_24.png,,other: this is another closing of several tabs moment... he's muttering about weights and biases.,,
554,2,https://www.youtube.com/watch?t=19844&v=W5XNOmyJr6I,19844,screencapture-localhost-8000-2022-01-26-13_03_56.png,,revisit: tensorflow overview page;,,
555,2,https://www.youtube.com/watch?t=19869&v=W5XNOmyJr6I,19869,screencapture-localhost-8000-2022-01-26-13_04_58.png,,revisit: TensorBoard documentation;,,
556,2,https://www.youtube.com/watch?t=19885&v=W5XNOmyJr6I,19885,screencapture-localhost-8000-2022-01-26-13_05_54.png,,goal: let's get tensorflow logs,,
557,2,https://www.youtube.com/watch?t=19890&v=W5XNOmyJr6I,19890,screencapture-localhost-8000-2022-01-26-13_06_46.png,,visit: book (his) zero to mastery TensorFlow for Deep Learning; this may turn out to be a plug for himself rather than development related.,,
558,2,https://www.youtube.com/watch?t=19961&v=W5XNOmyJr6I,19961,screencapture-localhost-8000-2022-01-26-13_09_11.png,,code: model_building; copying in tensorflow callback code that he's copied from his book,"# Get helper_functions.py script from course GitHub
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learni

# Impart helper functions we're going to use
from helper_functions import create_tensorboard_callback, plot_loss_curve
",162;332;769;145
559,2,https://www.youtube.com/watch?t=19986&v=W5XNOmyJr6I,19986,screencapture-localhost-8000-2022-01-26-13_10_23.png,,code: model_building; he moves the tensorboard callback up to the top where he's done installs of various things,"!pip install pydot
!pip install wandb 
# Get helper_functions.py script from course GitHub
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learni

# Import helper functions we're going to use
from helper_functions import create_tensorboard_callback, plot_loss_curve
",168;229;769;205
560,2,https://www.youtube.com/watch?t=19997&v=W5XNOmyJr6I,19997,screencapture-localhost-8000-2022-01-26-13_11_16.png,,goal: so now we're going to import helper functions,,
561,2,https://www.youtube.com/watch?t=20021&v=W5XNOmyJr6I,20021,screencapture-localhost-8000-2022-01-26-13_12_09.png,,"goal: we're going to get weights and biases logging up here. he notes that the image downloads have now finished, making it possible to train a model with a bigger dataset.",,
562,2,https://www.youtube.com/watch?t=20105&v=W5XNOmyJr6I,20105,,,code: model_building; adding callback for tensorboard in the model.fit call,,675;226;421;130
563,2,https://www.youtube.com/watch?t=20124&v=W5XNOmyJr6I,20124,screencapture-localhost-8000-2022-01-26-13_21_45.png,,revisit: book (his) zero to mastery TensorFlow for Deep Learning; he's checking the new code against his example,,
564,2,https://www.youtube.com/watch?t=20149&v=W5XNOmyJr6I,20149,screencapture-localhost-8000-2022-01-26-13_22_43.png,,code: model_building; more details on tensorboard callback,"# Fit model
history_1 = model_1.fit(train_data,
   epochs=50,
   validation_data=test_data,
   callbacks=[early_stopping,
      create_tensorboard_callback(""logs"", str(model_1.name))])
",510;473;1003;172
565,2,https://www.youtube.com/watch?t=20153&v=W5XNOmyJr6I,20153,screencapture-localhost-8000-2022-01-26-13_23_24.png,,code: model_building; model_1.name,"model_1.name

# Fit model
history_1 = model_1.fit(train_data,
   epochs=50,
   validation_data=test_data,
   callbacks=[early_stopping,
",507;350;625;320
566,2,https://www.youtube.com/watch?t=20156&v=W5XNOmyJr6I,20156,screencapture-localhost-8000-2022-01-26-13_24_52.png,,output: write out the name which is EfficientNetB0-V1,,
567,2,https://www.youtube.com/watch?t=20156&v=W5XNOmyJr6I,20156,screencapture-localhost-8000-2022-01-26-13_24_52.png,,code: model_building; cast name to string,"str(model_1.name)

# Fit model
history_1 = model_1.fit(train_data,
   epochs=50,
   validation_data=test_data,
   callbacks=[early_stopping,
      create_tensorboard_callback(""logs"", str(model_1.name))])
",513;302;988;362
568,2,https://www.youtube.com/watch?t=20180&v=W5XNOmyJr6I,20180,,,"code: model_building; model fit is missing a ,",,675;226;421;130
569,2,https://www.youtube.com/watch?t=20216&v=W5XNOmyJr6I,20216,screencapture-localhost-8000-2022-01-26-13_27_57.png,,revisit: weights and biases page; he's checking to see if the data logged into weights and biases.,,
570,2,https://www.youtube.com/watch?t=20223&v=W5XNOmyJr6I,20223,screencapture-localhost-8000-2022-01-26-13_28_34.png,,output: warning from weights and biases about the use of several even logs.,,
571,2,https://www.youtube.com/watch?t=20257&v=W5XNOmyJr6I,20257,screencapture-localhost-8000-2022-01-26-13_29_32.png,,code: model_building; adding a log dir when w and b is initialized,"import wandb
wandb.tensorboard.patch(root_logdir:""logs/"")
wandb.init(project=""100k-livestream-video"", sync_tensorboard=True)
",501;344;733;94
572,2,https://www.youtube.com/watch?t=20269&v=W5XNOmyJr6I,20269,screencapture-localhost-8000-2022-01-26-13_30_24.png,,output: error - tensorboard is already patched,,
573,2,https://www.youtube.com/watch?t=20273&v=W5XNOmyJr6I,20273,screencapture-localhost-8000-2022-01-26-13_30_54.png,,code: model_building; removes the tensorboard piece from init.,"import wandb
wandb.tensorboard.patch(root_logdir=""logs"")
wandb.init(project=""100k-livestream-video"")
",522;296;484;100
574,2,https://www.youtube.com/watch?t=20273&v=W5XNOmyJr6I,20273,,,code: model_building; also removes the / after logs,,675;226;421;130
575,2,https://www.youtube.com/watch?t=20281&v=W5XNOmyJr6I,20281,screencapture-localhost-8000-2022-01-26-13_33_07.png,,code: model_building; comments out init call,"import wandb
wandb.tensorboard.patch(root_logdir=""logs"")
# wandb.init(project=""100k-livestream-video"")
",519;446;505;94
576,2,https://www.youtube.com/watch?t=20296&v=W5XNOmyJr6I,20296,screencapture-localhost-8000-2022-01-26-13_33_48.png,,output: error - tensorboard is already patched.,,
577,2,https://www.youtube.com/watch?t=20324&v=W5XNOmyJr6I,20324,screencapture-localhost-8000-2022-01-26-13_34_57.png,,code: model_building; removing patch call and bringing the init call with sync_tensorboard back,"import wandb
# wandb.tensorboard.patch(root_logdir=""logs"")
wandb.init(project=""100k—livestream-video"", sync_tensorboard=True)
",516;287;706;97
578,2,https://www.youtube.com/watch?t=20333&v=W5XNOmyJr6I,20333,screencapture-localhost-8000-2022-01-26-13_35_41.png,,"search: weights and biases sync tensorboard; he's getting a little frustrated with the feedback ""don't just tell me to...""",,
579,2,https://www.youtube.com/watch?t=20339&v=W5XNOmyJr6I,20339,screencapture-localhost-8000-2022-01-26-13_36_41.png,,revisit: book (his) zero to mastery TensorFlow for Deep Learning; not sure what he's looking for exactly,,
580,2,https://www.youtube.com/watch?t=20344&v=W5XNOmyJr6I,20344,screencapture-localhost-8000-2022-01-26-13_37_20.png,,revisit: Tensorboard docs;,,
581,2,https://www.youtube.com/watch?t=20365&v=W5XNOmyJr6I,20365,screencapture-localhost-8000-2022-01-26-13_38_16.png,,visit: Experiment Logging with Tensorboard and wandb; this is a link from his weights and biases sync tensorboard search,,
582,2,https://www.youtube.com/watch?t=20411&v=W5XNOmyJr6I,20411,screencapture-localhost-8000-2022-01-26-13_40_13.png,,revisit: book (his) zero to mastery TensorFlow for Deep Learning;,,
583,2,https://www.youtube.com/watch?t=20437&v=W5XNOmyJr6I,20437,screencapture-localhost-8000-2022-01-26-13_41_08.png,,other: starting tensorboard and setting the logdir; this seems to be another application running in the background?,,
584,2,https://www.youtube.com/watch?t=20450&v=W5XNOmyJr6I,20450,screencapture-localhost-8000-2022-01-26-13_42_08.png,,"visit: localhost; ""there we go, ok we're on"" we're getting back weights and biases info ",,
585,2,https://www.youtube.com/watch?t=20471&v=W5XNOmyJr6I,20471,screencapture-localhost-8000-2022-01-26-13_45_06.png,,"goal: ""now we need a bigger data set""",,
586,2,https://www.youtube.com/watch?t=20518&v=W5XNOmyJr6I,20518,screencapture-localhost-8000-2022-01-26-13_46_15.png,,goal: we need to split our data into food and non-food images. how about we do that?,,
587,2,https://www.youtube.com/watch?t=20583&v=W5XNOmyJr6I,20583,screencapture-localhost-8000-2022-01-26-13_48_10.png,,revisit: weights and biases page (his account); now there's some actual data there.,,
588,2,https://www.youtube.com/watch?t=20664&v=W5XNOmyJr6I,20664,screencapture-localhost-8000-2022-01-26-13_50_25.png,,revisit: Experiment Logging with Tensorboard and wandb; not sure what he's looking for,,
589,2,https://www.youtube.com/watch?t=20723&v=W5XNOmyJr6I,20723,screencapture-localhost-8000-2022-01-26-13_51_59.png,,code: model_building; adding in wandb.init before the model fit command,"# Create EarlyStopping callback and TensorBoard callback
early_stopping = tf.keras.callbacks.EarlyStopping(patience=5,
   monitor=""val_loss""
)

# Fit model
wandb.init(sync_tensorboard=True)
history_1 = model_1.fit(train_data,
   epochs=50,
   validation_data=test_data
",516;323;661;350
590,2,https://www.youtube.com/watch?t=20813&v=W5XNOmyJr6I,20813,screencapture-localhost-8000-2022-01-26-13_58_19.png,,revisit: weights and biases page (his account); he's trying to add a visualization,,
591,2,https://www.youtube.com/watch?t=20879&v=W5XNOmyJr6I,20879,screencapture-localhost-8000-2022-01-26-13_59_57.png,,search: weights and biases log tensorboard logs;,,
592,2,https://www.youtube.com/watch?t=20887&v=W5XNOmyJr6I,20887,screencapture-localhost-8000-2022-01-26-14_00_50.png,,"visit: Logging with Weights & Biases - Monitoring your neural network's training made easy; ""I actually don't know why this isn't working"" he's now exploring new links but has done this same search before.",,
593,2,https://www.youtube.com/watch?t=20988&v=W5XNOmyJr6I,20988,screencapture-localhost-8000-2022-01-26-14_03_51.png,,revisit: weights and biases page (his account); he got to it this time by clicking something in the ide and now it seems to work,,
594,2,https://www.youtube.com/watch?t=21124&v=W5XNOmyJr6I,21124,screencapture-localhost-8000-2022-01-26-14_08_36.png,,"goal: ""ok so let's move the data""",,
596,2,https://www.youtube.com/watch?t=21160&v=W5XNOmyJr6I,21160,screencapture-localhost-8000-2022-01-26-14_09_32.png,,goal: Let's filter out imagenet datasets,,
597,2,https://www.youtube.com/watch?t=21163&v=W5XNOmyJr6I,21163,,,code: model_building; commenting out downloader command (since data is downloaded),,675;226;421;130
599,2,https://www.youtube.com/watch?t=21239&v=W5XNOmyJr6I,21239,screencapture-localhost-8000-2022-01-26-14_12_28.png,,output: 1000? that seems wrong somehow,"import os
image_files = []

for dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):
   image_files.append(files)
len(image_files)
",507;248;697;148
600,2,https://www.youtube.com/watch?t=21274&v=W5XNOmyJr6I,21274,screencapture-localhost-8000-2022-01-26-14_13_52.png,,code: model_building; changes the dir which causes the count to go down by 1. hmm,"import os
image_files = []
for dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images""):
   image_files.append(files)
len(image_files) 

image_files
",510;241;838;323
601,2,https://www.youtube.com/watch?t=21305&v=W5XNOmyJr6I,21305,screencapture-localhost-8000-2022-01-26-14_15_19.png,,code: model_building; experimenting with how to get the items in the list for use in append - I think he thinks they are getting added as a single list entity rather than as individual items,"list([""item_1"", ""item 2""]).items()
",510;350;430;52
602,2,https://www.youtube.com/watch?t=21324&v=W5XNOmyJr6I,21324,screencapture-localhost-8000-2022-01-26-14_22_01.png,,"code: model_building; attempt to separate files, but I don't think it works",,675;226;421;130
603,2,https://www.youtube.com/watch?t=21324&v=W5XNOmyJr6I,21324,screencapture-localhost-8000-2022-01-26-14_22_01.png,,output: count is still 999,"import os
image_files = []
for dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):
   image_files.append(file for file in files)
len(image_files)

image_files
",516;238;844;326
604,2,https://www.youtube.com/watch?t=21408&v=W5XNOmyJr6I,21408,,,code: model_building; nested loops to count images,,675;226;421;130
605,2,https://www.youtube.com/watch?t=21413&v=W5XNOmyJr6I,21413,screencapture-localhost-8000-2022-01-26-14_24_47.png,,code: model_building; updated loop,"import os
image_files = []
for dirs, m_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):
   for item in files:
      image_files.append(files)
len(image_files)

image_files
",513;199;835;335
606,2,https://www.youtube.com/watch?t=21413&v=W5XNOmyJr6I,21413,screencapture-localhost-8000-2022-01-26-14_25_29.png,,output: 54594 images,"import os
image_files = []
for dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):
   for item in files:
      image_files.append(item)
len(image_files)

image_files
",516;193;838;332
607,2,https://www.youtube.com/watch?t=21428&v=W5XNOmyJr6I,21428,screencapture-localhost-8000-2022-01-26-14_26_24.png,,"goal: ""let's build a model....so let's get the classnames""","import os
image_files = []
ima
",513;208;802;82
608,2,https://www.youtube.com/watch?t=21553&v=W5XNOmyJr6I,21553,screencapture-localhost-8000-2022-01-26-14_29_33.png,,code: model_building; adding a list of imagedirs - that's what we'll need to filter based on,"image_dirs = []
for dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):
   image_dirs.append(sub_dirs)
   for item in files:
      image_files.append(item)
   len(image_files) I

image_files[:5], sub_dirs[:5]
",504;208;679;335
609,2,https://www.youtube.com/watch?t=21582&v=W5XNOmyJr6I,21582,screencapture-localhost-8000-2022-01-26-14_31_39.png,,code: model_building; try printing sub_dirs,,675;226;421;130
610,2,https://www.youtube.com/watch?t=21582&v=W5XNOmyJr6I,21582,screencapture-localhost-8000-2022-01-26-14_31_39.png,,output: subdirs are all empty,"image_dirs = []
for dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):
   print(sub_dirs)
   image_dirs.append(sub_dirs)
   for item in files:
      image_files.append(item)
len(image_files)
",513;193;694;199
611,2,https://www.youtube.com/watch?t=21596&v=W5XNOmyJr6I,21596,screencapture-localhost-8000-2022-01-26-14_33_02.png,,code: model_building; print dirs instead,"image_dirs = []
for dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):
   print(dirs)
   image_dirs.append(sub_dirs)
   for item in files:
      image_files.append(item)
len(image_files)
",516;196;667;193
612,2,https://www.youtube.com/watch?t=21596&v=W5XNOmyJr6I,21596,screencapture-localhost-8000-2022-01-26-14_35_41.png,,output: dirs seem to have the classnames in them,,
613,2,https://www.youtube.com/watch?t=21642&v=W5XNOmyJr6I,21642,screencapture-localhost-8000-2022-01-26-14_37_10.png,,code: model_building; creating an imagedir list using listdir,"image_dirs = os.listdir(""data/imagenet_images/"")
for dirs, sub_dirs, files in os.walk(""data/imagenet_images/""):
   image_dirs.append(sub_dirs)
   for item in files:
      image_files.append(item)
len(image_files) 
",516;191;664;160
614,2,https://www.youtube.com/watch?t=21646&v=W5XNOmyJr6I,21646,screencapture-localhost-8000-2022-01-27-09_46_24.png,,code: model_building; echoing filenames and dirs.,"len(image_files)

image_files[:5], image_dirs[:5]
",516;191;472;208
615,2,https://www.youtube.com/watch?t=21646&v=W5XNOmyJr6I,21646,screencapture-localhost-8000-2022-01-27-09_46_24.png,,output: ok - we have filenames and dirs corresponding to class names,,
616,2,https://www.youtube.com/watch?t=21690&v=W5XNOmyJr6I,21690,screencapture-localhost-8000-2022-01-26-14_31_39.png,,code: model_building; echoing number of classes via directories,"image_dirs = []
for dirs, dirs, files in os.walk(""data/imagenet_images/""):
   print(sub_dirs)
   image_dirs.append(sub_dirs)
   for item in files:
      image_files.append(item)
len(image_files)

image_files[:5], dirs[:5]
",507;205;703;322
617,2,https://www.youtube.com/watch?t=21690&v=W5XNOmyJr6I,21690,screencapture-localhost-8000-2022-01-26-14_31_39.png,,output: almost 2K dir names,"len(image_dirs) 
",513;341;181;55
618,2,https://www.youtube.com/watch?t=21729&v=W5XNOmyJr6I,21729,screencapture-localhost-8000-2022-01-27-09_49_39.png,,code: model_building; echoing class/dir names,"len(image_dirs)

image_dirs
",516;275;184;211
619,2,https://www.youtube.com/watch?t=21729&v=W5XNOmyJr6I,21729,screencapture-localhost-8000-2022-01-27-09_49_39.png,,output: names of classes; I think he's wondering why if imagenet has 1000 classes of images that there are more directories than that.,,
620,2,https://www.youtube.com/watch?t=21735&v=W5XNOmyJr6I,21735,screencapture-localhost-8000-2022-01-27-09_51_30.png,,"goal: ""ok now let's start filtering some data""",,
621,2,https://www.youtube.com/watch?t=21772&v=W5XNOmyJr6I,21772,screencapture-localhost-8000-2022-01-27-09_52_32.png,,"goal: ""we need data. we need to make train and test folders""",,
622,2,https://www.youtube.com/watch?t=21858&v=W5XNOmyJr6I,21858,screencapture-localhost-8000-2022-01-27-09_54_22.png,,code: model_building; creating test and train directories in the data directory,"!mkdir data/train

!mkdir data/test
",513;223;226;166
623,2,https://www.youtube.com/watch?t=21869&v=W5XNOmyJr6I,21869,screencapture-localhost-8000-2022-01-27-09_55_09.png,,"goal: ""then inside here is going to be food images and non-food images so let's do that""",,
624,2,https://www.youtube.com/watch?t=21964&v=W5XNOmyJr6I,21964,screencapture-localhost-8000-2022-01-27-09_57_38.png,,code: data_splitting; he's just copied in a bunch of things from the model_building section,"import os

for dirs, sub_dirs, files in os.walk(""data/model_test_images/""):
   print(dirs)
   print(sub_dirs)
   print(files)

import random
def create_train_test_list(target_dir):
   random.seed(42)
   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
",510;241;997;422
625,2,https://www.youtube.com/watch?t=21979&v=W5XNOmyJr6I,21979,,,"code: data_splitting; adding imports, changing directory of images to walk",,675;226;421;130
626,2,https://www.youtube.com/watch?t=21989&v=W5XNOmyJr6I,21989,screencapture-localhost-8000-2022-01-27-10_09_33.png,,output: printing results of the walk,"import os
from shutil import copy2
import random

for dirs, sub_dirs, files in os.walk(""data/imagenet_images""):
   print(dirs)
   print(sub_dirs)
   print(files)
",513;235;658;199
627,2,https://www.youtube.com/watch?t=22003&v=W5XNOmyJr6I,22003,screencapture-localhost-8000-2022-01-27-10_11_16.png,,code: data_splitting; commenting out walk code and removing unnecessary import.,"def create_train_test_list(target_dir):
   random. seed(42)
   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list

train_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")
len(train_image_list), len(test_image_list)
",519;362;1006;284
628,2,https://www.youtube.com/watch?t=22016&v=W5XNOmyJr6I,22016,screencapture-localhost-8000-2022-01-27-10_12_24.png,,code: data_splitting; create train test list with a target directory. testing with aircraft still - this will need to be updated once the larger dataset is in play,"def create_train_test_list(target_dir):
   random.seed(42)
   image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list

train_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")
len(train_image_list), len(test_image_list)
",513;220;1018;290
629,2,https://www.youtube.com/watch?t=22016&v=W5XNOmyJr6I,22016,screencapture-localhost-8000-2022-01-27-10_13_20.png,,output: split still seems to work with aircraft,,
630,2,https://www.youtube.com/watch?t=22025&v=W5XNOmyJr6I,22025,screencapture-localhost-8000-2022-01-27-10_14_01.png,,code: data_splitting; copied in file copying function (beginning),"   train_image_List = random.sample(image_List, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list

train_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")
len(train_image_list), len(test_image_list)

def copy_images_to_file(img_path_list, target_dir, train=True):
   if train:
      split_dir = ""train""
   else:
      split_dir = ""test""

   # Copy images
",513;191;1000;476
631,2,https://www.youtube.com/watch?t=22021&v=W5XNOmyJr6I,22021,screencapture-localhost-8000-2022-01-27-10_16_34.png,,code: data_splitting; end of file copying function,,675;226;421;130
632,2,https://www.youtube.com/watch?t=22021&v=W5XNOmyJr6I,22021,screencapture-localhost-8000-2022-01-27-10_16_34.png,,code: data_splitting; beginning of move images code,"      # Copy images
      for image_path in img_path_list:
         image_file_name = os.path.split(image_path)[-1]
         dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)
         print(f""Copying: {image_path} to {dest_path}"")
         copy2(image_path, dest_path)

# Create a function to move images

data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   for split_dir in [""train"", ""test""]:
      os.makedirs(os.path.ioin(target_dir, split_dir, image_dir), exist_ok=True)
",519;196;1393;476
633,2,https://www.youtube.com/watch?t=22024&v=W5XNOmyJr6I,22024,screencapture-localhost-8000-2022-01-27-10_17_19.png,,code: data_splitting; end of function,"# Copy testing images
copy_images_to_file(img_path_list=test_image_list,
   target_dir=target_dir,
   train=False)
",537;202;568;148
634,2,https://www.youtube.com/watch?t=22068&v=W5XNOmyJr6I,22068,screencapture-localhost-8000-2022-01-27-10_18_37.png,,goal: filter the classnames using the list of numeric keys corresponding to food classes from before,,
635,2,https://www.youtube.com/watch?t=22077&v=W5XNOmyJr6I,22077,screencapture-localhost-8000-2022-01-27-10_19_47.png,,code: data_exploration; looking at food classnames,"df_food.class_name.tolist()
",516;208;301;46
636,2,https://www.youtube.com/watch?t=22077&v=W5XNOmyJr6I,22077,screencapture-localhost-8000-2022-01-27-10_21_20.png,,code: data_exploration; looking at food classnames,"df_food.clasnames|
",513;296;217;49
637,2,https://www.youtube.com/watch?t=22112&v=W5XNOmyJr6I,22112,screencapture-localhost-2222-2022-05-02-14_47_35.png,,code: data_exploration; creating foodlistfilter and nonfoodlistfilter by getting the classnames associated with each from data processing earlier.,"food_list_filter = df_food.class_name.tolist()
non_food_list_filter = df_non_food.class_name.tolist()
",420;359;602;77
638,2,https://www.youtube.com/watch?t=22123&v=W5XNOmyJr6I,22123,screencapture-localhost-8000-2022-01-27-10_24_00.png,,code: data_exploration; printing out the first five food and non-food classes.,"food_list_filter = df_food.class_name.tolist()
non_food_list_filter = df_non_food.class_name.tolist()


food_list_filter[:5], non_food_list_filter[:5]
",510;202;628;202
639,2,https://www.youtube.com/watch?t=22123&v=W5XNOmyJr6I,22123,screencapture-localhost-8000-2022-01-27-10_24_00.png,,output: the first 5 food and non food classes,"food_list_filter = df_food.class_name.tolist()
non_food_list_filter = df_non_food.class_name.tolist()

food_list_filter[:5], non_food_list_filter[:5]
",516;193;586;202
640,2,https://www.youtube.com/watch?t=22168&v=W5XNOmyJr6I,22168,screencapture-localhost-8000-2022-01-27-10_25_34.png,,goal: move food images to food images folder,,
641,2,https://www.youtube.com/watch?t=22192&v=W5XNOmyJr6I,22192,screencapture-localhost-8000-2022-01-27-10_26_46.png,,code: data_exploration; list of directories in imagenet downloads,"# Move food images to food_images folder
imagenet_downloaded_image_folders = os.listdir(""data/imagenet_images/"")
imagenet_downloaded_image_folders
",504;292;787;100
642,2,https://www.youtube.com/watch?t=22192&v=W5XNOmyJr6I,22192,screencapture-localhost-8000-2022-01-27-10_26_46.png,,output: these are the classname directories,"# Move food images to food_images folder
imagenet_downloaded_image_folders = os.listdir(""data/imagenet_images/"")
imagenet_downloaded_image_folders
",519;299;778;94
643,2,https://www.youtube.com/watch?t=22215&v=W5XNOmyJr6I,22215,screencapture-localhost-2222-2022-05-02-14_34_51.png,,code: data_exploration; I'm going to lower them all,"# Move food images to food_images folder
imagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]
imagenet_downloaded_image_folders
",435;334;1005;94
644,2,https://www.youtube.com/watch?t=22220&v=W5XNOmyJr6I,22220,screencapture-localhost-8000-2022-01-27-10_44_21.png,,code: data_exploration; lower casing dir names and printing out first 10,"# Move food images to food_images folder
imagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]
imagenet_downloaded_image_folders[:10]
",513;299;1225;94
645,2,https://www.youtube.com/watch?t=22228&v=W5XNOmyJr6I,22228,screencapture-localhost-8000-2022-01-27-10_45_05.png,,code: data_exploration; printing 5 instead of 10,,675;226;421;130
646,2,https://www.youtube.com/watch?t=22228&v=W5XNOmyJr6I,22228,screencapture-localhost-8000-2022-01-27-10_45_05.png,,output: now dir names are in lower case,"# Move food images to food_images folder
imagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]
imagenet_downloaded_image_folders[:5]
",507;299;1246;97
647,2,https://www.youtube.com/watch?t=22246&v=W5XNOmyJr6I,22246,screencapture-localhost-8000-2022-01-27-10_46_03.png,,code: data_exploration; changing comment to better reflect what this section of code is actually doing - getting class names,"# Get list of downloaded ImageNet class folder names
imagenet_downloaded_image_folders = [folder_name.lower() for folder_name in os.listdir(""data/imagenet_images/"")]
imagenet_downloaded_image_folders[:5]
",513;293;1198;103
648,2,https://www.youtube.com/watch?t=22274&v=W5XNOmyJr6I,22274,screencapture-localhost-8000-2022-01-27-10_47_12.png,,goal: move food images from imagenet downloaded folder to data/food_images,,
649,2,https://www.youtube.com/watch?t=22673&v=W5XNOmyJr6I,22673,screencapture-localhost-2222-2022-05-02-14_33_23.png,,"code: data_exploration; beginnings of the data copy function. He's not quite done, but I'm worried it's going to stop fitting on the screen, so capturing what's here.","from shutil import copy2
start_dir = ""imagenet_images""
dest_dir = ""data/food_images""
for image_folder in imagenet_downloaded_image_folders:
   if image_folder in food_list_filter:
   # Make new target dir
   dest_dir = os.path.join(dest_dir, image_folder)
   os.makedirs(dest_dir, exist_ok=True)

   start_dir = os.path.join(start_dir, image_folder)
   images_to_copy = os.listdir(start_dir)
   for image_to_copy in images_to_copy:
      image_filename = image_to_copy.split()[-1]
      start_path = os.path.join(start_dir, image_filename)
      dest_path = os.path.join(dest_dir, image_filename)
      print(f""Copying: {start_path} to {dest_path}..."")
      # copy2(image_to_copy)
",433;251;662;391
650,2,https://www.youtube.com/watch?t=22675&v=W5XNOmyJr6I,22675,screencapture-localhost-8000-2022-01-27-11_01_42.png,,output: error - no such file or directory,,
651,2,https://www.youtube.com/watch?t=22764&v=W5XNOmyJr6I,22764,screencapture-localhost-8000-2022-01-27-11_04_19.png,,code: data_exploration; adding the data/ in front of imagenet,"from shutil import copy2
start_dir = ""data/limagenet_images""
dest_dir = ""data/food_images""
for image_folder in imagenet_downloaded_image_folders:
   if image_folder in food_list_filter:
   #Make new target dir
   dest_dir = os.path.join(dest_dir, image_folder)
   os.makedirs(dest_dir, exist_ok=True)

   start_dir = os.path.join(start_dir, image_folder)
   images_to_copy = os.listdir(start_dir)
   for image_to_copy in images_to_copy:
      image_filename = image_to_copy.split()[-1]
      start_path = os.path.join(start_dir, image_filename)
      dest_path = os.path.join(dest_dir, image_filename)
      print(f""Copying: {start_path} to {dest_path}..."")
      # copy2(image_to_copy)
",510;199;748;458
652,2,https://www.youtube.com/watch?t=22765&v=W5XNOmyJr6I,22765,screencapture-localhost-8000-2022-01-27-11_04_51.png,,output: error no such file or directory data/imagenet_images/japanese; is this b/c he lower cased them?,,
653,2,https://www.youtube.com/watch?t=22839&v=W5XNOmyJr6I,22839,screencapture-localhost-8000-2022-01-27-11_06_59.png,,"code: data_exploration; replaces the iterating through list with a listdir - if this is a capitalization issue, this should address it.","# Move food images from ImageNet downloaded folders to data/food_images
from shutil import copy2
start_dir = ""data/imagenet_images""
dest_dir = ""data/food_images""
for image_folder in os.listdir(start_dir):
   if image_folder in food_list_filter:
   # Make new target dir
   dest_dir = os.path.join(dest_dir, image_folder)
   os.makedirs(dest_dir, exist_ok=True)

   start_dir = os.path.join(start_dir, image_folder)
   images_to_copy = os.listdir(start_dir)
   for image_to_copy in images_to_copy:
",513;305;790;359
654,2,https://www.youtube.com/watch?t=22842&v=W5XNOmyJr6I,22842,screencapture-localhost-8000-2022-01-27-11_08_45.png,,code: data_exploration; lowers the dir name to check if it's in the filter.,"# Move food images from ImageNet downloaded folders to data/food_images
from shutil import copy2
start_dir = ""data/imagenet 
dest_dir = ""data/food_imag
for image_folder in os.lis
   if image_folder.lower() in food_list_filter:
      # Make new target dir
      dest_dir = os.path.join(dest_dir, image_folder)
      os.makedirs(dest_dir, exist_ok=True)

      start_dir = os.path.join(start_dir, image_folder)
      images_to_copy = os.listdir(start_dir)
      for image_to_copy in images_to_copy:
",519;299;793;359
655,2,https://www.youtube.com/watch?t=22845&v=W5XNOmyJr6I,22845,screencapture-localhost-8000-2022-01-27-11_09_19.png,,output: that now seems to work,,
656,2,https://www.youtube.com/watch?t=22860&v=W5XNOmyJr6I,22860,screencapture-localhost-8000-2022-01-27-11_16_37.png,,output: error no such file or directory data/imagenet_images/Japanese/cayenne; I wondered if this would be an issue - he's redefining  dest_dir within the subdirectories which appears to carry over.,,
657,2,https://www.youtube.com/watch?t=22976&v=W5XNOmyJr6I,22976,screencapture-localhost-8000-2022-01-27-11_20_12.png,,code: data_exploration; echoing the image folder name at the beginning,"# Move food images from ImageNet downloaded folders to data/food_im
from shutil import copy2
start_dir = ""data/imagenet_images""
dest_dir = ""data/food_images""
for image_folder in os.listdir(start_dir):
   print(f""Image folder: .... {image_folder}..."")
   if image_folder.lower() in food_list_filter: 
      # Make new target dir
      dest_dir = os.path.join(dest_dir, image_ 
      os.makedirs(dest_dir, exist_ok=True) 

      start_dir = os.path.join(start_dir, imag
      images_to_copy = os.listdir(start_dir) 

      for image_to_copy in images_to_copy: 
         image_filename = image_to_copy.split.
         start_path = os.path.join(start_dir, image_filename)
         dest path = os.path.join(dest_dir, image_filename)
",516;193;712;479
658,2,https://www.youtube.com/watch?t=22984&v=W5XNOmyJr6I,22984,screencapture-localhost-8000-2022-01-27-11_21_00.png,,output: error no such file or directory; same issue as before,,
659,2,https://www.youtube.com/watch?t=23038&v=W5XNOmyJr6I,23038,screencapture-localhost-8000-2022-01-27-11_22_26.png,,"code: data_exploration; ""I need to bring the for loop out"" I think this is wrong, but we'll see","for image_folder in os.listdir(start_dir):
   print(f""Image folder: .... {image_folder}..."")
   if image_folder.lower() in food_list_filter:
      # Make new target dir
      dest_dir = os.path.join(dest_dir, image_folder)
      os.makedirs(dest_dir, exist_ok=True)

      start_dir = os.path.join(start_dir, image_folder)
      images_to_copy = os.listdir(start_dir)

   for image_to_copy in images_to_copy:
      image_filename = image_to_copy.split()[-1]
      start_path = os.path.join(start_dir, image_filename)
      dest_path = os.path.join(dest_dir, image_filename)
      print(f""Copying: {start_path} to {dest_path}..."")
      #- copy2(image_to_copy)
",516;202;688;431
660,2,https://www.youtube.com/watch?t=23093&v=W5XNOmyJr6I,23093,screencapture-localhost-8000-2022-01-27-11_27_19.png,,"code: data_exploration; has done some creation of new variables, but loop is in wrong spot and needs to carry through on use of new variables in places","for image_folder in os.listdir(start_dir):
   print(f""Image folder: .... {image_folder}..."")
   if image_folder.lower() in food_list_filter:
      # Make new target dir
      new_dest_dir = os.path.join(dest_dir, image_folder)
      os.makedirs(dest_dir, exist_ok=True)

      target_image_folder = os.path.join(start_dir, image_folder)
      images_to_copy = os.listdir(target_image_folder)

   for image_to_copy in images_to_copy:
      image_filename = image_to_copy.split()[-1]
      start_path = os.path.join(target,image_folder, image_filename)
      dest_path = os.path.join(new_dest_dir, image_filename)
      print(f""Copying: {start_path} to {dest_path}..."")
      # copy2(image_to_copy)
",510;199;772;434
661,2,https://www.youtube.com/watch?t=23095&v=W5XNOmyJr6I,23095,screencapture-localhost-8000-2022-01-27-11_28_14.png,,output: error target image folder is not defined; I think this is because of the miss-placement of the loop,,
662,2,https://www.youtube.com/watch?t=23163&v=W5XNOmyJr6I,23163,screencapture-localhost-8000-2022-01-27-11_30_18.png,,code: data_exploration; I'm not sure what he's thinking here - feels like it's moving further from correct,"print(f""image folderr: .... {image_folder}..."")
if image_folder.lower() in food_list_filter:
   # Make new target dir
   new_dest_dir = os.path.join(dest_dir, image_folder)
   os.makedirs(dest_dir, exist_ok=True)

   target_image_folder = os.path.join(start_dir, image_folder)
   images_to_copy = os.listdir(target_image_folder)
else:
   pass

if target_image_folder:
   for image_to_copy in images_to_copy:
      image_filename = image_to_copy.split() [-1]
      start_path = os.path.join(target_image_folder, image_filename)
      dest_path = os.path.join(new_dest_dir, image_filename)
      print(f""Copying: {start_path} to {dest_path}..."")
      # copy2(image_to_copy)
",555;193;763;467
663,2,https://www.youtube.com/watch?t=23180&v=W5XNOmyJr6I,23180,screencapture-localhost-8000-2022-01-27-11_31_24.png,,output: error food_list_filter is not defined;,,
664,2,https://www.youtube.com/watch?t=23238&v=W5XNOmyJr6I,23238,screencapture-localhost-8000-2022-01-27-11_38_00.png,,code: data_exploration; trying to print out target_image_folder -referencing later when it's out of scope.,"   # Make new target dir
   new_dest_dir = os.path.join(dest_dir, image_folder)
   os.makedirs(dest_dir, exist_ok=True)

   target_image_folder = os.path.join(start_dir, image_folder)
   print(target_image_folder)
   images_to_copy = os.list
else:
   pass 

if target_image_folder: [
   for image_to_copy in imag 
      image_filename = imag 
      start_path = os.path. 
      dest_path = os.path.
      print(f""Copying: (sta
      # copy2(image_to_copy)
",558;196;682;470
665,2,https://www.youtube.com/watch?t=23241&v=W5XNOmyJr6I,23241,screencapture-localhost-8000-2022-01-27-11_38_58.png,,output: error target_image_folder is not defined. This is probably b/c the first several directories are not food.,,
666,2,https://www.youtube.com/watch?t=23262&v=W5XNOmyJr6I,23262,screencapture-localhost-8000-2022-01-27-11_40_34.png,,code: data_exploration; defining target_image_folder early and in the right scope. This will actually make it so the loop doesn't need to move though it's a bit strange.,"from shutil import copy2
start_dir = ""data/imagenet_images""
dest_dir = ""data/food_images""
for image_folder in os.listdir(start_dir):
   target_image_folder = None
   print(f""Image folder: .... {image_folder}..."")
   if image_folder.lower() in food_list_filter:
      # Make new target dir
      new_dest_dir = os.path.join(dest_dir, image_folder)
      os.makedirs(dest_dir, exist_ok=True)

      target_image_folder = os.path.join(start_dir, image_folder)
      images_to_copy = os.listdir(target_image_folder)
   else:
      pass

if target_image_folder:
   for image_to_copy in images_to_copy:
",510;188;751;476
667,2,https://www.youtube.com/watch?t=23264&v=W5XNOmyJr6I,23264,screencapture-localhost-8000-2022-01-27-11_41_30.png,,output: initial output looks ok,,
668,2,https://www.youtube.com/watch?t=23337&v=W5XNOmyJr6I,23337,screencapture-localhost-8000-2022-01-27-11_43_30.png,,code: data_exploration; adding the actual copy piece.,"   target_image_folder = os.path.join(start_dir, image_folder)
   images_to_copy = os.listdir(target_image_folder)
else:
   pass

if target_image_folder:
   for image_to_copy in images_to_copy:
      image_filename = image_to_copy.split() [-1]
      start_path = os.path.join(target_image_folder, image_filename)
      dest_path = os.path.join(new_dest_dir, image_filename)
      print(f""Copying: {start_path} to {dest_path}..."")
      copy2(start_path, dest_path)
",537;196;787;317
669,2,https://www.youtube.com/watch?t=23363&v=W5XNOmyJr6I,23363,screencapture-localhost-8000-2022-01-27-11_44_33.png,,output: error no such file or directory data/imagenet_images/japanese/cayenne/somefile...,,
670,2,https://www.youtube.com/watch?t=23451&v=W5XNOmyJr6I,23451,screencapture-localhost-8000-2022-01-27-11_46_59.png,,code: data_exploration; printing out the target image folder,"from shutil import copy2
start_dir = ""data/imagenet_images""
dest_dir = ""data/food_images""
for image_folder in os.listdir(start_dir): 
   target_image_folder = None 
   print(f""Image folder: .... {image_folder}..."")
   if image_folder.lower() in food_list_filter: 
      # Make new target dir 
      new_dest_dir = os.path.join(dest_dir, image_folder) 
      os.makedirs(dest_dir, exist_ok=True) 

      target_image_folder = os.path.join(start_dir, image f
      print(f""Target image folder: {target_image folder}..."")
      images_to_copy = os.listdir(target_image_folder)
   else:
      pass

   if target_image_folder:
",510;188;688;482
671,2,https://www.youtube.com/watch?t=23479&v=W5XNOmyJr6I,23479,screencapture-localhost-8000-2022-01-27-11_48_10.png,,"output: logging output of file copy, but I think what the logging says its doing has diverged from what it's actually doing",,
672,2,https://www.youtube.com/watch?t=23556&v=W5XNOmyJr6I,23556,screencapture-localhost-8000-2022-01-27-12_03_40.png,,code: data_exploration; moving where target image folder gets printed.,"target_image_folder = None
print(f""Image folder: .... {image_folder}..."")
if image_folder.lower() in food_list_filter:
   # Make new target dir
   new_dest_dir = os.path.join(dest_dir, image_folder)
   os.makedirs(dest_dir, exist_ok=True)

   target_image_folder = os.path.join(start_dir, image_folder)
else:
   pass

if target_image_folder:
   print{{f""Target image folder: {target_image_folder}..."")|
   images_to_copy = os.listdir(target_image_folder)
   for image_to_copy in images_to_copy:
      image_filename = image_to_copy.split() [-1]
      start_path = os.path.join(target_image_folder, image_filename)
      dest path = os.path.join(new_dest_dir, image_filename)
",540;193;778;479
673,2,https://www.youtube.com/watch?t=23654&v=W5XNOmyJr6I,23654,screencapture-localhost-8000-2022-01-27-12_05_54.png,,output: error no such file or directory data/food_images/Japanese,,
674,2,https://www.youtube.com/watch?t=23688&v=W5XNOmyJr6I,23688,screencapture-localhost-8000-2022-01-27-12_07_44.png,,code: data_exploration; adding print of new_dest_dir,"# Move food images from ImageNet downloaded folders to data/food_images
from shutil import copy2
start_dir = ""data/imagenet_images""
dest_dir = ""data/food_images""
for image_folder in os.listdir(start_dir):
   target_image_folder = None
   print(f""Image folder: .... {image_folder}..."")
   if image_folder.lower() in food_list_filter:
      # Make new target dir
      new_dest_dir = os.path.join(dest_dir, image_folder)
      os.makedirs(dest_dir, exist_ok=True)
      print{(new_dest_dir)

      # Images to copy
      target_image_folder = os.path.join(start_dir, image_folder)
   else:
      pass
",519;196;772;461
675,2,https://www.youtube.com/watch?t=23691&v=W5XNOmyJr6I,23691,screencapture-localhost-8000-2022-01-27-12_08_25.png,,output: error no such file or dir; still generating the directory with uppercase letters (Japanese),,
676,2,https://www.youtube.com/watch?t=23715&v=W5XNOmyJr6I,23715,screencapture-localhost-8000-2022-01-27-12_09_32.png,,code: data_exploration; caught the error where the directory being created is not actually the new_data_dest.,"from shutil import copy2
start_dir = ""data/imagenet_images""
dest_dir = ""data/food_images""
for image_folder in os.listdir(start_dir):
   target_image_folder = None
   print(f""Image folder: .... {image_folder}..."")
   if image_folder.lower() in food_list_filter:
      # Make new target dir
      new_dest_dir = os.path.join(dest_dir, image_folder)
      os.makedirs(new_dest_dir, exist_ok=True)
      print(new_dest_dir)

      # Images to copy
      target_image_folder = os.path.join(start_dir, image_folder)
   else:
      pass

   if target_image_folder:
",513;191;739;476
677,2,https://www.youtube.com/watch?t=23735&v=W5XNOmyJr6I,23735,screencapture-localhost-2222-2022-05-02-14_30_18.png,,code: data_exploration; more details in print message,"from shutil import copy2
start_dir = ""data/imagenet_images""
dest_dir = ""data/food_images"" 
for image_folder in os.listdir(start_dir): 
   target_image_folder = None
   print(f""Image folder: .... {image_folder}... 
   if image_folder.lower() in food_list_filter: 
      # Make new target dir
      new_dest_dir = os.path.join(dest_dir, im
      print(f""Making folder: {new_dest_dir}..."")
      os.makedirs(new_dest_dir, exist_ok=True)


      # Images to copy
      target_image_folder = os.path.join(start_dir, image_folder)
   else:
      pass
",430;253;627;386
678,2,https://www.youtube.com/watch?t=23740&v=W5XNOmyJr6I,23740,screencapture-localhost-8000-2022-01-27-12_13_13.png,,"code: data_exploration; commenting out the copy again. ""I think we've got it now""","for image_to_copy in images_to_copy:
   image_filename = image_to_copy.split()[-1]
   start_path = os.path.join(target_image_folder, image_filename)
   dest_path = os.path.join(new_dest_dir, image_filename)
   print(f""Copying: {start_path} to {dest_path}..."")
   # copy2(start_path, dest_path)
",570;199;760;184
679,2,https://www.youtube.com/watch?t=23763&v=W5XNOmyJr6I,23763,screencapture-localhost-8000-2022-01-27-12_14_13.png,,"goal: ""why doesn't it make a new folder for japanese?""; he's still debugging moving the food images from imagenet into the food folder.",,
680,2,https://www.youtube.com/watch?t=23801&v=W5XNOmyJr6I,23801,screencapture-localhost-8000-2022-01-27-12_15_48.png,,"goal: ""food images lopped. now let's do non-food images""",,
681,2,https://www.youtube.com/watch?t=23836&v=W5XNOmyJr6I,23836,screencapture-localhost-8000-2022-01-27-12_16_51.png,,"goal: ""move non food images to non_food_images""",,
682,2,https://www.youtube.com/watch?t=23866&v=W5XNOmyJr6I,23866,screencapture-localhost-8000-2022-01-27-12_17_45.png,,code: data_exploration; has changed dir to non_food and food_list_filter to non_food_list_filter,"# Move food images from ImageNet downloaded folders to data/food_images
from shutil import copy2
start_dir = ""data/imagenet_images""
dest_dir = ""data/non_food_images""
for image_folder in os.listdir(start_dir):
   target_image_folder = None
   print(f""Image folder: .... {image_folder}..."")
   if image_folder.lower() in non_food_list_filter:
      # Make new target dir
      new_dest_dir = os.path.join(dest_dir, image_folder)
      print(f""Making folder: {new_dest_dir}..."")
      os.makedirs(new_dest_dir, exist_ok=True)
",513;350;823;317
683,2,https://www.youtube.com/watch?t=24033&v=W5XNOmyJr6I,24033,screencapture-localhost-8000-2022-01-27-12_21_18.png,,"goal: extract food images files and move to train; I think he wants to get rid of the sub-dir, although why he didn't just do that when he moved them in the first place...",,
684,2,https://www.youtube.com/watch?t=24279&v=W5XNOmyJr6I,24279,screencapture-localhost-8000-2022-01-27-13_07_40.png,,code: data_exploration; starting to split into train and test sets,"# Extract food_images files and move to train/food_images
# Do the same with test & non_food_images
food_image_filepaths = []
for dir, sub_dir, files in os.walk(""data/food_images/""):
   food_image_filepaths.append(files)
food_images_filepaths
",516;196;634;175
685,2,https://www.youtube.com/watch?t=24279&v=W5XNOmyJr6I,24279,screencapture-localhost-8000-2022-01-27-13_07_40.png,,output: food_images_filepaths is not defined.,,
686,2,https://www.youtube.com/watch?t=24307&v=W5XNOmyJr6I,24307,screencapture-localhost-8000-2022-01-27-13_09_06.png,,search: python get list of all files in directory;,,
687,2,https://www.youtube.com/watch?t=24321&v=W5XNOmyJr6I,24321,screencapture-localhost-8000-2022-01-27-13_11_11.png,,visit: python list files in a directory: step-by-step guide; I'm not sure why he's looking this up - he's been using listdir.,,
688,2,https://www.youtube.com/watch?t=24347&v=W5XNOmyJr6I,24347,screencapture-localhost-8000-2022-01-27-13_12_41.png,,code: data_exploration; putting path join in so that it's not just the filename,"# Extract food_images files and move to train/food_images
# Do the same with test & non_food_images
food_image_filepaths = []
for dir, sub_dir, files in os.walk(""data/food_images/""):
   food_image_filepaths.append(os.path,join(dir, files))
food_image_filepaths
",513;191;679;187
689,2,https://www.youtube.com/watch?t=24347&v=W5XNOmyJr6I,24347,screencapture-localhost-8000-2022-01-27-13_13_26.png,,output: error - argument to join must be a str or a path not a list.,,
690,2,https://www.youtube.com/watch?t=24368&v=W5XNOmyJr6I,24368,screencapture-localhost-8000-2022-01-27-13_14_55.png,,code: data_exploration; now looping through the files.,"# Do the same with test & non_food_images
food_image_filepaths = []
for dir, sub_dir, files in os.walk('""data/food_images/""):
   for file in files:
      food_image_filepaths.append(os.path.join(dir, file))
food_image_filepaths
",516;193;679;184
691,2,https://www.youtube.com/watch?t=24375&v=W5XNOmyJr6I,24375,screencapture-localhost-8000-2022-01-27-13_15_23.png,,output: a list of the food files in their respective sub directories.,,
692,2,https://www.youtube.com/watch?t=24379&v=W5XNOmyJr6I,24379,screencapture-localhost-8000-2022-01-27-13_16_25.png,,code: data_exploration; how many food images do we have?,,675;226;421;130
693,2,https://www.youtube.com/watch?t=24379&v=W5XNOmyJr6I,24379,screencapture-localhost-8000-2022-01-27-13_16_25.png,,output: 2842 food images,"food_image_filepaths = []
for dir, sub_dir, files in os.walk(""data/food_images/""):
   for file in files:
      food_image_filepaths.append(os.path.join(dir, file))
len(food_image_filepaths)
",510;191;682;142
694,2,https://www.youtube.com/watch?t=24390&v=W5XNOmyJr6I,24390,screencapture-localhost-8000-2022-01-27-13_17_21.png,,"goal: ""we're going to need to bump those numbers up a bit for model building""; he's referring to the number of food images in the dataset.",,
695,2,https://www.youtube.com/watch?t=24419&v=W5XNOmyJr6I,24419,screencapture-localhost-8000-2022-01-27-13_18_32.png,,"goal: ""let's randomly get a train and test split""",,
696,2,https://www.youtube.com/watch?t=24483&v=W5XNOmyJr6I,24483,screencapture-localhost-8000-2022-01-27-13_20_21.png,,code: data_exploration; creating a test/train split - this is reused code from before.,"def create_train_test_list(image_list):
   random.seed(42)
   # image_list = (os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]
   train_split = int(0.8 % len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list

train_image_list, test_image_list = create_train_test_list(food_image_filepaths)
len(train_image_list), len(test_image_list)
",510;263;1024;275
697,2,https://www.youtube.com/watch?t=24497&v=W5XNOmyJr6I,24497,screencapture-localhost-8000-2022-01-27-13_21_10.png,,"output: size of the train and test sets; ""there we go, train and test. Done.""",,
698,2,https://www.youtube.com/watch?t=24564&v=W5XNOmyJr6I,24564,screencapture-localhost-8000-2022-01-27-13_23_05.png,,code: data_splitting; starting to do the same for the test data - I think I've mislabeled the past few codes as data_exploration where they may have been data_splitting,"# Extract food_images files and move to train/food_images
# Do the same with test & non_food_images
food_image_filepaths = [1
for dir, sub_dir, files in os.walk(""data/food_images/""):
   for file in files:
      food_image_filepaths.append(os.path.join(dir, file))

non_food_image_filepaths = []
for dir, sub_dir, files in os.walk(""data/non_food_images/""):
   for file in files:
      food_image_filepaths.append(os.path.join(dir, file))
food_image_filepaths[:5] 
",510;232;727;353
699,2,https://www.youtube.com/watch?t=24577&v=W5XNOmyJr6I,24577,screencapture-localhost-8000-2022-01-27-13_24_51.png,,code: data_splitting; printing out the first 5 non-food images,"non_food_image_filepaths = []
for dir, sub_dir, files in os.walk(""data/non_food_images/""):
   for file in files:
      food_image_filepaths.append(os.path.join(dir, file))
food_image_filepaths[:5], non_food_image_filepaths[:5]
",516;199;685;160
700,2,https://www.youtube.com/watch?t=24592&v=W5XNOmyJr6I,24592,screencapture-localhost-8000-2022-01-27-13_25_47.png,,code: data_splitting; appending non-foods to the non-foods list.,"non_food_image_filepaths = []
for dir, sub_dir, files in os.walk(""data/non_food_images/""):
   for file in files:
      non_food_image_filepaths.append(os.path.join(dir, file))
food_image_filepaths[:5], non_food_image_filepaths[:5]

def create_train_test_list(image_list):
   random.seed(42)
   # image_list = [os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir)]
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list
",510;223;1021;452
701,2,https://www.youtube.com/watch?t=24593&v=W5XNOmyJr6I,24593,screencapture-localhost-8000-2022-01-27-13_26_16.png,,output: now we seem to have foods and non-foods,,
702,2,https://www.youtube.com/watch?t=24650&v=W5XNOmyJr6I,24650,screencapture-localhost-8000-2022-01-27-13_27_53.png,,code: data_splitting; copying in previously written function to do the copying.,"# Move to train and test
def copy_images_to_file(img_path_list, target_dir, train=True):
   if train:
      split_dir = ""train""
   else:
      split_dir = ""test""

   # Copy images
   for image_path in img_path_list:
      image_file_name = os.path.split(image_path)[-1]
      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)
      print(f""Copying: {image_path} to {dest_path}"")
      copy2(image_path, dest_path)
",510;191;943;347
703,2,https://www.youtube.com/watch?t=24846&v=W5XNOmyJr6I,24846,screencapture-localhost-8000-2022-01-27-13_32_05.png,,code: data_splitting; some cleaning of the copy_images_to_file method,"# Move to train and test
def copy_images_to_file(img_path_list, split_dir):
   # Copy images
   for image_path in img_path_list:
      image_file_name = os.path.split(image_path)[-1]
      dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)
      print(f""Copying: {image_path} to {dest_path}"")
      copy2(image_path, dest_path)

for split_dir in [""train"", ""test""]:
   for image_path_list in [food_image_filepaths, non_food_image_filepaths]:
      train_images, test_images = create_train_test_list(image_path_list)

copy_images_to_file(train_images, )
",513;211;943;455
704,2,https://www.youtube.com/watch?t=24871&v=W5XNOmyJr6I,24871,screencapture-localhost-8000-2022-01-27-13_33_10.png,,"goal: ""let's just rewrite this from scratch because I need some different logic here""",,
705,2,https://www.youtube.com/watch?t=25170&v=W5XNOmyJr6I,25170,screencapture-localhost-8000-2022-01-27-13_39_12.png,,code: data_splitting; getting ready to copy the training food data.,"train_images, test_images = create_train_test_list(food_image_filepaths)

# Training images
target_dir = ""data/train/food_images/""
for image_path in train_images:
   image_filename = image_path.split()[-1]
   dest_path = os.path.join(target_dir, image_filename)
   print(f""Copying {image_path} to {dest_path}"")
   # copy2(image_path, )
",510;359;805;253
706,2,https://www.youtube.com/watch?t=25178&v=W5XNOmyJr6I,25178,screencapture-localhost-8000-2022-01-27-13_40_18.png,,output: seems to have sensible directories,,
707,2,https://www.youtube.com/watch?t=25211&v=W5XNOmyJr6I,25211,screencapture-localhost-2222-2022-05-02-14_28_14.png,,code: data_splitting; adding print of image_filename,"train_images, test_image 

# Training images 
target_dir = ""data/train 
for image_path in train_
   image_filename = ima
   print(image_filename)
   dest_path = os.path.join(target_dir, image_filename)
   print(f""Copying {image_path} to {dest_path}"")
   # copy2(image_path, )
",423;276;685;248
708,2,https://www.youtube.com/watch?t=25212&v=W5XNOmyJr6I,25212,screencapture-localhost-8000-2022-01-27-13_42_13.png,,output: example output,,
709,2,https://www.youtube.com/watch?t=25234&v=W5XNOmyJr6I,25234,screencapture-localhost-8000-2022-01-27-16_05_48.png,,code: data_splitting; getting just the filename without the path,"target_dir = ""data/train/food_images/""
for image_path in trajn_images:
   image_filename = os.path.split(image_path)[-1]
   print(image_filename)
   dest_path = os.path.join(target_dir, image_filename)
   print(f“Copying {image_path} to {dest_path}"")
   # copy2(image_path, )
",516;193;637;232
710,2,https://www.youtube.com/watch?t=25235&v=W5XNOmyJr6I,25235,screencapture-localhost-8000-2022-01-27-16_06_34.png,,output: now copying to train food images without the classname directory,,
711,2,https://www.youtube.com/watch?t=25272&v=W5XNOmyJr6I,25272,screencapture-localhost-8000-2022-01-27-16_08_40.png,,code: data_splitting; setting up for moving both test and training images without their classname sub directories,"# Training images
target_dir = ""data/train/food_images/""
for image_path in train_images:
   image_filename = os.path.split(image_path)[-1]
   # print(image_filename)
   dest_path = os.path.join(target_dir, image_filename)
   print(f""Copying {image_path} to {dest_path}"")
   # copy2(image_path, )

# Test images
target_dir = ""data/test/food_images/""
for image_path in test_images:
   image_filename = os.path.split(image_path) [-1]
   # print(image_filename)
   dest_path = os.path.join(target_dir, image_filename)
   print(f""Copying {imagp_path} to {dest_path}"")
   # copy2(image_path, )
",507;185;661;476
712,2,https://www.youtube.com/watch?t=25275&v=W5XNOmyJr6I,25275,screencapture-localhost-8000-2022-01-27-16_09_24.png,,"output: seems to have the paths correct, but the copy is not currently happening",,
713,2,https://www.youtube.com/watch?t=25297&v=W5XNOmyJr6I,25297,screencapture-localhost-2222-2022-05-02-14_15_31.png,,code: data_splitting; make it so the data copy actually happens,"for image_path in train_images:
   image_filename = os.path.split(image_path)[-1]
   # print(inage_filenane)
   dest_path = os.path.join(target_dir, image_filename)
   print(f""Copying {image_path} to {dest_path}"")
   copy2(image_path, dest_path)

# Test images
target_dir = ""data/test/food_images/""
for image_path in test_images:
   image_filename = os.path.split(image_path)[-1]
   # print(image_filenane)
   dest_path = os.path.join(target_dir, image_filename)
   print(f""Copying {image_path} to {dest_path}"")
   copy2(image_path, dest_path)
",433;263;551;346
714,2,https://www.youtube.com/watch?t=25307&v=W5XNOmyJr6I,25307,screencapture-localhost-8000-2022-01-27-16_12_27.png,,output: error no such file or directory data/train/food_images/some file,,
715,2,https://www.youtube.com/watch?t=25343&v=W5XNOmyJr6I,25343,screencapture-localhost-8000-2022-01-27-16_13_34.png,,code: data_splitting; making the directories for test and train underneath food_images,"# Training images
target_dir = ""data/train/food_images/""
os.makedirs(target_dir, exist_ok=True)
for image_path in train_images: 
   image_filename = os.path.split(im
   # print(image_filename) 
   dest_path = os.path.join(target_d 
   print(f""Copying {image_path} to { 
   copy2(image_path, dest_path) 

# Test images
target_dir = ""data/test/food_images/""
os.makedirs(target_dir, exist_ok=True)
for image_path in test_images:
   image_filename = os.path.split(image_path)[-1]
   # print(image_filename)
   dest path = os.path.join(target_dir, image_filename)
",513;214;625;458
716,2,https://www.youtube.com/watch?t=25383&v=W5XNOmyJr6I,25383,screencapture-localhost-8000-2022-01-27-16_14_49.png,,goal: let's functionize this - why is it taking me so long to process this data?,,
717,2,https://www.youtube.com/watch?t=25516&v=W5XNOmyJr6I,25516,,,"code: data_splitting; functionize the copying to the test/train directories, currently has stray :s at end of calls to functions",,675;226;421;130
718,2,https://www.youtube.com/watch?t=25520&v=W5XNOmyJr6I,25520,screencapture-localhost-8000-2022-01-27-16_17_54.png,,output: invalid syntax,"train_images, test_images = create_train_test_list(food_image_filepaths)

# Training images
def copy_images_to_file(image_list, target_dir):
   # target_dir = ""data/train/food_lmages/""
   os.makedirs(target_dir, exist_ok=True)
   for image_path in image_list:
   image_filename = os.path.split(image_path)[-1]
   # print(image_filename)
   dest_path = os.path.join(target_dir, image_filename)
   print(f""Copying {image_path} to {dest path}"")
   copy2(image_path, dest_path)

copy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/""):
copy_images_to_file(image_list=train_images, target_dir=“data/train/foodimages/""):
",507;235;907;410
719,2,https://www.youtube.com/watch?t=25523&v=W5XNOmyJr6I,25523,,,code: data_splitting; corrected calls to copy images function,,675;226;421;130
720,2,https://www.youtube.com/watch?t=25524&v=W5XNOmyJr6I,25524,screencapture-localhost-8000-2022-01-27-16_20_22.png,,output: looks like files are being copied,,
721,2,https://www.youtube.com/watch?t=25542&v=W5XNOmyJr6I,25542,screencapture-localhost-8000-2022-01-27-16_21_01.png,,code: data_splitting; fix calls so that test go to test images,"os.makedirs(target_dir, exist_ok=True)
for image_path in image_list:
   image_filename = os.path.split(image_path)[-1]
   # print(image_filename)
   dest_path = os.path.join(target_dir, image_filename)
   print(f“Copying {image_path} to {dest_path}"")
   copy2(image_path, dest_path)

copy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/"")
copy_images_to_file(image_list=test_images, target_dir=""data/test/food_images/"")
",519;191;883;281
722,2,https://www.youtube.com/watch?t=25558&v=W5XNOmyJr6I,25558,screencapture-localhost-8000-2022-01-27-16_21_41.png,,output: that did not fix it; test images directory is still empty,,
723,2,https://www.youtube.com/watch?t=25610&v=W5XNOmyJr6I,25610,screencapture-localhost-8000-2022-01-27-16_30_27.png,,code: data_splitting; trying to figure out why the test data isn't ending up in test.,"train_images, test_images = create_train_test_list(food_image_filepaths)

# Training images
def copy_images_to_file(image_list, target_dir):
   # target_dir = ""data/train/food_images/""
   os.makedirs(target_dir, exist_ok=True)
   for image_path in image_list:
      image_filename = os.path.split(image_path)[-1]
      # print(image_filename)
      dest_path = os.path.join(target_dir, image_filename)
      print(f""Copying {image_path} to {dest_path}"")
      copy2(image_path, dest_path)

print(test_images)
copy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/"")
copy_images_to_file(image_list=test_images, target_dir=""data/test/food_images/""|)
",513;185;886;434
724,2,https://www.youtube.com/watch?t=25689&v=W5XNOmyJr6I,25689,screencapture-localhost-8000-2022-01-27-16_32_59.png,,output: looks like the files are there (maybe vscode isn't refreshing the dir view?),,
725,2,https://www.youtube.com/watch?t=25738&v=W5XNOmyJr6I,25738,,,code: data_splitting; now repeating the process of test/train split for the non-food images,,675;226;421;130
726,2,https://www.youtube.com/watch?t=25755&v=W5XNOmyJr6I,25755,screencapture-localhost-8000-2022-01-27-16_40_59.png,,output: images are going into directories,,
727,2,https://www.youtube.com/watch?t=25755&v=W5XNOmyJr6I,25755,screencapture-localhost-8000-2022-01-27-16_40_59.png,,goal: ok now we have two classes who's ready to build a big dog model?,,
728,2,https://www.youtube.com/watch?t=25899&v=W5XNOmyJr6I,25899,screencapture-localhost-8000-2022-01-28-09_54_25.png,,code: model_building; updating the test and train directories with the food/not food data.,"train_dir = ""data/train""
test_dir = ""data/test""
train_dir, test_dir

# Load in data
train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,
   batch_size=32,
   image_size=(224, 224)
)

test data = tf.keras.preprocessing.image dataset from directory(test dir,
",513;257;805;422
729,2,https://www.youtube.com/watch?t=25900&v=W5XNOmyJr6I,25900,screencapture-localhost-8000-2022-01-28-09_55_04.png,,output: tf is not defined; this is probably an import that needs to happen - he just went and re-executed some of the model_building code after the directories are defined.,,
730,2,https://www.youtube.com/watch?t=25909&v=W5XNOmyJr6I,25909,screencapture-localhost-8000-2022-01-28-09_56_08.png,,output: found 10854 files belonging to 2 classes; he reexecutes the import statement and then tries again. now tf has been able to load the data.,,
731,2,https://www.youtube.com/watch?t=25922&v=W5XNOmyJr6I,25922,screencapture-localhost-8000-2022-01-28-09_58_32.png,,"output: found 43467 images for I assume training data, so over 50K total",,
732,2,https://www.youtube.com/watch?t=25943&v=W5XNOmyJr6I,25943,screencapture-localhost-8000-2022-01-28-09_59_42.png,,"output: classnames ""food images"" and ""non food images""; he's just going through and executing the pieces of model building one at a time. ",,
733,2,https://www.youtube.com/watch?t=25943&v=W5XNOmyJr6I,25943,screencapture-localhost-8000-2022-01-28-09_59_42.png,,"goal: ""it's time to build a big big model""",,
734,2,https://www.youtube.com/watch?t=26113&v=W5XNOmyJr6I,26113,screencapture-localhost-8000-2022-01-28-10_03_51.png,,output: trying (and struggling ) to start some kind of watch program on the GPU. I assume this monitors load or something.,"input_layer = tf.keras.Input(shape=(224, 224, 3))
x = base_model(input_layer)
x = tf.keras.layers.GlobalAveragePooling2D() (x)
output_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)

# Construct model
model_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetB0-V1"")
",516;193;838;202
735,2,https://www.youtube.com/watch?t=26129&v=W5XNOmyJr6I,26129,screencapture-localhost-8000-2022-01-28-10_07_08.png,,output: watch -n 1 nvidia-smi and here's the gpu output info I gather,,
736,2,https://www.youtube.com/watch?t=26304&v=W5XNOmyJr6I,26304,screencapture-localhost-8000-2022-01-28-10_21_23.png,,revisit: weights and biases page (his account); model training is currently underway. he wants to know whether weights and biases is working correctly as there's just been a wandb warning.,,
737,2,https://www.youtube.com/watch?t=26304&v=W5XNOmyJr6I,26304,screencapture-localhost-8000-2022-01-28-10_21_23.png,,output: wandb warning,,
738,2,https://www.youtube.com/watch?t=26335&v=W5XNOmyJr6I,26335,screencapture-localhost-8000-2022-01-28-10_23_15.png,,"revisit: wandb compute stats (his account); ""hows the compute going?""",,
739,2,https://www.youtube.com/watch?t=26439&v=W5XNOmyJr6I,26439,screencapture-localhost-8000-2022-01-28-10_25_36.png,,"output: 'we're looking at about 95% accuracy, that's good enough for me'",,
740,2,https://www.youtube.com/watch?t=26512&v=W5XNOmyJr6I,26512,screencapture-localhost-8000-2022-01-28-10_39_07.png,,goal: save model,,
741,2,https://www.youtube.com/watch?t=26524&v=W5XNOmyJr6I,26524,screencapture-localhost-8000-2022-01-28-10_39_37.png,,goal: convert model to tflite for deployment,,
742,2,https://www.youtube.com/watch?t=26611&v=W5XNOmyJr6I,26611,screencapture-localhost-8000-2022-01-28-10_41_29.png,,code: data_exploration; printing num of food images,,675;226;421;130
743,2,https://www.youtube.com/watch?t=26611&v=W5XNOmyJr6I,26611,screencapture-localhost-8000-2022-01-28-10_41_29.png,,output: we only have 2K food images,"len(os.listdir(""data/train/food_images/""))
",144;431;487;49
744,2,https://www.youtube.com/watch?t=26620&v=W5XNOmyJr6I,26620,screencapture-localhost-8000-2022-01-28-10_41_29.png,,output: vs. 41K non-food images,,
745,2,https://www.youtube.com/watch?t=26628&v=W5XNOmyJr6I,26628,screencapture-localhost-8000-2022-01-28-10_42_47.png,,goal: let's increase how many food images that we have.,,
746,2,https://www.youtube.com/watch?t=26634&v=W5XNOmyJr6I,26634,screencapture-localhost-8000-2022-01-28-10_43_33.png,,goal: can i get the food101 dataset in the house,,
747,2,https://www.youtube.com/watch?t=26655&v=W5XNOmyJr6I,26655,screencapture-localhost-8000-2022-01-28-10_44_20.png,,"goal: ""let's just get it working - deployed ..."" [and then we can loop back and get some more images]",,
748,2,https://www.youtube.com/watch?t=26680&v=W5XNOmyJr6I,26680,screencapture-localhost-8000-2022-01-28-10_45_27.png,,code: model_building; saving model1 as version 0,"model_1.save(""food_not_food_model_v0"")
",150;302;451;55
749,2,https://www.youtube.com/watch?t=26708&v=W5XNOmyJr6I,26708,screencapture-localhost-8000-2022-01-28-10_46_17.png,,output: model saved,,
750,2,https://www.youtube.com/watch?t=26718&v=W5XNOmyJr6I,26718,screencapture-localhost-8000-2022-01-28-11_13_02.png,,goal: convert model to tflite for deployment,,
751,2,https://www.youtube.com/watch?t=26717&v=W5XNOmyJr6I,26717,screencapture-localhost-8000-2022-01-28-11_13_41.png,,revisit: tensorflow lite conversion page; he's got this in a tab and just goes right there.,,
752,2,https://www.youtube.com/watch?t=26728&v=W5XNOmyJr6I,26728,,,code: model_building; he copies in code from the tflite conversion page,,675;226;421;130
753,2,https://www.youtube.com/watch?t=26764&v=W5XNOmyJr6I,26764,screencapture-localhost-8000-2022-01-28-11_15_00.png,,code: model_building; updated to include the food_not_food model info.,"# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model dir) #
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:I
   f.write(tflite_model)
",156;359;769;190
754,2,https://www.youtube.com/watch?t=26768&v=W5XNOmyJr6I,26768,screencapture-localhost-8000-2022-01-28-11_16_53.png,,output: misnamed a variable.,"# Convert the model
save_model_dir = ""food_not_food_model_v0""
converter = tf.lite.TFLiteConverter.from_saved_model(saved model dir) # path to the SavedModel directory
tflite_model = converter.convert()

# Save the model.
with open('food_not_food_model_v0.tflite', 'wb') as f:
   f.write(tflite_model)
",162;422;1117;226
755,2,https://www.youtube.com/watch?t=26771&v=W5XNOmyJr6I,26771,screencapture-localhost-8000-2022-01-28-11_18_21.png,,code: model_building; fixed var name,"(variable) saved_model_dir: Literal('food_not_food_model_v0')
saved_model_dir = ""food_not_food_model_v0""
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory
tflite_model = converter.convert()

# Save the model.
with open('food_not_food_model_v0.tflite', 'wb') as f:
   f.write(tflite_model)
",162;281;1111;229
756,2,https://www.youtube.com/watch?t=26792&v=W5XNOmyJr6I,26792,screencapture-localhost-8000-2022-01-28-11_19_07.png,,output: from tflite conversion,,
757,2,https://www.youtube.com/watch?t=26792&v=W5XNOmyJr6I,26792,screencapture-localhost-8000-2022-01-28-11_19_07.png,,goal: do we have a tensorflow lite model?,,
758,2,https://www.youtube.com/watch?t=26795&v=W5XNOmyJr6I,26795,screencapture-localhost-8000-2022-01-28-11_20_25.png,,output: we have a tflite model (visible in file list on the left),,
759,2,https://www.youtube.com/watch?t=26799&v=W5XNOmyJr6I,26799,screencapture-localhost-8000-2022-01-28-11_20_53.png,,goal: let's see if we can get this deployed now,,
760,2,https://www.youtube.com/watch?t=26814&v=W5XNOmyJr6I,26814,screencapture-localhost-8000-2022-01-28-11_21_34.png,,other: this is another mass clean up of tabs.,,
761,2,https://www.youtube.com/watch?t=26829&v=W5XNOmyJr6I,26829,screencapture-localhost-8000-2022-01-28-11_22_32.png,,"visit: repl.it; he types this in directly ""let's now go to repl""",,
762,2,https://www.youtube.com/watch?t=26837&v=W5XNOmyJr6I,26837,screencapture-localhost-8000-2022-01-28-11_23_49.png,,visit: see all repls;,,
763,2,https://www.youtube.com/watch?t=26843&v=W5XNOmyJr6I,26843,screencapture-localhost-8000-2022-01-28-11_24_24.png,,visit: fork orderlymintcream2 repl; I have no idea what this is,,
764,2,https://www.youtube.com/watch?t=26848&v=W5XNOmyJr6I,26848,screencapture-localhost-8000-2022-01-28-11_25_38.png,,other: makes a fork for food-not-food.,,
765,2,https://www.youtube.com/watch?t=26858&v=W5XNOmyJr6I,26858,screencapture-localhost-8000-2022-01-28-11_26_44.png,,visit: food-not-food repl repository; this is associated with his account,,
766,2,https://www.youtube.com/watch?t=26881&v=W5XNOmyJr6I,26881,,,code: classes.js; he's putting in the potential classes - food/not food,,675;226;421;130
767,2,https://www.youtube.com/watch?t=26884&v=W5XNOmyJr6I,26884,screencapture-localhost-8000-2022-01-28-11_29_42.png,,goal: let's check the order,,
768,2,https://www.youtube.com/watch?t=26891&v=W5XNOmyJr6I,26891,screencapture-localhost-8000-2022-01-28-11_30_22.png,,code: model_building; trying to determine which order the classes go in in the model (I think),"train_data.class_names
",510;329;277;46
769,2,https://www.youtube.com/watch?t=26941&v=W5XNOmyJr6I,26941,screencapture-localhost-8000-2022-01-28-11_32_27.png,,output: confirming food/nonfood ordering of labels.,,
770,2,https://www.youtube.com/watch?t=26954&v=W5XNOmyJr6I,26954,screencapture-localhost-8000-2022-01-28-11_33_55.png,,visit: classification on imbalanced data; someone in the chat has commented that the 95% accuracy might be because of the imbalance in the sizes of the training/test sets by class (lots more non-food images and food images),,
771,2,https://www.youtube.com/watch?t=26963&v=W5XNOmyJr6I,26963,screencapture-localhost-8000-2022-01-28-11_35_11.png,,goal: where do we pass them?,,
772,2,https://www.youtube.com/watch?t=26998&v=W5XNOmyJr6I,26998,screencapture-localhost-8000-2022-01-28-11_36_27.png,,goal: let's scale the weights,"# Make model untrainable

base_model.trainable = False

# Build a functional model

input_layer = tf.keras.Input(shape=(224, 224, 3))

x = base_model(input_layer)

x = tf.keras.layers.GlobalAveragePooling2D() (x)

output_layer = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)

# Construct model

model_1 = tf.keras.Model(input_layer, output_layer, name=""EfficientNetBO-v1"")
¢ AL i

tf.keras.utils.plot_model(model_1, show_shapes=True)
",516;199;844;419
773,2,https://www.youtube.com/watch?t=27068&v=W5XNOmyJr6I,27068,screencapture-localhost-8000-2022-01-28-11_39_38.png,,code: model_building; copying in the class scaling code; I'm going to scale the class for now b/c they are going to be different either way.,"# See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data
# Scaling by total/2 helps keep the loss to a similar magnitude.
# The sun of the weights of all exaples stays the same.
weight_for_0 = (1 / neg) * (total / 2.0)
weight_for_1 = (1 / pos) * (total / 2.9)

class_weight = {0: weight_for_0, 1: weight_for_1}

print('Weight for class 0: {:.2f}'.format(weight_for_0))
print{'Weight for class 1: {:.2f}'.format(weight_for_1))
",417;524;724;226
774,2,https://www.youtube.com/watch?t=27156&v=W5XNOmyJr6I,27156,screencapture-localhost-8000-2022-01-28-11_53_54.png,,"code: model_building; trying to quantify the same sizes, but missing a /",,675;226;421;130
775,2,https://www.youtube.com/watch?t=27156&v=W5XNOmyJr6I,27156,screencapture-localhost-8000-2022-01-28-11_53_54.png,,output: error no such file or dir,"total_samples = len(os.listdir(train_dir))
num_food_samples = len(os.listdir(train_dir + ""food_images""))
num_non_food_samples = len(os.listdir(train_dir + ""non_food_images""))
total_samples, num_food_samples, num_non_food_samples
",423;329;658;109
776,2,https://www.youtube.com/watch?t=27176&v=W5XNOmyJr6I,27176,screencapture-localhost-8000-2022-01-28-11_55_25.png,,"code: model_building; trying to use path.join but doesn't replace + with ,","test_dir = ""data/test""
train_dir, test_dir

total_samples = len(os.listdir(train_dir))
num_food_samples = len(os.listdir(os.path.join(train_dir + ""food_images"")))
num_non_food_samples = len(os.listdir(os.path.join(train_dir + ""non_food_images"")))
total_samples, num_food_samples, num_non_food_samples
",423;175;760;259
777,2,https://www.youtube.com/watch?t=27176&v=W5XNOmyJr6I,27176,screencapture-localhost-8000-2022-01-28-11_55_25.png,,output: error no such file or directory,"test_dir = ""data/test""
train_dir, test_dir

total_samples = len(os.listdir(train_dir))
num_food_samples = len(os.listdir(os.path.join(train_dir + ""food_images"")))
num_non_food_samples = len(os.listdir(os.path.join(train_dir + ""non_food_images"")))
total_samples, num_food_samples, num_non_food_samples
",420;179;763;257
778,2,https://www.youtube.com/watch?t=27186&v=W5XNOmyJr6I,27186,screencapture-localhost-8000-2022-01-28-11_57_18.png,,code: model_building; fixed join call,,675;226;421;130
779,2,https://www.youtube.com/watch?t=27186&v=W5XNOmyJr6I,27186,screencapture-localhost-8000-2022-01-28-11_57_18.png,,"output: now have accurate counts for food and not food training images. the total is just counting train and test directories, so 2","test_dir = ""data/test""
train_dir, test_dir

total_samples = len(os.listdir(train_dir))
num_food_samples = len(os.listdir(os.path.join(train_dir, ""food_images"")))
num_non_food_samples = len(os.listdir(os.path.join(train_dir, ""non_food_images"")))
total_samples, num_food_samples, num_non_food_samples 

# See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data
# Scaling by total/2 helps keep the loss to a similar magnitude.
# The sum of the weights of all examples stays the same.
weight_for_0 = (1 / neg) * (total / 2.0)
weight_for_1 = (1 / pos) * (total / 2.0)

class_weight = {0: weight_for_0, 1: weight_for_1}

print(""weight for class 0: {:.2f}"".format(weight_for_0))
",423;173;742;578
780,2,https://www.youtube.com/watch?t=27223&v=W5XNOmyJr6I,27223,screencapture-localhost-8000-2022-01-28-12_00_28.png,,"code: model_building; has filled in the scaling code with class weights, but total is misnamed.",,675;226;421;130
781,2,https://www.youtube.com/watch?t=27223&v=W5XNOmyJr6I,27223,screencapture-localhost-8000-2022-01-28-12_00_28.png,,output: error - total is not defined.,"# Load in data
train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,
   batch_size=32,
   image_size=(224, 224)
)

test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,
   batch_size=32,
   image_size=(224, 224)
)
",414;497;700;229
782,2,https://www.youtube.com/watch?t=27231&v=W5XNOmyJr6I,27231,screencapture-localhost-8000-2022-01-28-12_02_33.png,,"code: model_building; fixed total_samples variable name, but the value is still wrong.","# See: https://wa. tensorflow.org/tutorials/structured data/inbalanced data
# Scaling by total/2 helps keep the loss to a similar magnitude.
# The sun of the weights of all examples stays the same.
weight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)
weight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)

class_weight = {0: weight_for_0, 1: weight_for_1} 

print('Weight for class 0: {:.2f}'.format(weight_for_0))
print('Weight for class 1: {:.2f}'.format(weight_for_1))
",420;305;691;232
783,2,https://www.youtube.com/watch?t=27248&v=W5XNOmyJr6I,27248,screencapture-localhost-8000-2022-01-28-12_04_05.png,,goal: since we have a data imbalance let's get class weights.,"# Since we have a data imabalance let's get class weights

# See: https://waw.tensorflow.org/tutorials/structured data/inbalanced data
# Scaling by total/2 helps keep the loss to a similar magnitude.
# The sum of the weights of all examples stays the same.

weight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)
weight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)

class_weight = {0: weight_for_0, 1: weight_for_1}

print('Weight for class 0: {:.2f}'.format(weight_for_0))
print('Weight for class 1: {:.2f}'.format(weight_for_1))
",423;332;694;284
784,2,https://www.youtube.com/watch?t=27248&v=W5XNOmyJr6I,27248,screencapture-localhost-8000-2022-01-28-12_04_05.png,,output: class weights are both 0 (probably due to incorrect total sample numbers),"# Since we have a data imabalance let's get class weights

# See: https://waw.tensorflow.org/tutorials/structured data/inbalanced data
# Scaling by total/2 helps keep the loss to a similar magnitude.
# The sum of the weights of all examples stays the same.
weight_for_0 = (1 / num_food_samples) * (total_samples / 2.0)
weight_for_1 = (1 / num_non_food_samples) * (total_samples / 2.0)

class_weight = {0: weight_for_0, 1: weight_for_1}

print('Weight for class 0: {:.2f}'.format(weight_for_0))
print('Weight for class 1: {:.2f}'.format(weight_for_1))
",426;335;688;281
785,2,https://www.youtube.com/watch?t=27318&v=W5XNOmyJr6I,27318,screencapture-localhost-8000-2022-01-28-12_06_52.png,,code: model_building; trying to print out the weights - forgot the f in front,"class_weight = {0: weight_for_0, 1: weight_for_1}

print('Weight for class 0: {weight_for_0}')
print('Weight for class 1: {weight_for_1}')

# Load in data
train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,
   batch_size=32,
   image_size=(224, 224)
)

test data = tf.keras.preprocessing.image dataset from directory(test_dir,
",162;167;811;476
786,2,https://www.youtube.com/watch?t=27324&v=W5XNOmyJr6I,27324,screencapture-localhost-8000-2022-01-28-13_15_52.png,,code: model_building; has added the f in front of the print,,675;226;421;130
787,2,https://www.youtube.com/watch?t=27324&v=W5XNOmyJr6I,27324,screencapture-localhost-8000-2022-01-28-13_15_52.png,,output: can now see the weights are teeny tiny b/c total is wrong.,"class_weight = {0: weight_for_0, 1: weight_for_1}

print(f'Weight for class 0: {weight_for_0}')
print(f'Weight for class 1: {weight_for_1}')

# Load in data
train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,
   batch_size=32,
   image_size=(224, 224)
)

test data = tf.keras.preprocessing.image dataset from directorv(test_dir,
",162;202;802;476
788,2,https://www.youtube.com/watch?t=27329&v=W5XNOmyJr6I,27329,screencapture-localhost-8000-2022-01-28-13_17_00.png,,goal: shouldn't they add to 1?,,
789,2,https://www.youtube.com/watch?t=27329&v=W5XNOmyJr6I,27329,screencapture-localhost-8000-2022-01-28-13_17_00.png,,revisit: classification on imbalanced data page;,,
790,2,https://www.youtube.com/watch?t=27370&v=W5XNOmyJr6I,27370,screencapture-localhost-8000-2022-01-28-13_18_31.png,,goal: we've got class weights let's see how this influences the training run.,"# wandb.tensorboard.patch(root_logdir=""logs"")
wandb.init(project=""100k-livestream-video"", sync_tensorboard=True)
history_1 = model_1.fit(train_data,
   epochs=5,
   validation_data=test_data,
   callbacks=[early_stopping,
      create_tensorboard_callback(""logs"", model_1.name)])
",165;191;940;205
791,2,https://www.youtube.com/watch?t=27391&v=W5XNOmyJr6I,27391,screencapture-localhost-8000-2022-01-28-13_19_36.png,,code: model_building; adding the classweights into the model fit call (note: the weights are still pretty broken),"# Fit model
import wandb 
# wandb.tensorboard.patch(root_logdir=""logs"")
wandb.init(project=""100k-livestream-video"", sync_tensorboard=True)
history_1 = model_1.fit(train_data,
   epochs=5,
   validation_data=test_data,
   callbacks=[early_stopping,
      create_tensorboard_callback(""logs"", model_1.name)],
   class_weight=class_weight) # adjust for different numbers of classes...
",159;284;1033;275
792,2,https://www.youtube.com/watch?t=27399&v=W5XNOmyJr6I,27399,screencapture-localhost-8000-2022-01-28-13_20_22.png,,"goal: ""do we have weights and biases tracking the history here?""",,
793,2,https://www.youtube.com/watch?t=27399&v=W5XNOmyJr6I,27399,screencapture-localhost-8000-2022-01-28-13_20_22.png,,revisit: weights and biases page (his account);,,
794,2,https://www.youtube.com/watch?t=27410&v=W5XNOmyJr6I,27410,screencapture-localhost-8000-2022-01-28-13_21_26.png,,visit: wandb runs (his account);,,
795,2,https://www.youtube.com/watch?t=27443&v=W5XNOmyJr6I,27443,screencapture-localhost-8000-2022-01-28-13_22_53.png,,goal: we just want to only look at splendid dream; I'm not really sure what all of these names correspond to,,
796,2,https://www.youtube.com/watch?t=27583&v=W5XNOmyJr6I,27583,screencapture-localhost-8000-2022-01-28-13_26_03.png,,"output: the weights do seem to be changing the accuracy - it's lower ""which is what we want. this one will be more robust""","model_1.evaluate(test_data)
",156;623;322;43
797,2,https://www.youtube.com/watch?t=27641&v=W5XNOmyJr6I,27641,screencapture-localhost-8000-2022-01-28-13_27_40.png,,goal: I think we need some more food images,"model_1.evaluate(test_data)
",150;551;349;43
798,2,https://www.youtube.com/watch?t=27641&v=W5XNOmyJr6I,27641,screencapture-localhost-8000-2022-01-28-13_27_40.png,,output: this is more reflective of how our model is actually doing (accuracy under 80% currently),"model_1.evaluate(test_data)
",153;551;322;46
799,2,https://www.youtube.com/watch?t=27676&v=W5XNOmyJr6I,27676,screencapture-localhost-8000-2022-01-28-13_29_09.png,,goal: let's start comparing the models,,
800,2,https://www.youtube.com/watch?t=27676&v=W5XNOmyJr6I,27676,screencapture-localhost-8000-2022-01-28-13_29_09.png,,revisit: wandb runs (his account); watching the comparisons and looking for differences,,
801,2,https://www.youtube.com/watch?t=27757&v=W5XNOmyJr6I,27757,screencapture-localhost-8000-2022-01-28-13_35_42.png,,output: we're getting about 80% accuracy which is pretty good,"len(os.listdir(""data/train/food_images/"")), len(os.listdir(""data/train/non_food_images/""))
",159;494;982;64
802,2,https://www.youtube.com/watch?t=27769&v=W5XNOmyJr6I,27769,screencapture-localhost-8000-2022-01-28-13_36_16.png,,goal: let's save the model,"len(os.listdir(""data/train/food_images/"")), len(os.listdir(""data/train/non_food_images/""))

model_1. save(""food_not_food_model_v1"")
",153;278;973;329
803,2,https://www.youtube.com/watch?t=27789&v=W5XNOmyJr6I,27789,screencapture-localhost-8000-2022-01-28-13_36_53.png,,"goal: ""and then we'll get it converted to tf lite""",,
804,2,https://www.youtube.com/watch?t=27838&v=W5XNOmyJr6I,27838,screencapture-localhost-8000-2022-01-28-13_38_09.png,,goal: let's create another bucket; I assume this means a place to upload the model to.,,
805,2,https://www.youtube.com/watch?t=27855&v=W5XNOmyJr6I,27855,screencapture-localhost-8000-2022-01-28-13_39_02.png,,visit: console.cloud.google.com; he types this in directly,,
806,2,https://www.youtube.com/watch?t=27869&v=W5XNOmyJr6I,27869,screencapture-localhost-8000-2022-01-28-13_40_12.png,,goal: I'm going to create a bucket; if you haven't used google cloud that's ok,,
807,2,https://www.youtube.com/watch?t=27940&v=W5XNOmyJr6I,27940,screencapture-localhost-8000-2022-01-28-13_41_52.png,,other: he's uploading the food_not_food model to a google bucket.,,
808,2,https://www.youtube.com/watch?t=27954&v=W5XNOmyJr6I,27954,screencapture-localhost-8000-2022-01-28-13_42_38.png,,goal: I think we can get a smaller model (currently 15MB),,
809,2,https://www.youtube.com/watch?t=27981&v=W5XNOmyJr6I,27981,screencapture-localhost-8000-2022-01-28-13_43_32.png,,goal: let's get a smaller model building,,
810,2,https://www.youtube.com/watch?t=28034&v=W5XNOmyJr6I,28034,screencapture-localhost-8000-2022-01-28-13_44_49.png,,other: he's just done a reasonable explanation of the bucket's role in response to a question from the chat,,
811,2,https://www.youtube.com/watch?t=28060&v=W5XNOmyJr6I,28060,screencapture-localhost-8000-2022-01-28-13_45_47.png,,revisit: console.cloud bucket; model is uploaded and he's changing the permissions on it.,,
812,2,https://www.youtube.com/watch?t=28074&v=W5XNOmyJr6I,28074,screencapture-localhost-8000-2022-01-28-13_46_55.png,,visit: colab.research.google.com; also a direct visit.,,
813,2,https://www.youtube.com/watch?t=28084&v=W5XNOmyJr6I,28084,screencapture-localhost-8000-2022-01-28-13_48_28.png,,visit: colab new notebook;,,
814,2,https://www.youtube.com/watch?t=28089&v=W5XNOmyJr6I,28089,screencapture-localhost-8000-2022-01-28-13_48_59.png,,"other: initiating a download of the model using wget, presumably to colab",,
815,2,https://www.youtube.com/watch?t=28153&v=W5XNOmyJr6I,28153,screencapture-localhost-8000-2022-01-28-13_50_50.png,,goal: we're going to build and deploy the application at the same time,,
816,2,https://www.youtube.com/watch?t=28169&v=W5XNOmyJr6I,28169,screencapture-localhost-8000-2022-01-28-13_51_35.png,,search: google storage pricing; this is not related to the code but in response to a chat questions,,
817,2,https://www.youtube.com/watch?t=28177&v=W5XNOmyJr6I,28177,screencapture-localhost-8000-2022-01-28-13_52_11.png,,visit: cloud storage pricing; not problem related.,,
818,2,https://www.youtube.com/watch?t=28231&v=W5XNOmyJr6I,28231,screencapture-localhost-8000-2022-01-28-13_53_40.png,,goal: we do need to change the cors setting.,,
819,2,https://www.youtube.com/watch?t=28231&v=W5XNOmyJr6I,28231,screencapture-localhost-8000-2022-01-28-13_53_40.png,,search: cors policy google storage bucket;,,
820,2,https://www.youtube.com/watch?t=28236&v=W5XNOmyJr6I,28236,screencapture-localhost-8000-2022-01-28-14_19_47.png,,visit: cross-origin resource sharing (CORS);,,
821,2,https://www.youtube.com/watch?t=28283&v=W5XNOmyJr6I,28283,,,code: classes.js; just delete file (still visible in the browser),,675;226;421;130
822,2,https://www.youtube.com/watch?t=28288&v=W5XNOmyJr6I,28288,screencapture-localhost-8000-2022-01-28-14_21_05.png,,code: script.js; has added the classes const to the top.,"export const classes = {
1: ""food"",
2: ""not_food""
};
",483;257;274;109
824,2,https://www.youtube.com/watch?t=28473&v=W5XNOmyJr6I,28473,screencapture-localhost-8000-2022-01-28-14_27_32.png,,code: script.js; this is more tour of his pre-created code. I don't think he's made changes beyond fixing the class names at the beginning,"   // Check if model loaded
   if (tfliteModel) {
      model_status.innerText = ""Model loaded"";
   }
} catch (error) {
   console. log(error);
}

// // Prepare input tensors.
// const img = tf.browser.fromPixels(document.querySelector('img'));
// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);

// // Run inference and get output tensors.
// let outputTensor = tfliteModel.predict(input);
// console.log(outputTensor.dataSync());
}
loadModel() ;

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to
   be same as model inputs
   image = tf.expandDims(image);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as
   output thus we cast int32 in below line
  image = tf.cast(image, ""int32""); // Model requires uints
  const output = model.predict(image) ;
  const output_values = tf.softmax(output.arraySync()[0]);
  console. log(output.arraySync()) //arraySync() Returns an array to use

  // update HTML
  predicted_class.innerText = classes[output_values.argMax().arraySync()];
  predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
",486;278;664;847
825,2,https://www.youtube.com/watch?t=28556&v=W5XNOmyJr6I,28556,screencapture-localhost-8000-2022-01-28-14_29_39.png,,code: index.html; adding more explanatory text to the app description,,675;226;421;130
826,2,https://www.youtube.com/watch?t=28592&v=W5XNOmyJr6I,28592,screencapture-localhost-8000-2022-01-28-14_32_54.png,,code: index.html; separating out desc into sep paragraphs,,675;226;421;130
827,2,https://www.youtube.com/watch?t=28592&v=W5XNOmyJr6I,28592,screencapture-localhost-8000-2022-01-28-14_32_54.png,,output: you can see the output on the right,,
828,2,https://www.youtube.com/watch?t=28609&v=W5XNOmyJr6I,28609,screencapture-localhost-8000-2022-01-28-14_33_58.png,,code: index.html; adding a <br> after desc,"<IDOCTYPE html>
<html>
   <head>
      <meta charset=""utf-8"" />
      <meta name=""viewport"" content=""width=device-width"" />
      <title>Hello World - TensorFlow.js</title>
      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />
   </head>
   <body>
      <h1>Food Not Food</h1>
      <p>This app will tell you if the image you upload is food or not.</p>
      <p>Yes. That's it. </p>
      <p>It'll use a computer vision machine learning model to classify your
      image as ""food"" or ""not food"".</p>
      <br>
      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>
      <p id=""status"">Awaiting TF.js load</p>
      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>

      <!— Upload image —>
      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>
      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""
      /></p>
      <p<img id=""image"" width=""200"" /></p>

      <p>Predicted class:</p>
      <p id=""predicted_class""></p>
      <p>Predicted probability:</p>
      <p id=""predicted_prob""></p>
     
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""
         type=""text/javascript""
      ></script>
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>

      <script src=""script.js""></script>
   </body>
</html>
",474;250;664;877
829,2,https://www.youtube.com/watch?t=28609&v=W5XNOmyJr6I,28609,screencapture-localhost-8000-2022-01-28-14_33_58.png,,output: rendered on right,"<IDOCTYPE html>
<html>
   <head>
      <meta charset=""utf-8"" />
      <meta name=""viewport"" content=""width=device-width"" />
      <title>Hello World - TensorFlow.js</title>
      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />
   </head>
   <body>
      <h1>Food Not Food</h1>
      <p>This app will tell you if the image you upload is food or not.</p>
      <p>Yes. That's it. </p>
      <p>It'll use a computer vision machine learning model to classify your
      image as ""food"" or ""not food"".</p>
      <br>
      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>
      <p id=""status"">Awaiting TF.js load</p>
      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>

      <!— Upload image —>
      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>
      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""
      /></p>
      <p<img id=""image"" width=""200"" /></p>

      <p>Predicted class:</p>
      <p id=""predicted_class""></p>
      <p>Predicted probability:</p>
      <p id=""predicted_prob""></p>
     
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""
         type=""text/javascript""
      ></script>
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>

      <script src=""script.js""></script>
   </body>
</html>",
830,2,https://www.youtube.com/watch?t=28645&v=W5XNOmyJr6I,28645,screencapture-localhost-8000-2022-01-28-14_35_40.png,,code: index.html; updating the model loading feedback,,675;226;421;130
831,2,https://www.youtube.com/watch?t=28645&v=W5XNOmyJr6I,28645,screencapture-localhost-8000-2022-01-28-14_35_40.png,,output: rendered on right,"      <title>Hello World - TensorFlow.js</title>
      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />
   </head>
   <body>
      <h1>Food Not Food</h1>
      <p>This app will tell you if the image you upload is food or not.</p>
      <p>Yes. That's it. </p>
      <p>It'll use a computer vision machine learning model to classify your
      image as ""food"" or ""not food"".</p>
      <br>
      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>
      <p id=""status"">Awaiting TF.js load</p>

      <br>
      <p> This line below will say loaded if the model is loaded:</p>
      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>

      <!— Upload image —>
      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>
      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""
      /></p>
      <p<img id=""image"" width=""200"" /></p>

      <p>Predicted class:</p>
      <p id=""predicted_class""></p>
      <p>Predicted probability:</p>
      <p id=""predicted_prob""></p>
     
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""
         type=""text/javascript""
      ></script>
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>

      <script src=""script.js""></script>
   </body>
</html>",
832,2,https://www.youtube.com/watch?t=28665&v=W5XNOmyJr6I,28665,screencapture-localhost-8000-2022-01-28-14_36_31.png,,code: index.html; adding another <br> before image upload stuff,"      <title>Hello World - TensorFlow.js</title>
      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />
   </head>
   <body>
      <h1>Food Not Food</h1>
      <p>This app will tell you if the image you upload is food or not.</p>
      <p>Yes. That's it. </p>
      <p>It'll use a computer vision machine learning model to classify your
      image as ""food"" or ""not food"".</p>
      <br>
      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>
      <p id=""status"">Awaiting TF.js load</p>
      <br>
      <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>
      <p id=""status"">Awaiting TF.js model/TFLite model loading</p>

      <!— Upload image —>
      <br>
      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>
      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""
      /></p>
      <p<img id=""image"" width=""200"" /></p>

      <p>Predicted class:</p>
      <p id=""predicted_class""></p>
      <p>Predicted probability:</p>
      <p id=""predicted_prob""></p>
     
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""
         type=""text/javascript""
      ></script>
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>

      <script src=""script.js""></script>
   </body>
</html>",675;226;421;130
833,2,https://www.youtube.com/watch?t=28665&v=W5XNOmyJr6I,28665,screencapture-localhost-8000-2022-01-28-14_36_31.png,,output: rendered on right,"      <title>Hello World - TensorFlow.js</title>
      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />
   </head>
   <body>
      <h1>Food Not Food</h1>
      <p>This app will tell you if the image you upload is food or not.</p>
      <p>Yes. That's it. </p>
      <p>It'll use a computer vision machine learning model to classify your
      image as ""food"" or ""not food"".</p>
      <br>
      <p>This Line below will say loaded if TensorFlow.js is loaded:</p>
      <p id=""status"">Awaiting TF.js load</p>

      <br>
      <p>This line below will say loaded if the model is loaded</p>
      <p id=""status"">Awaiting TF.js model/TFLite model loading</p>

      <!— Upload image —>
      <br>
      <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>
      <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""
      /></p>
      <p<img id=""image"" width=""200"" /></p>

      <p>Predicted class:</p>
      <p id=""predicted_class""></p>
      <p>Predicted probability:</p>
      <p id=""predicted_prob""></p>
     
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs/dist/tf.min.js""
         type=""text/javascript""
      ></script>
      <script
         src=""https://cdn.jsdelivr.net/ngm/gtensorflow/tfjs-tflite00.0.1-alpha.7/dist/tf-tflite.min.js""></script>

      <script src=""script.js""></script>
   </body>
</html>",
834,2,https://www.youtube.com/watch?t=28696&v=W5XNOmyJr6I,28696,screencapture-localhost-8000-2022-01-28-14_37_42.png,,output: mushroom image classified as undefined; he says this is due to a change he just made,"const classes = {
   1: “food"",
   2: ""not_food""
};

const status = document.getElementById(“status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""
         ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
",474;257;676;871
835,2,https://www.youtube.com/watch?t=28857&v=W5XNOmyJr6I,28857,screencapture-localhost-8000-2022-01-28-14_41_01.png,,revisit: google cloud bucket; he's copying the url for the model,,
836,2,https://www.youtube.com/watch?t=28863&v=W5XNOmyJr6I,28863,screencapture-localhost-8000-2022-01-31-10_05_30.png,,"other: closed several tabs; ""can that can that...""","const status = document.getElementById(“status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""
         // ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();
",
837,2,https://www.youtube.com/watch?t=28865&v=W5XNOmyJr6I,28865,screencapture-localhost-8000-2022-01-31-10_06_18.png,,"goal: ""we do need to update the cross-region origin policy""","const status = document.getElementById(“status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""

         ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
",
838,2,https://www.youtube.com/watch?t=28913&v=W5XNOmyJr6I,28913,screencapture-localhost-8000-2022-01-31-10_07_40.png,,other: uploaded tflite model to the replit space,"const classes = {
   1: “food"",
   2: ""not_food""
};

const status = document.getElementById(“status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""
         ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
",
839,2,https://www.youtube.com/watch?t=28963&v=W5XNOmyJr6I,28963,screencapture-localhost-8000-2022-01-31-10_09_14.png,,code: script.js; calling local copy of the food_not_food tflite model,"const classes = {
   1: “food"",
   2: ""not_food""
};

const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""
         ""/food_not_food_model_v1.tflite""
         ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
",675;226;421;130
840,2,https://www.youtube.com/watch?t=28963&v=W5XNOmyJr6I,28963,screencapture-localhost-8000-2022-01-31-10_09_51.png,,code: script.js; adding the food_not_food tflite model to the code,,675;226;421;130
841,2,https://www.youtube.com/watch?t=28973&v=W5XNOmyJr6I,28973,screencapture-localhost-8000-2022-01-31-10_10_45.png,,"output: ""model loaded""; ""look at that team!""","const classes = {
   1: “food"",
   2: ""not_food""
};

const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""
         ""/food_not_food_model_v1.tflite""
         ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
",
842,2,https://www.youtube.com/watch?t=28982&v=W5XNOmyJr6I,28982,screencapture-localhost-8000-2022-01-31-10_11_38.png,,"goal: ""who's ready to test out the model?""",,
843,2,https://www.youtube.com/watch?t=29020&v=W5XNOmyJr6I,29020,screencapture-localhost-8000-2022-01-31-10_12_40.png,,code: index.html; adding burger not burger emojis to the html page.,"<IDOCTYPE html>
<html>
   <head>
      <meta charset=""utf-8"" />
      <meta name=""viewport"" content=""width=device-width"" /> !
      <title>Hello World - TensorFlow.js</title>
      <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />
   </head>

<body>
   <h1>Food Not Food (£ or £© )</h1>
   <p>This app will tell you if the image you upload is food or not.</p>
   <p>Yes. That's it. </p>
   <p>It'll use a computer vision machine learning model to classify your
   image as ""food"" or ""not food"".</p>
   <br>
   <p>This line below will say loaded if TensorFlow.js is loaded:</p>
   <p id=""status'"">Awaiting TF.js load</p>

   <br>
   <p>This line below will say loaded if the model is loaded:</p>
   <p id=""model status"">Awaiting TF.js model/TFLite model loading</p>

   <!-- Upload image -->
   <br>
   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>
   <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input""
   /></p>
   <p><img id=""inage"" width=""200"" /></p>

   <p>Predicted class:</p>
   <p id=""predicted_class""></p>
   <p>Predicted probability:</p>
   <p id=""predicted_prob""></p>

   <script
      src=""https://cdn.jsdelivr.net/npn/gtensorflow/tfjs/dist/tf.min.js""
      type=""text/javascript""
   ></script>
",486;247;673;814
844,2,https://www.youtube.com/watch?t=29031&v=W5XNOmyJr6I,29031,screencapture-localhost-8000-2022-01-31-10_13_32.png,,"search: truck; ""what should we try....uhmm truck""",,
845,2,https://www.youtube.com/watch?t=29089&v=W5XNOmyJr6I,29089,screencapture-localhost-8000-2022-01-31-10_15_00.png,,"output: ""script error""; what did we get wrong?",,
846,2,https://www.youtube.com/watch?t=29128&v=W5XNOmyJr6I,29128,screencapture-localhost-8000-2022-01-31-10_16_17.png,,"code: script.js; commenting out the new model, re-adding the example 10 class model and trying the truck with that.","const classes = {
   1: “food"",
   2: ""not_food""
};

const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""
         //""/food_not_food_model_v1.tflite""
         ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

};
",675;226;421;130
847,2,https://www.youtube.com/watch?t=29146&v=W5XNOmyJr6I,29146,screencapture-localhost-8000-2022-01-31-10_17_43.png,,code: script.js; re-adding the food not food model,"const classes = {
   1: “food"",
   2: ""not_food""
};

const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""
         ""/food_not_food_model_v1.tflite""
         // ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
",675;226;421;130
848,2,https://www.youtube.com/watch?t=29181&v=W5XNOmyJr6I,29181,screencapture-localhost-8000-2022-01-31-10_19_20.png,,"output: same script error; ""ok we're getting a script error for this one so there's probably something wrong here""",,
849,2,https://www.youtube.com/watch?t=29191&v=W5XNOmyJr6I,29191,screencapture-localhost-8000-2022-01-31-10_20_27.png,,code: script.js; example model back in,"if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         ""https://storage.googleapis. con/food-vision-models-test/10_whole_foods_
         model_v0. tflite""
         // ""/food_not_food_model_v1.tflite""
         ""/10_whole_foods_model_vo. tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
",675;226;421;130
850,2,https://www.youtube.com/watch?t=29211&v=W5XNOmyJr6I,29211,screencapture-localhost-8000-2022-01-31-10_21_10.png,,"output: list of ints; ""what outputs do we get here?"" he's trying to understand the example code that he's building off of.",,
851,2,https://www.youtube.com/watch?t=29236&v=W5XNOmyJr6I,29236,screencapture-localhost-8000-2022-01-31-10_22_28.png,,code: script.js; console logging DType - this may be an image formatting issue?,"      }
   } catch (error) {
      console.log(error); 
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as 
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   image = tf.cast(image, ""int32""); // Model requires uint8
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""&"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
",477;260;682;811
852,2,https://www.youtube.com/watch?t=29242&v=W5XNOmyJr6I,29242,screencapture-localhost-8000-2022-01-31-10_23_30.png,,code: script.js; bring the new model back in.,"const classes = {
   1: ""food"",
   2: ""not_food""
};

const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         https://storage.googleapis.com/food-vision-model-playground/food_not_fo
         od_model_v1.tflite
         ""/food_not_food_model_v1.tflite""
         // ""/10_whole_foods_model_vo kflite""
      };
      model = tfliteModel; // assigning it to the global scope model as
      tfliteModel can only be used within this scope
      // console. log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) { 
         model_status. innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);
",474;253;682;820
853,2,https://www.youtube.com/watch?t=29252&v=W5XNOmyJr6I,29252,screencapture-localhost-8000-2022-01-31-10_24_28.png,,"output: same error; ""I'm pretty sure our model is not accepting the right type of data""",,
854,2,https://www.youtube.com/watch?t=29274&v=W5XNOmyJr6I,29274,screencapture-localhost-8000-2022-01-31-10_25_58.png,,code: script.js; commented out the line casting the image to int32,"      console. log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);

   // Run inference and get output tensors
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to
   be same as model inputs
   image = tf.expandDims (image);

   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFronTFLiteType(""uint8""));
   // image = tf.cast(image, 'int32');  // Model requires uint8
   const output = model.predict(image) ;
   const output_values = tf.softmax(output.arraySync() [6]);
   console.log(output.arraySync());
   console.log(output.arraySync() [0]); // arraySync Returns an array to use


   // Update HTML
   predicted_class. innerText = classes [output_values.argMax().arraySync()1;
   predicted_prob. innerText = output_values.max().arraySync() * 100 + ""5"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"") ;
",486;257;673;790
855,2,https://www.youtube.com/watch?t=29288&v=W5XNOmyJr6I,29288,screencapture-localhost-8000-2022-01-31-10_26_40.png,,"output: again just script error it's not clear where exactly it's occurring. the message about int32 goes away, but still doesn't seem to work",,
856,2,https://www.youtube.com/watch?t=29339&v=W5XNOmyJr6I,29339,screencapture-localhost-8000-2022-01-31-10_28_34.png,,code: script.js; let's console log the image,"      console. log(error);
   }

   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);

   // Run inference and get output tensors
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to
   be same as model inputs
   image = tf.expandDims (image);
   console.log(image);

   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFronTFLiteType(""uint8""));
   // image = tf.cast(image, 'int32');  // Model requires uint8
   const output = model.predict(image) ;
   const output_values = tf.softmax(output.arraySync() [6]);
   console.log(output.arraySync());
   console.log(output.arraySync() [0]); // arraySync Returns an array to use


   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()1;
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"") ;",675;226;421;130
857,2,https://www.youtube.com/watch?t=29359&v=W5XNOmyJr6I,29359,screencapture-localhost-8000-2022-01-31-10_29_14.png,,output: printing image properties (inc float32 type),,
858,2,https://www.youtube.com/watch?t=29419&v=W5XNOmyJr6I,29419,screencapture-localhost-8000-2022-01-31-10_31_05.png,,code: script.js; console logging image.arraySync.,"   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);

   // Run inference and get output tensors
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to
   be same as model inputs
   image = tf.expandDims (image);
   console.log(image.arraySync());

   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFronTFLiteType(""uint8""));
   // image = tf.cast(image, 'int32');  // Model requires uint8
   const output = model.predict(image) ;
   const output_values = tf.softmax(output.arraySync() [6]);
   console.log(output.arraySync());
   console.log(output.arraySync() [0]); // arraySync Returns an array to use

   // Update HTML
   predicted_class. innerText = classes [output_values.argMax().arraySync()1;
   predicted_prob. innerText = output_values.max().arraySync() * 100 + ""5"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"") ;

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files(0);",675;226;421;130
859,2,https://www.youtube.com/watch?t=29437&v=W5XNOmyJr6I,29437,screencapture-localhost-8000-2022-01-31-10_44_28.png,,output: array sync seems to print lots of [Array]; no real insight to be had.,,
860,2,https://www.youtube.com/watch?t=29444&v=W5XNOmyJr6I,29444,screencapture-localhost-8000-2022-01-31-10_45_43.png,,code: script.js; comment out image console logging,"};
loadModel();

// Function to classify image
function classifyImage(model, image) {
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(inage); 
   // console.log(image.arraySync());

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as 
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   // image = tf.cast(image, ""int32""); // Model requires uint8
   const output = model.predict (inage);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output.arraySync());
   console.log(output.arraySync() [0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementByTd(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

   // Get the data url from the image
   const reader = new FileReader();

   // When reader is ready display image
   reader.onload = function (event) {
",480;266;679;805
861,2,https://www.youtube.com/watch?t=29452&v=W5XNOmyJr6I,29452,screencapture-localhost-8000-2022-01-31-10_46_26.png,,search: tensorflow lite model inputs;,,
862,2,https://www.youtube.com/watch?t=29458&v=W5XNOmyJr6I,29458,screencapture-localhost-8000-2022-01-31-10_46_58.png,,visit: tensorflow lite inference;,,
863,2,https://www.youtube.com/watch?t=29501&v=W5XNOmyJr6I,29501,screencapture-localhost-8000-2022-01-31-10_48_11.png,,search: how to know what inputs a tflite model take;,,
864,2,https://www.youtube.com/watch?t=29523&v=W5XNOmyJr6I,29523,screencapture-localhost-8000-2022-01-31-10_49_12.png,,revisit: tflite model conversion overview;,,
866,2,https://www.youtube.com/watch?t=29598&v=W5XNOmyJr6I,29598,screencapture-localhost-8000-2022-01-31-10_51_36.png,,output: script error,,
867,2,https://www.youtube.com/watch?t=29633&v=W5XNOmyJr6I,29633,screencapture-localhost-8000-2022-01-31-10_52_52.png,,code: script.js; uncommented the line casting the image to int32,"};
loadModel();

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image); 
   // console.log(image.arraySync());

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as 
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   image = tf.cast(image, ""int32""); // Model requires uint8
   const output = model.predict (inage);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output.arraySync());
   console.log(output.arraySync() [0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementByTd(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

   // Get the data url from the image
   const reader = new FileReader();

   // When reader is ready display image
   reader.onload = function (event) {",675;226;421;130
868,2,https://www.youtube.com/watch?t=29646&v=W5XNOmyJr6I,29646,screencapture-localhost-8000-2022-01-31-10_54_03.png,,output: same script error. he really just has no real idea where to go here and there's no real path forward based on the error,,
869,2,https://www.youtube.com/watch?t=29671&v=W5XNOmyJr6I,29671,screencapture-localhost-8000-2022-01-31-10_55_07.png,,"code: script.js; bring back the other model - ""if we use the other model, what does that say?""","const status = document.getElementById(""status"");
if (status) {
   status.innerText = “Loaded TensorFlow.js — version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
      //
      https://storage.googleapis.com/food-vision-model-playground/food_not_fo
      od_model_v1.tflite
      // ""/food_not_food_model_v1.tflite""
      ""/10_whole_foods_model_vo. tflite""
   };
   model = tfliteModel; // assigning it to the global scope model as
   tfliteModel can only be used within this scope
   // console.log(tfliteModel);

   // Check if model loaded
   if (tfliteModel) {
      model_status.innerText = ""Model loaded"";
   }
} catch (error) {
   console. log(error) ;
}

   // // Prepare input tensors
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();
",483;257;676;823
870,2,https://www.youtube.com/watch?t=29704&v=W5XNOmyJr6I,29704,screencapture-localhost-8000-2022-01-31-10_56_23.png,,output: gets the same warning but then seems to be able to move forward after that.,"} catch (error) {
   console. log(error) ;
}

   // // Prepare input tensors
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image);
   console.log(image);

   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFliteType(""uint8""));
   image = tf.cast(image, ""float32"");
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");",
872,2,https://www.youtube.com/watch?t=29715&v=W5XNOmyJr6I,29715,screencapture-localhost-8000-2022-01-31-10_57_43.png,,code: script.js; brings back the food not food model,"if (status) {
   status.innerText = “Loaded TensorFlow.js — version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
      //
      https://storage.googleapis.com/food-vision-model-playground/food_not_fo
      od_model_v1.tflite
      ""/food_not_food_model_v1.tflite""
      // ""/10_whole_foods_model_vo. tflite""
   };
   model = tfliteModel; // assigning it to the global scope model as
   tfliteModel can only be used within this scope
   // console.log(tfliteModel);

   // Check if model loaded
   if (tfliteModel) {
      model_status.innerText = ""Model loaded"";
   }
} catch (error) {
   console. log(error) ;
}

   // // Prepare input tensors
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyImage(model, image)",675;226;421;130
873,2,https://www.youtube.com/watch?t=29738&v=W5XNOmyJr6I,29738,screencapture-localhost-8000-2022-01-31-10_58_28.png,,"output: same script error, but no warnings about image conversion. i think the error may actually be farther along",,
874,2,https://www.youtube.com/watch?t=29755&v=W5XNOmyJr6I,29755,screencapture-localhost-8000-2022-01-31-10_59_20.png,,search: what input does tensorflow lite model take;,,
875,2,https://www.youtube.com/watch?t=29760&v=W5XNOmyJr6I,29760,screencapture-localhost-8000-2022-01-31-11_00_27.png,,revisit: tensorflow lite inference page;,,
876,2,https://www.youtube.com/watch?t=29814&v=W5XNOmyJr6I,29814,screencapture-localhost-8000-2022-01-31-11_01_46.png,,output: (of model training) says that the input type is float32,,
877,2,https://www.youtube.com/watch?t=29854&v=W5XNOmyJr6I,29854,screencapture-localhost-8000-2022-01-31-11_03_03.png,,"other: prediction; ""the goal is erroring on the predict function""",,
878,2,https://www.youtube.com/watch?t=29882&v=W5XNOmyJr6I,29882,screencapture-localhost-8000-2022-01-31-11_04_29.png,,code: script.js; change the float32 back to int32,"   console. log(error) ;
}

   // // Prepare input tensors
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyInage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to
   be same as model inputs
   image = tf.expandDims(image);
   console.log(image);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   image = tf.cast(image, ""int32""); // Model requires uint8
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]);  // arraySync() Returns an array to use

   // Update HTHL
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");
",480;250;694;823
879,2,https://www.youtube.com/watch?t=29926&v=W5XNOmyJr6I,29926,screencapture-localhost-8000-2022-01-31-11_06_00.png,,search:tflite.tfliteconverter.from_saved_model(;,,
880,2,https://www.youtube.com/watch?t=29930&v=W5XNOmyJr6I,29930,screencapture-localhost-8000-2022-01-31-11_06_38.png,,revisit: tf.lite.TFLiteConverter;,,
881,2,https://www.youtube.com/watch?t=29965&v=W5XNOmyJr6I,29965,screencapture-localhost-8000-2022-01-31-11_07_40.png,,search: how to check input type to tflite model;,,
882,2,https://www.youtube.com/watch?t=29968&v=W5XNOmyJr6I,29968,screencapture-localhost-8000-2022-01-31-11_08_22.png,,visit: how to know tensorflow lite model's input/output feature info;,,
883,2,https://www.youtube.com/watch?t=30001&v=W5XNOmyJr6I,30001,screencapture-localhost-8000-2022-01-31-11_09_33.png,,"goal: ""we're going to check what our input type is here""; he's going to the netron app which is a model visualizer of some sort",,
884,2,https://www.youtube.com/watch?t=30009&v=W5XNOmyJr6I,30009,screencapture-localhost-8000-2022-01-31-11_11_18.png,,visit: netron.app; has loaded the food_not_food model to see what it looks like.,,
885,2,https://www.youtube.com/watch?t=30030&v=W5XNOmyJr6I,30030,screencapture-localhost-8000-2022-01-31-11_31_47.png,,visit: netron.app input details; confirms that the models input is float32.,,
886,2,https://www.youtube.com/watch?t=30069&v=W5XNOmyJr6I,30069,screencapture-localhost-8000-2022-01-31-11_33_13.png,,"other: someone on the chat has suggested ""remove all image pre-processing and the error should say the shape of data that is required""",,
887,2,https://www.youtube.com/watch?t=30078&v=W5XNOmyJr6I,30078,screencapture-localhost-8000-2022-01-31-11_34_07.png,,code: script.js; removes all the preprocessing by commenting.,"   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel() ;

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   // image = tf.image.resizeBilinear(image, [224, 224]); // image size needs
   to be same as model inputs
   // image = tf.expandDims(image);
   console.log(image);


   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()(0]);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
",483;253;667;826
888,2,https://www.youtube.com/watch?t=30117&v=W5XNOmyJr6I,30117,screencapture-localhost-8000-2022-01-31-11_36_27.png,,output: still seems to do the same thing,,
890,2,https://www.youtube.com/watch?t=30139&v=W5XNOmyJr6I,30139,screencapture-localhost-8000-2022-01-31-11_38_10.png,,output: same script error,,
891,2,https://www.youtube.com/watch?t=30170&v=W5XNOmyJr6I,30170,screencapture-localhost-8000-2022-01-31-11_39_18.png,,code: script.js; commenting out tf.softmax,"   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel() ;

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   // image = tf.image.resizeBilinear(image, [224, 224]); // image size needs
   to be same as model inputs
   // image = tf.expandDims(image);
   console.log(image);


   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   const output = model.predict(image);
   // const output_values = tf.softmax(output.arraySync()(0]);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
",675;226;421;130
892,2,https://www.youtube.com/watch?t=30180&v=W5XNOmyJr6I,30180,screencapture-localhost-8000-2022-01-31-11_40_07.png,,output: script error; so this at least pretty much isolates the issue to predict.,,
893,2,https://www.youtube.com/watch?t=30191&v=W5XNOmyJr6I,30191,screencapture-localhost-8000-2022-01-31-11_40_52.png,,code: script.js; uncomments expandDims,"   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel() ;

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs
   to be same as model inputs
   image = tf.expandDims(image);
   console.log(image);


   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   const output = model.predict(image);
   // const output_values = tf.softmax(output.arraySync()(0]);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
",675;226;421;130
894,2,https://www.youtube.com/watch?t=30197&v=W5XNOmyJr6I,30197,screencapture-localhost-8000-2022-01-31-11_41_36.png,,output: script error;,,
895,2,https://www.youtube.com/watch?t=30206&v=W5XNOmyJr6I,30206,screencapture-localhost-8000-2022-01-31-11_41_36.png,,"other: prediction; ""the output is what's buckling""",,
896,2,https://www.youtube.com/watch?t=30229&v=W5XNOmyJr6I,30229,screencapture-localhost-8000-2022-01-31-11_43_31.png,,code: script.js; added console log of model,"   // console. log(tfliteModel);

   // Check if model loaded
   if (tfliteModel) {
      model_status.innerText = “Model loaded"";
   }
} catch (error) { 
 console.log(error);
}

// // Prepare input tensors.
// const img = tf.browser.fromPixels(document.querySelector('img'));
// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1); 
// // Run inference and get output tensors.
// let outputTensor = tfliteModel.predict(input);
// console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyImage(model, image) {
  // Preprocess image
  image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to
  be same as model inputs
  image = tf.expandDims(image);
  console.log(image);
  console.log(model);

// console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as
output thus we cast int32 in below line
console.log(tflite.getDTypeFronTFLiteType(""uint8""));
// image = tf.cast(image, 'int32'); // Model requires uint8
const output = model.predict(image);
// const output_values = tf.softmax(output.arraySync()[0]);
console.log(output.arraySync());
console.log(output.arraySync()[0]);

",492;253;670;808
897,2,https://www.youtube.com/watch?t=30332&v=W5XNOmyJr6I,30332,screencapture-localhost-8000-2022-01-31-11_45_51.png,,code: script.js; remove the console log of model,"} catch (error) { 
 console.log(error);
}

// // Prepare input tensors.
// const img = tf.browser.fromPixels(document.querySelector('img'));
// const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1); 
// // Run inference and get output tensors.
// let outputTensor = tfliteModel.predict(input);
// console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyImage(model, image) {
  // Preprocess image
  image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to
  be same as model inputs
  image = tf.expandDims(image);
  console.log(image);
  // console.log(model);

// console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output
thus we cast int32 in below line
console.log(tflite.getDTypeFronTFLiteType(""uint8""));
// image = tf.cast(image, 'int32'); // Model requires uint8
const output = model.predict(image);
// const output_values = tf.softmax(output.arraySync()[0]);
console.log(output.arraySync());
console.log(output.arraySync()[0]);

// Update HTML
predicted_class.innerText = classes[output_values.argMax().arraySync()];
predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}
",675;226;421;130
898,2,https://www.youtube.com/watch?t=30350&v=W5XNOmyJr6I,30350,screencapture-localhost-8000-2022-01-31-11_46_44.png,,"output: script error; ""the image gets shaped into that [1,224,224,3] I don't know what's going on with that""",,
899,2,https://www.youtube.com/watch?t=30379&v=W5XNOmyJr6I,30379,screencapture-localhost-8000-2022-01-31-11_48_01.png,,"other: closing tabs. he's kind of given up on the currently trained tflite model - ""if we want this deployed in 2 hours...""",,
900,2,https://www.youtube.com/watch?t=30389&v=W5XNOmyJr6I,30389,screencapture-localhost-8000-2022-01-31-11_49_13.png,,revisit: tflite converter overview;,,
901,2,https://www.youtube.com/watch?t=30425&v=W5XNOmyJr6I,30425,screencapture-localhost-8000-2022-01-31-11_50_38.png,,"goal: ""ok let's try to run this""; referring to the tflite converter example that includes a signature.",,
902,2,https://www.youtube.com/watch?t=30435&v=W5XNOmyJr6I,30435,screencapture-localhost-8000-2022-01-31-11_52_04.png,,"goal: ""Test run TFLite model""; this is back in python again.","# Load the TFLite model in TFLite Interpreter
interpreter = tf.lite.Interpreter(food_not_food_model_v1.tflite)
# There is only 1 signature defined in the model,
# so it will return it by default.
# If there are multiple signatures then we can pass the name.
my_signature = interpreter.get_signature_runner()

# my_signature is callable with input as arguments.
output = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))
# 'output' is dictionary with all outputs from the inference.
# In this case we have single output 'result'.
print(output['result'])",
903,2,https://www.youtube.com/watch?t=30453&v=W5XNOmyJr6I,30453,screencapture-localhost-8000-2022-01-31-11_53_06.png,,code: model_building; testing the tflite model in the python space.,"# Load the TFLite model in TFLite Interpreter
interpreter = tf.lite.Interpreter(food_not_food_model_v1.tflite)
# There is only 1 signature defined in the model,
# so it will return it by default.
# If there are multiple signatures then we can pass the name.
my_signature = interpreter.get_signature_runner()

# my_signature is callable with input as arguments.
output = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))
# 'output' is dictionary with all outputs from the inference.
# In this case we have single output 'result'.
print(output['result'])
",159;257;823;341
904,2,https://www.youtube.com/watch?t=30458&v=W5XNOmyJr6I,30458,screencapture-localhost-8000-2022-01-31-11_53_54.png,,code: model_building; adding quotes around model filename,"# Load the TFLite model in TFLite Interpreter
interpreter = tf.lite.Interpreter(""food_not_food_model_v1.tflite"")
# There is only 1 signature defined in the model,
# so it will return it by default.
# If there are multiple signatures then we can pass the name.
my_signature = interpreter.get_signature_runner()

# my_signature is callable with input as arguments.
output = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))
# 'output' is dictionary with all outputs from the inference,
# In this case we have single output 'result'.
print(output['result'])
",156;332;823;329
905,2,https://www.youtube.com/watch?t=30463&v=W5XNOmyJr6I,30463,screencapture-localhost-8000-2022-01-31-11_54_30.png,,output: error - invalid input name for signature def,,
906,2,https://www.youtube.com/watch?t=30472&v=W5XNOmyJr6I,30472,screencapture-localhost-8000-2022-01-31-11_55_28.png,,code: model_building; commenting out signature line.,"# Load the TFLite model in TFLite Interpreter
interpreter = tf.lite.Interpreter(""food_not_food_model_v1.tflite"")
# There is only 1 signature defined in the model,
# so it will return it by default.
# If there are multiple signatures then we can pass the name.
my_signature = interpreter.get_signature_runner()

# my_signature is callable with input as arguments.
# output = my_signature(x=tf.constant([1.6], shape=(1,10), dtype=tf.float32))
# 'output' is dictionary with all outputs from the inference.
# In this case we have single output 'result'.
# print(output[‘result'])
",153;214;850;323
907,2,https://www.youtube.com/watch?t=30486&v=W5XNOmyJr6I,30486,screencapture-localhost-8000-2022-01-31-11_57_15.png,,output: looking at mysignature which seems to at least be a valid object,,
908,2,https://www.youtube.com/watch?t=30512&v=W5XNOmyJr6I,30512,screencapture-localhost-8000-2022-01-31-11_58_26.png,,code: script.js; adds a print of the output.,"   // // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf. expandDims(img), 127.5), 1);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel() ;

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   // console.log(image);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output
   thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   // image = tf.cast(image, ""int32""); // Model requires uint8
   const output = model.predict(image);
   // const output_values = tf.softmax(output.arraySync()(0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");


",396;266;712;847
909,2,https://www.youtube.com/watch?t=30521&v=W5XNOmyJr6I,30521,screencapture-localhost-8000-2022-01-31-11_59_01.png,,output: same script error,,
910,2,https://www.youtube.com/watch?t=30532&v=W5XNOmyJr6I,30532,screencapture-localhost-8000-2022-01-31-11_59_29.png,,other: prediction; the model's not taking the image in some way shape or form.,,
911,2,https://www.youtube.com/watch?t=30544&v=W5XNOmyJr6I,30544,screencapture-localhost-8000-2022-01-31-12_00_09.png,,revisit: tflite converter overview;,,
912,2,https://www.youtube.com/watch?t=30576&v=W5XNOmyJr6I,30576,screencapture-localhost-8000-2022-01-31-12_01_11.png,,goal: here we go let's try this. this is an example on the tflite converter page that talks about a no signature scenario,,
914,2,https://www.youtube.com/watch?t=30604&v=W5XNOmyJr6I,30604,screencapture-localhost-8000-2022-01-31-12_03_28.png,,code: model_building; changes name of input file to be food not food.,"import numpy as np
import tensorflow as tf

# Load the TFLite model and allocate tensors.|
interpreter = tf.lite.Interpreter(model_path=""food_not_food_model_v1.tflite"")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()
",165;226;835;473
915,2,https://www.youtube.com/watch?t=30612&v=W5XNOmyJr6I,30612,screencapture-localhost-8000-2022-01-31-12_04_11.png,,code: model_building; the rest of the code that was scrolled off.,"interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[@] ['index'], input_data)

interpreter.invoke() 

# The function 'get_tensor()' returns a copy of the tensor data.
# Use 'tensor()' in order to get a pointer to the tensor.
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
",156;205;838;449
916,2,https://www.youtube.com/watch?t=30613&v=W5XNOmyJr6I,30613,screencapture-localhost-8000-2022-01-31-13_03_55.png,,output: this one seems to run.,,
917,2,https://www.youtube.com/watch?t=30622&v=W5XNOmyJr6I,30622,screencapture-localhost-8000-2022-01-31-13_04_44.png,,output: looking at input details; finding int32 again,,
918,2,https://www.youtube.com/watch?t=30715&v=W5XNOmyJr6I,30715,screencapture-localhost-8000-2022-01-31-13_06_59.png,,goal: int32 - let's try that. did we try that already?,,
920,2,https://www.youtube.com/watch?t=30747&v=W5XNOmyJr6I,30747,screencapture-localhost-8000-2022-01-31-13_08_53.png,,"output: same error; ""why is it converting int32 to float32?""",,
921,2,https://www.youtube.com/watch?t=30803&v=W5XNOmyJr6I,30803,screencapture-localhost-8000-2022-01-31-13_10_28.png,,other: git commit and push.,,
922,2,https://www.youtube.com/watch?t=30825&v=W5XNOmyJr6I,30825,screencapture-localhost-8000-2022-01-31-13_11_18.png,,"code: script.js; removing the cast again; ""no need to cast?""","   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);

   // Run inference and get output tensors
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as output 
   thus we cast int32 in below line
   console.log(tflite.getDTypeFronTFLiteType(""uint8""));
   // image = tf.cast(image, 'int32');  // Model requires uint8
   const output = model.predict(image) ;
   // const output_values = tf.softmax(output.arraySync() [6]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync() [0]); // arraySync Returns an array to use

   // Update HTML
   predicted_class.innerText = classes [output_values.argMax().arraySync()1;
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"") ;

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
",675;226;421;130
923,2,https://www.youtube.com/watch?t=30835&v=W5XNOmyJr6I,30835,screencapture-localhost-8000-2022-01-31-13_14_25.png,,output: same error.,,
924,2,https://www.youtube.com/watch?t=30901&v=W5XNOmyJr6I,30901,screencapture-localhost-8000-2022-01-31-13_15_54.png,,code: script.js; adding a model about to predict message,,675;226;421;130
925,2,https://www.youtube.com/watch?t=30901&v=W5XNOmyJr6I,30901,screencapture-localhost-8000-2022-01-31-13_15_54.png,,output: same error,,
926,2,https://www.youtube.com/watch?t=30901&v=W5XNOmyJr6I,30901,screencapture-localhost-8000-2022-01-31-13_15_54.png,,"goal: ""let's train another model; let's get some more data""","};
loadModel();

// function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as
   output thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFliteType(""uint8""));
   // image = tf.cast(image, ""int32"");  // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   // const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if(fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

   // Get the data url from the image
   const reader = new FileReader();",
927,2,https://www.youtube.com/watch?t=30911&v=W5XNOmyJr6I,30911,screencapture-localhost-8000-2022-01-31-13_17_43.png,,goal: let's use tensorflow lite modelmaker to train a bigger model. I'm pretty sure that will work.,,
928,2,https://www.youtube.com/watch?t=30949&v=W5XNOmyJr6I,30949,screencapture-localhost-8000-2022-01-31-13_18_54.png,,other: another git push of model_building,,
929,2,https://www.youtube.com/watch?t=30968&v=W5XNOmyJr6I,30968,screencapture-localhost-8000-2022-01-31-13_19_36.png,,goal: let's get more data.,,
930,2,https://www.youtube.com/watch?t=31019&v=W5XNOmyJr6I,31019,screencapture-localhost-8000-2022-01-31-13_20_45.png,,other: downloading zip file he has previously made of the food101 foods,,
931,2,https://www.youtube.com/watch?t=31055&v=W5XNOmyJr6I,31055,,,code: small_model_building; import tensorflow,,675;226;421;130
932,2,https://www.youtube.com/watch?t=31103&v=W5XNOmyJr6I,31103,screencapture-localhost-8000-2022-01-31-13_23_43.png,,code: small_model_building; a bunch of tensorflow lite model maker imports,"import os

import numpy as np

import tensorflow as tf
assert tf.__version__.startswith('2""')

from tflite_model_maker import model spec
from tflite_model_maker import image classifier
from tflite_model_maker.config import ExportFormat
from tflite_model_maker.config import QuantizationConfig
from tflite_model_maker.image_classifier import Dataloader
import matplotlib.pyplot as plt
",507;314;634;380
933,2,https://www.youtube.com/watch?t=31123&v=W5XNOmyJr6I,31123,screencapture-localhost-8000-2022-01-31-13_24_42.png,,"code: small_model_building; copying code from his previous project based on classifying types of food
","from tflite_model_maker.config import QuantizationConfig
from tflite_model_maker.image_classifier import Dataloader

import matplotlib.pyplot as plt

train_data_path = ""10_whole_foods/train""
test_data_path = ""10_whole_foods/test""

import os
class_names = sorted(os.listdir(train_data_path))
class_names
",504;208;640;392
934,2,https://www.youtube.com/watch?t=31139&v=W5XNOmyJr6I,31139,screencapture-localhost-8000-2022-01-31-13_25_51.png,,"code: small_model_building; replacing paths ""now this is some code I prepared earlier""","train_data_path = ""data/train""
test_data_path = ""data/test""

import os
class_names = sorted(os.listdir(train_data_path))
class_names
",510;241;538;178
935,2,https://www.youtube.com/watch?t=31171&v=W5XNOmyJr6I,31171,screencapture-localhost-8000-2022-01-31-13_27_03.png,,code: small_model_building; continuing to copy from previous project,"train_data = Dataloader.from_folder(train_data_path)
test_data = Dataloader.from_folder(test_data_path)

train_data, test_data

# Create model
model = image_classifier.create(train_data)

r='.', tflite_filename:""food_not_food_model_v2.tflite"")
",513;205;607;437
936,2,https://www.youtube.com/watch?t=31191&v=W5XNOmyJr6I,31191,screencapture-localhost-8000-2022-01-31-13_29_17.png,,code: small_model_building; copies in a last test case code snippet,"# Load image 
image = tf.keras.utils.load_img(""chicken_wings.jpeg"")
input_arr = tf.keras.utils.img_to_array(image)
input_arr = np.array([input_arr]) # Convert single image
input_arr = tf.image.resize(input_arr, size=(224, 224)) / 2
preds = model.predict_top_k(input_arr, k=5, batch_size=1)
preds[0]
",504;458;646;199
937,2,https://www.youtube.com/watch?t=31199&v=W5XNOmyJr6I,31199,,,code: small_model_building; change it to predict the top two class (there are only 2) instead of the top 5,,675;226;421;130
938,2,https://www.youtube.com/watch?t=31216&v=W5XNOmyJr6I,31216,screencapture-localhost-8000-2022-01-31-13_31_23.png,,"other: someone from chat says ""you could probably wrap it in a try and except""",,
939,2,https://www.youtube.com/watch?t=31216&v=W5XNOmyJr6I,31216,screencapture-localhost-8000-2022-01-31-13_31_23.png,,goal: try the try/except in the original code (implicit),,
940,2,https://www.youtube.com/watch?t=31259&v=W5XNOmyJr6I,31259,screencapture-localhost-8000-2022-01-31-13_33_07.png,,"other: chat ""Uint32 you reckon?""",,
941,2,https://www.youtube.com/watch?t=31262&v=W5XNOmyJr6I,31262,screencapture-localhost-8000-2022-01-31-13_33_39.png,,code: script.js; changes the cast from int32 to uint32,"      console.log(error);
   }   

   // // Prepare input tensors
   // const img = tf.browswer.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);

   // Run inference and get output tensors
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int 32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));
   image = tf.cast(image, 'int32');  // Model requires uint8
   const output = model.predict(image) ;
   // const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync() [0]); // arraySync Returns an array to use

   // Update HTML
   predicted_class.innerText = classes [output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""5"";
}",675;226;421;130
942,2,https://www.youtube.com/watch?t=31291&v=W5XNOmyJr6I,31291,screencapture-localhost-8000-2022-01-31-14_04_04.png,,"output: script error, but this one might be on the cast.",,
944,2,https://www.youtube.com/watch?t=31329&v=W5XNOmyJr6I,31329,screencapture-localhost-8000-2022-01-31-14_25_36.png,,output: script error -converting to uint,,
945,2,https://www.youtube.com/watch?t=31421&v=W5XNOmyJr6I,31421,screencapture-localhost-8000-2022-01-31-14_27_36.png,,"output: error with training the model; ""oh no we've run into a cuda error""",,
946,2,https://www.youtube.com/watch?t=31514&v=W5XNOmyJr6I,31514,screencapture-localhost-8000-2022-01-31-14_29_47.png,,visit: source code for previous model maker project; he's wondering if this one still works before trying to trouble shoot error in small_model_building,,
947,2,https://www.youtube.com/watch?t=31551&v=W5XNOmyJr6I,31551,screencapture-localhost-8000-2022-01-31-14_31_17.png,,code: prev_code; he updates the path from his old model maker project to get the food/not food data,"train_data_path = ""food-not-food/data/train""
test_data_path = ""food-not-food/data/train""

import os
class_names = sorted(os.listdir(train_data_path))
class_names
",519;362;535;178
948,2,https://www.youtube.com/watch?t=31578&v=W5XNOmyJr6I,31578,screencapture-localhost-8000-2022-01-31-14_33_22.png,,output: training a model with tensorflow lite model maker,,
949,2,https://www.youtube.com/watch?t=31578&v=W5XNOmyJr6I,31578,screencapture-localhost-8000-2022-01-31-14_33_22.png,,goal: now we're going to build a bigger dataset,,
950,2,https://www.youtube.com/watch?t=31897&v=W5XNOmyJr6I,31897,screencapture-localhost-8000-2022-01-31-14_42_29.png,,"goal: ""let's get another 20K data points""",,
951,2,https://www.youtube.com/watch?t=31921&v=W5XNOmyJr6I,31921,screencapture-localhost-8000-2022-01-31-14_43_22.png,,code: prev_code; saving modelmaker file as food not food v2,"# Save the model
model.export(export_dir='.', tflite_filename=""food_not_food_model_v2.tflite"")
",513;341;838;79
952,2,https://www.youtube.com/watch?t=32001&v=W5XNOmyJr6I,32001,screencapture-localhost-8000-2022-01-31-14_45_16.png,,goal: balancing the datasets; has created a new code file in order to select 20-30K of the food101 images.,,
953,2,https://www.youtube.com/watch?t=32036&v=W5XNOmyJr6I,32036,screencapture-localhost-8000-2022-01-31-14_46_29.png,,goal: get list of food 101 images,,
954,2,https://www.youtube.com/watch?t=32066&v=W5XNOmyJr6I,32066,screencapture-localhost-8000-2022-01-31-14_53_16.png,,code: prev_code; changing util to preprocessing for load_img,"# Load image
image = tf.keras.preprocessing.load_img(""chicken_wings.jpeg"")
input_arr = tf.keras.preprocessing.img_to_array(image)
input_arr = np.array([input_arr]) # Convert single image to a batch.
input_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels
preds = model.predict_top_k(input_arr, k=5, batch_size=1)
preds[0]
",513;247;868;199
955,2,https://www.youtube.com/watch?t=32078&v=W5XNOmyJr6I,32078,screencapture-localhost-8000-2022-01-31-14_54_08.png,,output: there's no load_image in preprocessing either.,,
956,2,https://www.youtube.com/watch?t=32110&v=W5XNOmyJr6I,32110,screencapture-localhost-8000-2022-01-31-14_56_07.png,,code: prev_code; adding .image to the keras path,"# Load image
image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")
input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr]) # Conv
input_arr = tf.image.resize(input_arr, si
preds = model.predict_top_k(input_arr, k=
preds[0]
",516;470;748;208
957,2,https://www.youtube.com/watch?t=32131&v=W5XNOmyJr6I,32131,screencapture-localhost-8000-2022-01-31-14_56_59.png,,code: prev_code; changing predict top 5 to predict top 2,"image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")
input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr]) # Convert single image to a batch.
input_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels
preds = model.predict_top_k(input_arr, k=2, batch_size=1)
preds [0]

dict([(k, float(v)) for k, v in dict(preds[0]).items()])
",513;202;871;341
958,2,https://www.youtube.com/watch?t=32150&v=W5XNOmyJr6I,32150,screencapture-localhost-8000-2022-01-31-14_57_49.png,,"output: it predicted non-food image more than food image; ""that's not good""",,
959,2,https://www.youtube.com/watch?t=32351&v=W5XNOmyJr6I,32351,screencapture-localhost-8000-2022-01-31-15_01_38.png,,code: add_more_food_images; walking extracted food 101 images to get the list of class names,"import os
food_image_paths = []
for dir, sub_dir, files os.walk(""101_food_classes_all_data""):
   for file in files:
      food_image_paths.append(os.path.join(dir, file))
food_image_paths
",516;353;679;172
960,2,https://www.youtube.com/watch?t=32359&v=W5XNOmyJr6I,32359,screencapture-localhost-8000-2022-01-31-15_02_35.png,,output: now we have a big long list of files,,
961,2,https://www.youtube.com/watch?t=32373&v=W5XNOmyJr6I,32373,screencapture-localhost-8000-2022-01-31-15_03_20.png,,output: > 100K images,,
962,2,https://www.youtube.com/watch?t=32402&v=W5XNOmyJr6I,32402,screencapture-localhost-8000-2022-01-31-15_04_25.png,,output: DSStore is not in the image list,,
963,2,https://www.youtube.com/watch?t=32422&v=W5XNOmyJr6I,32422,screencapture-localhost-8000-2022-01-31-15_05_12.png,,output: training data does have a .DSStore,,
964,2,https://www.youtube.com/watch?t=32422&v=W5XNOmyJr6I,32422,screencapture-localhost-8000-2022-02-01-09_53_24.png,,output: testing data also has .DSstore,,
965,2,https://www.youtube.com/watch?t=32536&v=W5XNOmyJr6I,32536,screencapture-localhost-8000-2022-02-01-09_56_25.png,,code: add_more_food_images; removing train .DSstore,"food_image_paths.remove(""101_food_classes_all_data/train/.DS_Store"")

""101_food_classes_all_data/train/.DS_Store"" in food_image_paths
",528;202;721;175
966,2,https://www.youtube.com/watch?t=32542&v=W5XNOmyJr6I,32542,screencapture-localhost-8000-2022-02-01-09_57_21.png,,"goal: ""food image paths - let's get a random 10K""",,
967,2,https://www.youtube.com/watch?t=32614&v=W5XNOmyJr6I,32614,screencapture-localhost-8000-2022-02-01-09_59_01.png,,code: add_more_food_images; has a list of 30K random food images from the training data. has done 30K to create a balanced training set.,"# Get random 30000 images
import random
random.seed(42)
random_30k_food_image_paths = random.sample(food_image_paths, k=30000)
len(random_30k_food_image_paths)
",510;272;793;142
968,2,https://www.youtube.com/watch?t=32631&v=W5XNOmyJr6I,32631,screencapture-localhost-8000-2022-02-01-10_00_23.png,,goal: what did we get for the length of the datasets? let's open up modelbuilder,,
969,2,https://www.youtube.com/watch?t=32655&v=W5XNOmyJr6I,32655,screencapture-localhost-8000-2022-02-01-10_01_18.png,,output: 41K non-food images; adjusting goal to 38K,,
970,2,https://www.youtube.com/watch?t=32664&v=W5XNOmyJr6I,32664,screencapture-localhost-8000-2022-02-01-10_03_13.png,,code: add_more_food_images; adjusted to get list of 38K to balance 41K non-food,"# Get random 30000 images
import random
random.seed(42)
random_38k_food_image_paths = random.sample(food_image_paths, k=38000)
len(random_38k_food_image_paths)
",513;257;775;157
971,2,https://www.youtube.com/watch?t=32683&v=W5XNOmyJr6I,32683,screencapture-localhost-8000-2022-02-01-10_04_15.png,,"goal: ""create train and test sets of images""",,
972,2,https://www.youtube.com/watch?t=32731&v=W5XNOmyJr6I,32731,screencapture-localhost-8000-2022-02-01-10_05_35.png,,"other: ""I need to clean up this code. Don't worry I'll clean it up after the stream""",,
973,2,https://www.youtube.com/watch?t=32741&v=W5XNOmyJr6I,32741,screencapture-localhost-8000-2022-02-01-10_06_45.png,,code: add_more_food_images; creating a test and train set for the 38K additional food images.,"def create_train_test_list(image_list):
   random.seed(42)
   # image_list = [os.path.join(target_dir, img_path) for img_path in os.li
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list))
   return train_image_list, test_im 

train_image_list, test_image_list = create_train_test_list(random_38k_food_i
len(train_image_list), len(test_image_list)
",159;389;817;275
974,2,https://www.youtube.com/watch?t=32743&v=W5XNOmyJr6I,32743,screencapture-localhost-8000-2022-02-01-10_08_49.png,,output: size of additional training test sets for food images,,
976,2,https://www.youtube.com/watch?t=32800&v=W5XNOmyJr6I,32800,screencapture-localhost-8000-2022-02-01-10_11_31.png,,code: add_more_food_images; a more complete view of image copying code,"image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")
input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr]) # Convert single image to a batch.
input_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels
preds = model.predict_top_k(input_arr, k=2, batch_size=1)
preds[0]

dict([(k, float(v)) for k, v in dict(preds[0]).items()])
",156;263;811;431
977,2,https://www.youtube.com/watch?t=32809&v=W5XNOmyJr6I,32809,screencapture-localhost-8000-2022-02-01-10_12_37.png,,code: add_more_food_images; commenting out actual copy to test directories,"# Training images
def copy_images_to_file(image_list, target_dir):
   # target_dir = ""data/train/food_images/""
   os.makedirs(target_dir, exist_ok=True)
   for image_path in image_list:
      image_filename = os.path.split(image_path)[-1]
      # print(image_filename)
      dest_path = os.path.join(target_dir, image_filename)
      print(f""Copying {image_path} to {dest_path}"")
      # copy2(image_path, dest_path)

print(test_images)
copy_images_to_file(image_list=train_images, target_dir=""data/train/food_im
copy_images_to_file(image_list=test_images, target_dir=""data/test/food_imag
",156;226;817;395
978,2,https://www.youtube.com/watch?t=32815&v=W5XNOmyJr6I,32815,screencapture-localhost-8000-2022-02-01-10_19_20.png,,output: image dirs look ok,,
979,2,https://www.youtube.com/watch?t=32825&v=W5XNOmyJr6I,32825,screencapture-localhost-8000-2022-02-01-10_21_12.png,,code: add_more_food_images; bringing the copy statement back,"train_images, test_images = create_train_test_list(random_38k_food_image_pa
# Training images
def copy_images_to_file(image_list, target_dir):
   # target_dir = ""data/train/food_images/""
   os.makedirs(target_dir, exist_ok=True)
   for image_path in image_list:
      image_filename = os.path.split(image_path)[-1]
      # print(image_filename)
      dest_path = os.path.join(target_dir, image_filename)
      print(f""Copying {image_path} to {dest_path}"")
      copy2(|image_path, dest_path])]

# print(test_images)
copy_images_to_file(image_list=train_images, target_dir=""data/train/food_ima
",162;299;817;410
981,2,https://www.youtube.com/watch?t=32838&v=W5XNOmyJr6I,32838,screencapture-localhost-8000-2022-02-01-10_22_17.png,,output: copy3 doesn't exist.,"from shutil import copy3
train_images, test_images = create_train_test_list(random_38k_food_image_pat

# Training images
def copy_images_to_file(image_list, target_dir):
   # target_dir = ""data/train/food_images/""
   os.makedirs(target_dir, exist_ok=True)
   for image_path in image_list:
      image_filename = os.path.split(image_path)[-1]
      # print(image_filename)
      dest_path = os.path.join(target_dir, image_filename)
      print(f""Copying {image_path} to {dest_path}"")
      copy2(image_path, dest_path)

# print(test_images)
",165;302;805;401
982,2,https://www.youtube.com/watch?t=32844&v=W5XNOmyJr6I,32844,screencapture-localhost-8000-2022-02-01-10_23_30.png,,code: add_more_food_images; change copy3 to copy2 - copy3 oops.,"from shutil import copy2
train_images, test_image

# Training images
def copy_images_to_file(image_list, target_dir):
   # target_dir = ""data/train/food_images/""
   os.makedirs(target_dir, exist_ok=True)
   for image_path in image_list:
      image_filename = os.path.split(image_path)[-1]
      # print(image_filename)
      dest_path = os.path.join(target_dir, image_filename)
      print(f""Copying {image_path} to {dest_path}"")
      copy2(image_path, dest_path)
",159;347;652;359
983,2,https://www.youtube.com/watch?t=32852&v=W5XNOmyJr6I,32852,screencapture-localhost-8000-2022-02-01-10_24_11.png,,output: images copying,,
984,2,https://www.youtube.com/watch?t=32861&v=W5XNOmyJr6I,32861,screencapture-localhost-8000-2022-02-01-10_24_36.png,,goal: we can now build another model,,
985,2,https://www.youtube.com/watch?t=32928&v=W5XNOmyJr6I,32928,screencapture-localhost-8000-2022-02-01-10_26_08.png,,output: now have more training and testing data,"len(train_data), len(test_data)

# Create model
tf.get_logger().setLevel('INFO')
model = image_classifier.create(train_data)
",159;317;493;275
986,2,https://www.youtube.com/watch?t=32928&v=W5XNOmyJr6I,32928,screencapture-localhost-8000-2022-02-01-10_26_38.png,,code: add_more_food_images; gets test path wrong,"train_data_path = ""food—not—food/data/train""
test_data_path = ""food-not-food/data/train""

import os
class_names = sorted(os.listdir(train_data_path))
class_names

# Create data loader
train_data = Dataloader.from_folder(train_data_path)
test_data = Dataloader.from_folder(test_data_path)
",162;299;577;407
988,2,https://www.youtube.com/watch?t=32937&v=W5XNOmyJr6I,32937,screencapture-localhost-8000-2022-02-01-10_28_02.png,,goal: we've got nearly 100K images of food and not food images now. let's train a model,,
989,2,https://www.youtube.com/watch?t=32957&v=W5XNOmyJr6I,32957,screencapture-localhost-8000-2022-02-01-10_29_08.png,,code: prev_code; change version of model to 3,"# Evaluate the model
loss, accuracy = model.evaluate(test_data)

# Save the model
model.export(export_dir=""."", tflite_filename=""food_not_food_model_v3.tflite""
",159;196;829;263
990,2,https://www.youtube.com/watch?t=33055&v=W5XNOmyJr6I,33055,screencapture-localhost-8000-2022-02-01-10_45_15.png,,other: copying second model to the google bucket space.,,
991,2,https://www.youtube.com/watch?t=33108&v=W5XNOmyJr6I,33108,screencapture-localhost-8000-2022-02-01-10_57_52.png,,other: setting the permissions for the v2 model,,
992,2,https://www.youtube.com/watch?t=33160&v=W5XNOmyJr6I,33160,screencapture-localhost-8000-2022-02-01-10_59_17.png,,other: upload v2 of the model to replit.,,
993,2,https://www.youtube.com/watch?t=33183&v=W5XNOmyJr6I,33183,screencapture-localhost-8000-2022-02-01-11_00_03.png,,goal: we're going to try again on making a prediction via replit and javascript using the v2 model,,
994,2,https://www.youtube.com/watch?t=33188&v=W5XNOmyJr6I,33188,screencapture-localhost-8000-2022-02-01-11_01_00.png,,code: script.js; replacing v1 model with v2,"   try {
         const tfliteModel = await tflite.loadTFLiteModel();
         //
         https://storage.googleapis.com/food-vision-model-playground/food_not_food_mod
         el_v1.tflite
         // ""/food_not_food_model_v1.tflite""
         ""/food_not_food_model_v2.tflite""
         // ""/10_whole_foods_model_v0.tflite""
      }; 
      model = tfliteModel; // assigning it to the global scale model as tfliteModel
      can only be used within this scope
      // console.log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }  

   // // Prepare input tensors
   // const img = tf.browswer.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);

   // Run inference and get output tensors
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);",675;226;421;130
995,2,https://www.youtube.com/watch?t=33205&v=W5XNOmyJr6I,33205,screencapture-localhost-8000-2022-02-01-11_01_49.png,,output: same script error; whew,"SR,
16 const tfliteModel = await tflite.loadTFLiteModel(
mt 17 /7
le_foods_model_v0.tiite https://storage.googleapis. com/food-vision-nodel-playground/
elvi.tflite
it food’ model v1:tite 18 // ""/food_not_food_model vi.tflite""
t_food_model_v2.tite 19 ""/food_not_food_model_v2. tflite""
20 // ""/10_vhole_foods_model_vd. tflite""
B
3 2 model = tfliteModel; // assigning it to the global scope model
can only be used within this scope
23 // console.log(tfliteModel);
24
25 // Check if model loaded
2 if (tfliteModel) {
27 model_status.innerText = “Model loaded"";
28 ¥
29} catch (error) {
30 console. log(error);
31}
32
",156;263;811;431
996,2,https://www.youtube.com/watch?t=33213&v=W5XNOmyJr6I,33213,screencapture-localhost-8000-2022-02-01-11_02_33.png,,code: script.js; changing uint32 back to int32,"   // // Prepare input tensors
   // const img = tf.browswer.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);

   // Run inference and get output tensors
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   // const output_values = tf.softmax(output.arraySync()(0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

",675;226;421;130
997,2,https://www.youtube.com/watch?t=33228&v=W5XNOmyJr6I,33228,screencapture-localhost-8000-2022-02-01-11_06_32.png,,output: error - output values is not defined (currently commented out),,
998,2,https://www.youtube.com/watch?t=33240&v=W5XNOmyJr6I,33240,screencapture-localhost-8000-2022-02-01-11_07_19.png,,code: script.js; uncommenting output_values,"   // Run inference and get output tensors
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()(0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
",675;226;421;130
999,2,https://www.youtube.com/watch?t=33253&v=W5XNOmyJr6I,33253,screencapture-localhost-8000-2022-02-01-11_07_59.png,,output: truck is predicted as food with 100% probability. Hmm.,,
1000,2,https://www.youtube.com/watch?t=33262&v=W5XNOmyJr6I,33262,screencapture-localhost-8000-2022-02-01-11_09_26.png,,other: prediction; I think our classes are back to front.,,
1001,2,https://www.youtube.com/watch?t=33286&v=W5XNOmyJr6I,33286,screencapture-localhost-8000-2022-02-01-11_10_17.png,,output: georgia's food is also predicted as food with 100%,,
1002,2,https://www.youtube.com/watch?t=33294&v=W5XNOmyJr6I,33294,screencapture-localhost-8000-2022-02-01-11_11_11.png,,code: script.js; change output prediction to sigmoid rather than softmax,"// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()(0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      When reader is ready display image
      reader.onload = function (event) {",675;226;421;130
1003,2,https://www.youtube.com/watch?t=33299&v=W5XNOmyJr6I,33299,screencapture-localhost-8000-2022-02-01-11_11_57.png,,search: tensorflow.js sigmoid;,,
1004,2,https://www.youtube.com/watch?t=33307&v=W5XNOmyJr6I,33307,screencapture-localhost-8000-2022-02-01-11_12_55.png,,visit: tensors/creation;,,
1005,2,https://www.youtube.com/watch?t=33359&v=W5XNOmyJr6I,33359,screencapture-localhost-8000-2022-02-01-11_14_10.png,,"output: after change to sigmoid, georgia's good is predicted as undefined with 100% probability",,
1006,2,https://www.youtube.com/watch?t=33371&v=W5XNOmyJr6I,33371,screencapture-localhost-8000-2022-02-01-11_26_02.png,,code: script.js; logging output values.arraysync,"// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.sigmoid(output.arraySync()(0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      When reader is ready display image
      reader.onload = function (event) {",675;226;421;130
1007,2,https://www.youtube.com/watch?t=33402&v=W5XNOmyJr6I,33402,screencapture-localhost-8000-2022-02-01-11_27_01.png,,output: truck still seen as good 99% maybe,,
1008,2,https://www.youtube.com/watch?t=33419&v=W5XNOmyJr6I,33419,screencapture-localhost-8000-2022-02-01-11_27_47.png,,output: georgia's good is still predicted as undefined.,,
1009,2,https://www.youtube.com/watch?t=33496&v=W5XNOmyJr6I,33496,screencapture-localhost-8000-2022-02-01-11_30_09.png,,code: script.js; adding argmax into output values log,"   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.sigmoid(output.arraySync()(0]);
   console.log(output_values..argMax().arraySync());
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      When reader is ready display image
      reader.onload = function (event) {
         // Get data URL
         const dataUrl = event.target.result;

         // Create image object
         const imageElement = new Image();
         imageElement.src = dataUrl;",675;226;421;130
1010,2,https://www.youtube.com/watch?t=33499&v=W5XNOmyJr6I,33499,screencapture-localhost-8000-2022-02-01-11_30_42.png,,code: script.js; removing extra .,"   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.sigmoid(output.arraySync()(0]);
   console.log(output_values.argMax().arraySync());
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      When reader is ready display image
      reader.onload = function (event) {
         // Get data URL
         const dataUrl = event.target.result;

         // Create image object
         const imageElement = new Image();
         imageElement.src = dataUrl;",675;226;421;130
1012,2,https://www.youtube.com/watch?t=33513&v=W5XNOmyJr6I,33513,screencapture-localhost-8000-2022-02-01-11_32_05.png,,output; truck still food,,
1013,2,https://www.youtube.com/watch?t=33539&v=W5XNOmyJr6I,33539,screencapture-localhost-8000-2022-02-01-11_32_53.png,,goal: let's save v3 of the model - see if it works better,,
1014,2,https://www.youtube.com/watch?t=33594&v=W5XNOmyJr6I,33594,screencapture-localhost-8000-2022-02-01-11_34_12.png,,code: script.js; labelling outputs - one with typo,"// Function to classify image
function classifyImage(model, image) {
   // Preprocess iamge
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.sigmoid(output.arraySync()(0]);
   console.log(""Arg max:"")
   console.log(output_values.argMax().arraySync());
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();
",675;226;421;130
1015,2,https://www.youtube.com/watch?t=33603&v=W5XNOmyJr6I,33603,screencapture-localhost-8000-2022-02-01-11_34_59.png,,output: error - console.long is not a function,,
1016,2,https://www.youtube.com/watch?t=33608&v=W5XNOmyJr6I,33608,screencapture-localhost-8000-2022-02-01-11_35_27.png,,code: script.js; fixed typo,"// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as
   output thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFliteType(""uint8""));
   image = tf.cast(image, ""int32"");  // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   // const output_values = tf.sigmoid(output.arraySync()[0]);
   console.log(""Arg max:"")
   console.log(output.argMax().arraySync());
   console.log(""Output:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if(fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

   // Get the data url from the image
   const reader = new FileReader();",399;250;715;817
1017,2,https://www.youtube.com/watch?t=33642&v=W5XNOmyJr6I,33642,screencapture-localhost-8000-2022-02-01-11_36_29.png,,output: georgia's food is still undefined.,,
1019,2,https://www.youtube.com/watch?t=33656&v=W5XNOmyJr6I,33656,screencapture-localhost-8000-2022-02-01-11_56_09.png,,goal: we want the argmax of zero,,
1020,2,https://www.youtube.com/watch?t=33666&v=W5XNOmyJr6I,33666,screencapture-localhost-8000-2022-02-01-11_57_30.png,,code: script.js; output.arraySync.argMax,"// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.sigmoid(output.arraySync()(0]);
   console.log(""Arg max:"")
   console.log(output_values.argMax().arraySync());
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();",675;226;421;130
1021,2,https://www.youtube.com/watch?t=33677&v=W5XNOmyJr6I,33677,screencapture-localhost-8000-2022-02-01-11_58_23.png,,output: error - can't call argmax on arraysync; I'm not sure if he knows what he's doing at this point or is just trying different combinations of methods that are often involved in the solution,,
1023,2,https://www.youtube.com/watch?t=33710&v=W5XNOmyJr6I,33710,screencapture-localhost-8000-2022-02-01-12_01_33.png,,code: script.js; removing the sigmoid call,"   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.sigmoid(output.arraySync()(0]);
   console.log(""Arg max:"")
   console.log(output_values.argMax().arraySync());
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
         // Get data URL
         const dataURL = event.target.result;

         // Create image object",675;226;421;130
1024,2,https://www.youtube.com/watch?t=33723&v=W5XNOmyJr6I,33723,screencapture-localhost-8000-2022-02-01-12_02_16.png,,code: script.js; back to printing output_values.argmax,"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = output.arraySync()[0];
   console.log(""Arg max:"")
   console.log(output_values.argMax());
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
         // Get data URL
 ",675;226;421;130
1025,2,https://www.youtube.com/watch?t=33741&v=W5XNOmyJr6I,33741,screencapture-localhost-8000-2022-02-01-12_03_05.png,,output: error- output_values.argmax has type error,,
1026,2,https://www.youtube.com/watch?t=33757&v=W5XNOmyJr6I,33757,screencapture-localhost-8000-2022-02-01-12_04_07.png,,code: script.js; output_values.argmax to outputvalues in print,"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = output.arraySync()[0];
   console.log(""Arg max:"")
   console.log(output_values);
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
         // Get data URL
 ",675;226;421;130
1027,2,https://www.youtube.com/watch?t=33784&v=W5XNOmyJr6I,33784,screencapture-localhost-8000-2022-02-01-12_05_13.png,,output: error calling argmax on output values (later in the code),,
1028,2,https://www.youtube.com/watch?t=33784&v=W5XNOmyJr6I,33784,screencapture-localhost-8000-2022-02-01-12_05_13.png,,goal: how do I get the argmax; singing,,
1029,2,https://www.youtube.com/watch?t=33795&v=W5XNOmyJr6I,33795,screencapture-localhost-8000-2022-02-01-12_07_02.png,,search: tensorflow js argmax;,,
1030,2,https://www.youtube.com/watch?t=33806&v=W5XNOmyJr6I,33806,screencapture-localhost-8000-2022-02-01-12_07_36.png,,goal: let's upload image model 3 while we're here.,"image = tf.keras.preprocessing.image.load_img(""chicken_wings.jpeg"")
input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr]) # Convert single image to a batch.
input_arr = tf.image.resize(input_arr, size=(224, 224)) / 255. # normalize pixels
preds = model.predict_top_k(input_arr, k=2, batch_size=1)
preds[0]
",165;205;883;163
1031,2,https://www.youtube.com/watch?t=33820&v=W5XNOmyJr6I,33820,screencapture-localhost-8000-2022-02-01-12_08_16.png,,output; from the trained model 3 - chicken wings test case gives the correct output.,,
1032,2,https://www.youtube.com/watch?t=33827&v=W5XNOmyJr6I,33827,screencapture-localhost-8000-2022-02-01-12_09_03.png,,other: uploading model v3 to the google bucket,,
1033,2,https://www.youtube.com/watch?t=33851&v=W5XNOmyJr6I,33851,screencapture-localhost-8000-2022-02-01-12_09_52.png,,code: script.js; tf.argmax(output array sync),"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.argmax(output.arraySync()[0]);
   console.log(""Arg max:"")
   console.log(output_values);
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
         // Get data URL
 ",675;226;421;130
1034,2,https://www.youtube.com/watch?t=33861&v=W5XNOmyJr6I,33861,screencapture-localhost-8000-2022-02-01-12_53_14.png,,output: error tf.argmax is not a function (argMax however...),,
1035,2,https://www.youtube.com/watch?t=33884&v=W5XNOmyJr6I,33884,screencapture-localhost-8000-2022-02-01-12_54_19.png,,code: script.js; output_values-> output in the log again,"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.argmax(output);
   console.log(""Arg max:"")
   console.log(output_values);
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
         // Get data URL
 ",675;226;421;130
1036,2,https://www.youtube.com/watch?t=33894&v=W5XNOmyJr6I,33894,screencapture-localhost-8000-2022-02-01-12_55_14.png,,output: error argmax is still not a function,,
1037,2,https://www.youtube.com/watch?t=33901&v=W5XNOmyJr6I,33901,screencapture-localhost-8000-2022-02-01-12_55_56.png,,"revisit: Tensors/Creation; ""Oh it's tf argMax""",,
1038,2,https://www.youtube.com/watch?t=33911&v=W5XNOmyJr6I,33911,screencapture-localhost-8000-2022-02-01-12_56_34.png,,code: script.js; fixes capitalization of argMax,"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.argMax(output);
   console.log(""Arg max:"")
   console.log(output_values);
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
         // Get data URL
 ",675;226;421;130
1039,2,https://www.youtube.com/watch?t=33917&v=W5XNOmyJr6I,33917,screencapture-localhost-8000-2022-02-01-12_57_03.png,,code: script.js; tf.argMax(output.arraySync[0]),"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.argMax(output.arraySync()[0]);
   console.log(""Arg max:"")
   console.log(output_values);
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
         // Get data URL",675;226;421;130
1040,2,https://www.youtube.com/watch?t=33934&v=W5XNOmyJr6I,33934,screencapture-localhost-8000-2022-02-01-12_57_57.png,,output: error - script error,,
1041,2,https://www.youtube.com/watch?t=33968&v=W5XNOmyJr6I,33968,screencapture-localhost-8000-2022-02-01-13_59_38.png,,other: updating permissions for uploaded model v3,,
1042,2,https://www.youtube.com/watch?t=34118&v=W5XNOmyJr6I,34118,screencapture-localhost-8000-2022-02-01-14_02_40.png,,code: script.js; argMax(output[0]),"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.argMax(output[0]);
   console.log(""Arg max:"")
   console.log(output_values);
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
         // Get data URL",675;226;421;130
1043,2,https://www.youtube.com/watch?t=34134&v=W5XNOmyJr6I,34134,screencapture-localhost-8000-2022-02-01-14_03_41.png,,output: error - script error,,
1044,2,https://www.youtube.com/watch?t=34159&v=W5XNOmyJr6I,34159,screencapture-localhost-8000-2022-02-01-14_04_30.png,,code: script.js; remove output_values entirely,"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   // const output_values = tf.argMax(output);
   console.log(""Arg max:"")
   // console.log(output_values);
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
        ",675;226;421;130
1045,2,https://www.youtube.com/watch?t=34176&v=W5XNOmyJr6I,34176,screencapture-localhost-8000-2022-02-01-14_05_24.png,,output; error - output values not defined,,
1046,2,https://www.youtube.com/watch?t=34205&v=W5XNOmyJr6I,34205,screencapture-localhost-8000-2022-02-01-14_06_33.png,,output: error - output values not defined; same code as prev run,,
1047,2,https://www.youtube.com/watch?t=34232&v=W5XNOmyJr6I,34232,screencapture-localhost-8000-2022-02-01-14_07_45.png,,goal: now I want to get the argMax of this,,
1048,2,https://www.youtube.com/watch?t=34273&v=W5XNOmyJr6I,34273,screencapture-localhost-8000-2022-02-01-14_09_24.png,,visit: 10 food classes previous project; he's looking at how he's getting the prediction from his old code,,
1049,2,https://www.youtube.com/watch?t=34354&v=W5XNOmyJr6I,34354,screencapture-localhost-8000-2022-02-01-14_11_21.png,,code: script.js; has put argmax with arraysync back in and commented out the html update parts at the end.,"   same as model inputs
   image = tf.expandDims(image)
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output 
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""Converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.argMax(output.arraySync()[0]);
   console.log(""Arg max:"")
   console.log(output);
   console.log(output_values);
   console.log(""Outputs:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use 

   // Update HTML
   // predicted_class.innerText = classes[output_values.argMax().arraySync()];
   // predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

   // Image uploading
   const fileInput = document.getElementById(""file-input"");
   const image = document.getElementById(""image"");

   function getImage() {
      if (!fileInput.files[0]) throw new Error(""Image not found"");
      const file = fileInput.files[0];

      // Get the data url from the image
      const reader = new FileReader();

      // When reader is ready display image
      reader.onload = function (event) {
",675;226;421;130
1050,2,https://www.youtube.com/watch?t=34373&v=W5XNOmyJr6I,34373,screencapture-localhost-8000-2022-02-01-14_12_25.png,,output: doesn't seem to have an error this time?,,
1051,2,https://www.youtube.com/watch?t=34394&v=W5XNOmyJr6I,34394,screencapture-localhost-8000-2022-02-01-14_13_16.png,,code: script.js; adds another arraySync at the end of the output values line,"same as model inputs
image = tf.expandins(image)
console. log(image) ;
// console. log(model);

// console. log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as ou
thus we cast int32 in below line
// console.log(tflite.getDTypeFromTFLiteType(""uint8""));
console.log(""converting image to different datatype..."");
image = tf.cast(image, ""int32""); // Model requires uint8
console.log(""model about to predict..."");
const output = model.predict(image);
const output_values = tf.argMax(output.arraySync()[0]).arraySync();
console.log(Arg max:"")
console.log(output);
console.log(output_values);
console.log(""Output:"")
console.log(output.arraySync());
console.log(output.arraySync()[0]); // arraySync() Returns an array to use

// Update HTML
// predicted_class.innerText = classes[output_values.argMax().arraySync()];
// predicted_prob.innerText = output_values.max().arraySync() % 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if (fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

   // Get the data url from the image
   const reader = new FileReader();

   //when reader is ready display image
   reader.onload = function (event) {
",414;257;652;814
1053,2,https://www.youtube.com/watch?t=34433&v=W5XNOmyJr6I,34433,screencapture-localhost-8000-2022-02-01-14_16_51.png,,output: I think this is saying not food,,
1054,2,https://www.youtube.com/watch?t=34448&v=W5XNOmyJr6I,34448,screencapture-localhost-8000-2022-02-01-14_17_37.png,,output: I think this is also saying not food.,,
1055,2,https://www.youtube.com/watch?t=34466&v=W5XNOmyJr6I,34466,screencapture-localhost-8000-2022-02-01-14_18_18.png,,goal: so now let's add the final model,,
1056,2,https://www.youtube.com/watch?t=34495&v=W5XNOmyJr6I,34495,screencapture-localhost-8000-2022-02-01-14_19_08.png,,output: final model predicts truck not food.,,
1057,2,https://www.youtube.com/watch?t=34535&v=W5XNOmyJr6I,34535,screencapture-localhost-8000-2022-02-01-14_20_09.png,,goal: I need to sigmoid this probably actually,,
1058,2,https://www.youtube.com/watch?t=34555&v=W5XNOmyJr6I,34555,screencapture-localhost-8000-2022-02-01-14_20_53.png,,output: food predicts food! also an error with max in the final html line,,
1059,2,https://www.youtube.com/watch?t=34570&v=W5XNOmyJr6I,34570,screencapture-localhost-8000-2022-02-01-14_22_13.png,,goal: ok let's get the probability,,
1060,2,https://www.youtube.com/watch?t=34618&v=W5XNOmyJr6I,34618,screencapture-localhost-8000-2022-02-01-14_23_20.png,,code: script.js; tweaking output values again,"   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image) ;
   // console. log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output
   thus we cast int32 in below line
   // console. log(tflite.getDTypeFromTFLiteType(""uints""));
   console.log(""converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(""Arg max:"")
   // console.log(output);
   console.log(output_values);
   console.log(""Output:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]1); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax.arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementByTd(""file-input"");
const image = document.getElementByTd(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

   // Get the data url from the image
   const reader = new FileReader();
",387;244;721;793
1061,2,https://www.youtube.com/watch?t=34632&v=W5XNOmyJr6I,34632,screencapture-localhost-8000-2022-02-01-14_23_59.png,,output: error; output_values.argMax is not a thing. still,,
1062,2,https://www.youtube.com/watch?t=34651&v=W5XNOmyJr6I,34651,screencapture-localhost-8000-2022-02-01-14_24_56.png,,code: script.js; added () after argMax,"   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image) ;
   // console.log(model);

   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));
   console. log(""converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(""Arg max:"")
   // console.log(output);
   console.log(output_values);
   console.log(""Output:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes [output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementByTd(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[e];

   // Get the data url from the image
   const reader = new FileReader();
",387;266;721;767
1063,2,https://www.youtube.com/watch?t=34659&v=W5XNOmyJr6I,34659,screencapture-localhost-8000-2022-02-01-14_25_42.png,,output: truck not food; html correctly updated.,,
1064,2,https://www.youtube.com/watch?t=34675&v=W5XNOmyJr6I,34675,screencapture-localhost-8000-2022-02-01-14_26_21.png,,"output: food is food, html still correct",,
1065,2,https://www.youtube.com/watch?t=34705&v=W5XNOmyJr6I,34705,screencapture-localhost-8000-2022-02-01-14_27_21.png,,goal: ok can we get this hosted?,,
1066,2,https://www.youtube.com/watch?t=34707&v=W5XNOmyJr6I,34707,screencapture-localhost-8000-2022-02-01-14_27_21.png,,goal: let's set the cors policy for the bucket,,
1067,2,https://www.youtube.com/watch?t=34782&v=W5XNOmyJr6I,34782,screencapture-localhost-8000-2022-02-01-14_29_17.png,,goal: I need to figure out where twitch ml deploy is,,
1068,2,https://www.youtube.com/watch?t=34810&v=W5XNOmyJr6I,34810,screencapture-localhost-8000-2022-02-01-14_30_08.png,,other: creating cors-config.json file,,
1069,2,https://www.youtube.com/watch?t=34849&v=W5XNOmyJr6I,34849,screencapture-localhost-8000-2022-02-01-14_59_58.png,,code: cors-config; we're going to make this available everywhere for an hour.,"[
   {
      ""origin"": [
         ""*""
      ],
      ""responseHeader"": [
         ""*"",
      ],
      ""method"": [
         ""GET"",
         ""POST"",
         ""HEAD""
      ],
      ""maxAgeSeconds"": 3600
   }
]

",147;155;370;431
1071,2,https://www.youtube.com/watch?t=34900&v=W5XNOmyJr6I,34900,screencapture-localhost-8000-2022-02-01-15_01_47.png,,output: seems to write into html correctly,,
1072,2,https://www.youtube.com/watch?t=34926&v=W5XNOmyJr6I,34926,screencapture-localhost-8000-2022-02-01-15_02_37.png,,code: script.js; printing output_values.arraySync,"function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as output
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   console.log(""converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(""Arg max:"")
   // console.log(output);|
   console.log(output_values.arraySync());
   console.log(""Output:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class. textContent = classes [output_values.argMax().arraySync()];
   predicted_prob.textContent = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[el;

   // Get the data url from the image
   const reader = new FileReader();
",390;272;721;802
1073,2,https://www.youtube.com/watch?t=34952&v=W5XNOmyJr6I,34952,screencapture-localhost-8000-2022-02-01-15_03_37.png,,goal: we still need to deploy the model so we need to update the CORS settings of this bucket.,,
1074,2,https://www.youtube.com/watch?t=34983&v=W5XNOmyJr6I,34983,screencapture-localhost-8000-2022-02-01-15_05_01.png,,search: google storage set cors;,,
1075,2,https://www.youtube.com/watch?t=34987&v=W5XNOmyJr6I,34987,screencapture-localhost-8000-2022-02-01-15_05_47.png,,visit: cross-origin resource sharing (CORS);,,
1077,2,https://www.youtube.com/watch?t=35060&v=W5XNOmyJr6I,35060,screencapture-localhost-8000-2022-02-01-15_08_23.png,,"code: script.js; forgot to add the ""s","const classes = {
   0: ""food"",
   1: ""not_food""
};

const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod
         el vl.tflite
         // ""/food_not_food_model_v1.tflite""
         // ""/food_not_food_model_v3.tflite""
         ""https://storage.googleapis.
         con/food-vis ion-model-playground/food_not_food_model_v3.tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as tfliteModel
      can only be used within this scope
      // console.log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

// // Prepare input tensors
// const img = tf.browser.fromPixels(document.querySelector('img'));
",393;257;727;805
1078,2,https://www.youtube.com/watch?t=35067&v=W5XNOmyJr6I,35067,screencapture-localhost-8000-2022-02-01-15_08_52.png,,output: error - model failed to fetch,,
1079,2,https://www.youtube.com/watch?t=35097&v=W5XNOmyJr6I,35097,screencapture-localhost-8000-2022-02-01-15_10_07.png,,other: error uploading cors,,
1080,2,https://www.youtube.com/watch?t=35104&v=W5XNOmyJr6I,35104,screencapture-localhost-8000-2022-02-01-15_10_36.png,,revisit: cross-origin resource sharing (CORS); its cors set not set cors,,
1081,2,https://www.youtube.com/watch?t=35116&v=W5XNOmyJr6I,35116,screencapture-localhost-8000-2022-02-01-15_17_06.png,,other: set cors policy on bucket,,
1082,2,https://www.youtube.com/watch?t=35162&v=W5XNOmyJr6I,35162,screencapture-localhost-8000-2022-02-01-15_18_13.png,,output: not immediately successful in fetching model from the bucket,,
1083,2,https://www.youtube.com/watch?t=35186&v=W5XNOmyJr6I,35186,screencapture-localhost-8000-2022-02-01-15_19_16.png,,output: still failing to fetch,,
1084,2,https://www.youtube.com/watch?t=35199&v=W5XNOmyJr6I,35199,screencapture-localhost-8000-2022-02-01-15_19_48.png,,output: still failing.,,
1085,2,https://www.youtube.com/watch?t=35225&v=W5XNOmyJr6I,35225,screencapture-localhost-8000-2022-02-01-15_21_13.png,,output: still failing,,
1086,2,https://www.youtube.com/watch?t=35271&v=W5XNOmyJr6I,35271,screencapture-localhost-8000-2022-02-01-15_22_30.png,,visit: twitch ml deploy project; checking his set up against a previous project of his.,,
1087,2,https://www.youtube.com/watch?t=35290&v=W5XNOmyJr6I,35290,screencapture-localhost-8000-2022-02-01-15_23_21.png,,code: index.html; copying in the script imports in index from twitch ml deploy,"   <br>
   <p>This line below will say loaded if the model is loaded:</p>
   <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>

   <!— Upload image —>
   <br>
   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>
   <p><input type=""file"" accept=""image/+"" name=""image"" id=""file-input"" /></p>
   <p><img id=""image"" width=""200"" /></p>

   <p>Predicted class:</p>
   <p id=""predicted_class""></p>
   <p>Predicted probability:</p>
   <p id=""predicted_prob""></p>

   <script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js""
   type=""text/javascript""></script> |
<script
src=""https://cdn. jsdelivr.net/npm/@tensorflow/tfjs—tflite@d.0.1-alpha.7/dist/tf-t
flite.min.js""></script>

   <script src=""script.js""></script>
</body>
</html>

",399;272;715;536
1088,2,https://www.youtube.com/watch?t=35297&v=W5XNOmyJr6I,35297,screencapture-localhost-8000-2022-02-01-15_24_04.png,,"output: still failing; ""Type Error""",,
1089,2,https://www.youtube.com/watch?t=35332&v=W5XNOmyJr6I,35332,screencapture-localhost-8000-2022-02-01-15_25_14.png,,code: script.js; removing the url model call,"const classes = {
   0: ""food"",
   1: ""non-food""
};

const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod
         el_v1.tflite
         //""/food_not_food_model_v1.tflite""
         ""/food_not_food_model_v3.tflite""
         //
         ""https://storage.googleapis. com/food-vision-model-playground/food_not_food_mo
         del_v3.tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as tfliteModel
      can only be used within this scope
      // console.log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status. innerText = “Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // // Prepare input tensors
",399;244;718;823
1090,2,https://www.youtube.com/watch?t=35360&v=W5XNOmyJr6I,35360,screencapture-localhost-8000-2022-02-01-15_26_07.png,,output: test with different image; predicts not food,,
1091,2,https://www.youtube.com/watch?t=35393&v=W5XNOmyJr6I,35393,screencapture-localhost-8000-2022-02-01-15_27_18.png,,output: with georgia food - still predicts food.,,
1092,2,https://www.youtube.com/watch?t=35470&v=W5XNOmyJr6I,35470,screencapture-localhost-8000-2022-02-01-15_29_01.png,,revisit: twitch ml deploy project;,,
1093,2,https://www.youtube.com/watch?t=35485&v=W5XNOmyJr6I,35485,screencapture-localhost-8000-2022-02-01-15_51_28.png,,code: script.js; trying with tf model from other project,"const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         ""https://storage.googleapis.
         com/food-vision-models-test/10_whole_foods_model_v@.tflite""
         //
         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod
         el_v1.tflite
         // ""/food_not_food_model_v1.tflite""

         // ""/food_not_food_model_v3.tflite""|
         //
         ""https://storage.googleapis. con/food-vision-model-playground/food_not_food_mo
         del_v3.tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as tflitelodel
      can only be used within this scope
      // console.log(tflitetodel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

   // Prepare input tensors.
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127,5), 1);
",393;260;730;811
1094,2,https://www.youtube.com/watch?t=35514&v=W5XNOmyJr6I,35514,screencapture-localhost-8000-2022-02-01-15_52_15.png,,output: that doesn't load either,,
1095,2,https://www.youtube.com/watch?t=35691&v=W5XNOmyJr6I,35691,screencapture-localhost-8000-2022-02-01-16_04_24.png,,visit: tflite js distro;,,
1096,2,https://www.youtube.com/watch?t=35733&v=W5XNOmyJr6I,35733,screencapture-localhost-8000-2022-02-01-16_05_31.png,,goal: let's try and get it on versel and see what happens,,
1097,2,https://www.youtube.com/watch?t=35881&v=W5XNOmyJr6I,35881,screencapture-localhost-8000-2022-02-01-16_08_24.png,,"other: he seems to be copying the full project from replit to his local machine , not totally sure why.",,
1098,2,https://www.youtube.com/watch?t=35911&v=W5XNOmyJr6I,35911,screencapture-localhost-8000-2022-02-01-16_09_35.png,,code: index.html; get the updated status,"   <title>Hello World - TensorFlow.js</title>
   <link href=""style.css"" rel=""stylesheet"" type=""text/css"" />
</head>

<body>
   <h1>Food Not Food (£ or 89)</h1>
   <p>This app will tell you if the image you upload is food or not.</p>
   <p>Yes. That's it. </p>
   <p>It'1l use a computer vision machine learning model to classify your image as ""food"" or ""not food"".</p>
   <br>
   <p>The line below will say loaded if TensorFlow.js is loaded:</p>
   <p id=""tfjs_status"">Awaiting TF.js load</p>

   <br>
   <p>This line below will say loaded if the model is loaded:</p>
   <p id=""model_status"">Awaiting TF.js model/TFLite model loading</p>

   <!— Upload image —>
   <br>
   <p><label for=""file"" style=""cursor; pointer;"">Upload Image</label></p>
",147;167;1213;530
1099,2,https://www.youtube.com/watch?t=35970&v=W5XNOmyJr6I,35970,screencapture-localhost-8000-2022-02-01-20_57_35.png,,other: git commit of index and the model - meant to also get script.js but typo.,,
1100,2,https://www.youtube.com/watch?t=36010&v=W5XNOmyJr6I,36010,screencapture-localhost-8000-2022-02-01-20_58_51.png,,other: git add script.js,,
1101,2,https://www.youtube.com/watch?t=36026&v=W5XNOmyJr6I,36026,screencapture-localhost-8000-2022-02-01-20_59_33.png,,visit: vercel; - going to make a new project here to deploy on something other than replit,,
1102,2,https://www.youtube.com/watch?t=36064&v=W5XNOmyJr6I,36064,screencapture-localhost-8000-2022-02-01-21_00_44.png,,other: now deployed on vercel,,
1103,2,https://www.youtube.com/watch?t=36115&v=W5XNOmyJr6I,36115,screencapture-localhost-8000-2022-02-01-21_01_57.png,,goal: change the CORS to the vercel address,,
1105,2,https://www.youtube.com/watch?t=36150&v=W5XNOmyJr6I,36150,screencapture-localhost-8000-2022-02-01-21_04_18.png,,other: updating cors policy on google bucket,,
1106,2,https://www.youtube.com/watch?t=36162&v=W5XNOmyJr6I,36162,screencapture-localhost-8000-2022-02-01-21_04_54.png,,code: script.js; use the url model rather than the local copy,"   tfjs_status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
} 

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         // ""https://storage.googleapis.com/food-vision-models—test/10_whole_foods_model_vO.tflite""
         // https://storage.googleapis.com/food-vision-model-playground/food_not_food_model_v1.tflite
         // ""/food_not_food_model_v1.tflite""

         // ""/food_not_food_model_v3.tflite""
         ""https://storage.googleapis.com/food-vision-model-playground/food_not_food_model_v3.tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as tfliteModel can only be used within this scop
      // console.log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
",144;179;1273;524
1107,2,https://www.youtube.com/watch?t=36196&v=W5XNOmyJr6I,36196,screencapture-localhost-8000-2022-02-01-21_05_58.png,,other: git commit of updated script,,
1108,2,https://www.youtube.com/watch?t=36239&v=W5XNOmyJr6I,36239,screencapture-localhost-8000-2022-02-01-21_07_01.png,,output: the model is not loading from the bucket,,
1109,2,https://www.youtube.com/watch?t=36290&v=W5XNOmyJr6I,36290,screencapture-localhost-8000-2022-02-01-21_08_12.png,,other: git commit script.js again to revert back to local model,,
1110,2,https://www.youtube.com/watch?t=36308&v=W5XNOmyJr6I,36308,screencapture-localhost-8000-2022-02-01-21_09_00.png,,code: index.html; updating the title,,675;226;421;130
1111,2,https://www.youtube.com/watch?t=36308&v=W5XNOmyJr6I,36308,screencapture-localhost-8000-2022-02-01-21_09_00.png,,other: git add the updated index.,,
1112,2,https://www.youtube.com/watch?t=36465&v=W5XNOmyJr6I,36465,screencapture-localhost-8000-2022-02-02-20_33_32.png,,output: testing camera image on vercel deployment; correctly identifies as not food,,
1113,2,https://www.youtube.com/watch?t=36475&v=W5XNOmyJr6I,36475,screencapture-localhost-8000-2022-02-03-20_47_33.png,,output: testing bananas and blueberries - also not food :(,,
1114,2,https://www.youtube.com/watch?t=36508&v=W5XNOmyJr6I,36508,screencapture-localhost-8000-2022-02-03-20_48_39.png,,output: bananas - not food :(,,
1115,2,https://www.youtube.com/watch?t=36517&v=W5XNOmyJr6I,36517,screencapture-localhost-8000-2022-02-03-20_48_39.png,,output: another banana - not food,,
1116,2,https://www.youtube.com/watch?t=36526&v=W5XNOmyJr6I,36526,screencapture-localhost-8000-2022-02-03-20_49_34.png,,output: bunch of bananas - food!,,
1117,2,https://www.youtube.com/watch?t=36553&v=W5XNOmyJr6I,36553,screencapture-localhost-8000-2022-02-03-20_50_21.png,,output: egg - not food :(,,
1118,2,https://www.youtube.com/watch?t=3373&v=W5XNOmyJr6I,3373,screencapture-localhost-2222-2022-04-28-14_42_06.png,,code: data_exploration; changes strip to split.,"for food_item in food_list:
   print(food_item.lower().split(""_""))",675;226;421;130
1119,2,https://www.youtube.com/watch?t=4355&v=W5XNOmyJr6I,4355,screencapture-localhost-2222-2022-04-28-14_48_36.png,,code: data_exploration; he's added a print stripped version for all in list. ,"# Check ImageNet classes for foods

# Look at imagenet classes
for k,v in imagenet_classes.item()
   # Get value from imagenet classes (string)
   # print(v. lower().split(*,""))]|
   print([space_word.strip("" "") for space_word in v.lower().split("","")])
   # See if value appears in flat_food_list
   if v.lower().split("","") in flat_food_list:
      print(k, v)
",453;316;672;228
1120,2,https://www.youtube.com/watch?t=4494&v=W5XNOmyJr6I,4494,screencapture-localhost-2222-2022-04-28-15_13_36.png,,code: data_exploration; tries assigning the result to a variable and printing that variable,"intersect_str = set([""string_1"", ""string_2""]).intersection(set(""string_1""))
intersect_str
",453;276;677;64
1121,2,https://www.youtube.com/watch?t=4569&v=W5XNOmyJr6I,4569,screencapture-localhost-2222-2022-04-28-15_40_33.png,,code: data_exploration; makes a set out of the imagenet class strings that have been split and prints it.,"# Check ImageNet classes for foods

# Look at imagenet classes
for k, v in imagenet_classes.items():
   # Get value from imagenet_classes (string) 
   # print(v.lower().split(*,""))
   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])
   print([imagenet_class_set])
   # See if value appears in flat_food_list
   if v.lower().split("","") in flat_food_list:
      print(k, v)
",448;379;849;258
1122,2,https://www.youtube.com/watch?t=4606&v=W5XNOmyJr6I,4606,screencapture-localhost-2222-2022-04-28-15_51_17.png,,code: data_exploration; removing the printing of every classname.,"# Check ImageNet classes for foods

# Look at imagenet classes
for k, v in imagenet_classes.items():
   # Get value from imagenet classes (string)
   # print(v.lower().split("",""))
   imagenet_class_set = set([space_word.strip("" "") for space_word in v.lower().split("","")])
   # print([imagenet_class_set])
   # See if value appears in flat_food_list
   if imagenet_class_set.intersection(flat_food_list):
      print(k, v)
",448;283;844;263
1123,2,https://www.youtube.com/watch?t=6702&v=W5XNOmyJr6I,6702,screencapture-localhost-2222-2022-04-28-15_55_03.png,,code: data_exploration; importing raw csv of imagenet classes,"import pandas as csv 

df = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv)
df.head()
",450;276;1073;102
1124,2,https://www.youtube.com/watch?t=6758&v=W5XNOmyJr6I,6758,screencapture-localhost-2222-2022-04-28-16_53_41.png,,code: data_exploration; fixing pandas import,"import pandas as pd

df = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv"")
df.head() |
",445;394;1103;107
1125,2,https://www.youtube.com/watch?t=6770&v=W5XNOmyJr6I,6770,screencapture-localhost-2222-2022-04-28-16_55_31.png,,code: data_exploration; lower classname,"df[""class_name""].lower()

",443;457;274;54
1126,2,https://www.youtube.com/watch?t=6774&v=W5XNOmyJr6I,6774,screencapture-localhost-2222-2022-04-28-16_56_19.png,,"code: data_exploration; convert to string, then lower.","df[""class_name""].str.lower()
",440;465;300;39
1127,2,https://www.youtube.com/watch?t=6914&v=W5XNOmyJr6I,6914,screencapture-localhost-2222-2022-04-28-16_58_15.png,,"code: data_exploration; trying to filter out anything where the csv entry contains ""food""","# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].str().contains(""food"")]
df_non_food

flat_food_list[:5]
",443;417;617;182
1128,2,https://www.youtube.com/watch?t=6924&v=W5XNOmyJr6I,6924,screencapture-localhost-2222-2022-04-28-16_59_57.png,,code: data_exploration; str() -> str,"len(df)

# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].str.contains(""food"")]
df_non_food
",448;276;546;220
1131,2,https://www.youtube.com/watch?t=6947&v=W5XNOmyJr6I,6947,screencapture-localhost-2222-2022-04-28-17_01_17.png,,"code: data_exploration; len of df[""classname""]","len(df)

len(df[""class_name""].unique())
",443;263;305;180
1132,2,https://www.youtube.com/watch?t=6995&v=W5XNOmyJr6I,6995,screencapture-localhost-2222-2022-04-28-17_14_25.png,,code: data_exploration; df removing the ~ in front.,"# Filter dataframe from food classes
df_non_food = df[df[""class_name""].str.contains(""food"")]
df_non_food
",450;417;516;82
1133,2,https://www.youtube.com/watch?t=7016&v=W5XNOmyJr6I,7016,screencapture-localhost-2222-2022-04-28-17_17_31.png,,code: data_exploration; df.dropna - try dropping the na's,"len(df)

df.dropna()",675;226;421;130
1134,2,https://www.youtube.com/watch?t=7072&v=W5XNOmyJr6I,7072,screencapture-localhost-2222-2022-04-29-11_26_39.png,,code: data_exploration; adding the lower back in,"# Filter dataframe from food classes
df_non_food = df[df[""class_naMe""].str.lower().contains(""food"")]
df_non_food
",443;419;589;82
1135,2,https://www.youtube.com/watch?t=7118&v=W5XNOmyJr6I,7118,screencapture-localhost-2222-2022-04-29-11_33_22.png,,code: data_exploration; returns to where the data is loaded and adds a lower there.,"import pandas as pd 

df = pd.read_csv(""https://raw.githubusercontent.com/mf1024/ImageNet-Datasets-Downloader/master/classes_in_imagenet.csv"")
# lower strings
df[""class_name""] = df[""class_name""].str.lower()
df.head()
",445;356;1078;142
1136,2,https://www.youtube.com/watch?t=7133&v=W5XNOmyJr6I,7133,screencapture-localhost-2222-2022-04-29-11_34_38.png,,"code: data_exploration; adds the ~ back in - ""there we go nonfood""","# Filter dataframe from food classes
df_non_food = df[~df[""class_name""].str.contains(""food"")]
df_non_food
",443;412;539;92
1137,2,https://www.youtube.com/watch?t=7187&v=W5XNOmyJr6I,7187,screencapture-localhost-2222-2022-04-29-11_58_16.png,,code: data_exploration; trying to filter out anything that's in the food list.,"# Filter dataframe from food classes 
df_non_food = df[~df[""class_name""].str.isin(flat_food_list)]
df_non_food",445;445;557;79
1138,2,https://www.youtube.com/watch?t=7193&v=W5XNOmyJr6I,7193,screencapture-localhost-2222-2022-04-29-11_59_34.png,,code: data_exploration; removes the str call in the filter.,,675;226;421;130
1140,2,https://www.youtube.com/watch?t=8351&v=W5XNOmyJr6I,8351,screencapture-localhost-2222-2022-04-29-12_44_25.png,,code: data_exploration; trying to capture the full list of exceptions that he's manually adding.,"'plate',
'pot',
'rack',
'refrigerator',
'saddle',
'shank',
'spring',
'steamer',
'stick',
'temple',
'truck',
'turban',
'ring',
'cup',
'rock',
'shell',
'pilot',
'runner',
'smith',
'ash',
'sand']
",168;268;159;472
1141,2,https://www.youtube.com/watch?t=9278&v=W5XNOmyJr6I,9278,screencapture-localhost-2222-2022-04-29-12_48_01.png,,code: data_exploration; printing top 5 non-foods - I think this is a way to close out the creation of that array.,"'shell',
'pilot',
'runner',
'smith',
'ash',
'sand']


not_food_list[:5]
",141;258;176;190
1142,2,https://www.youtube.com/watch?t=9447&v=W5XNOmyJr6I,9447,screencapture-localhost-2222-2022-04-29-12_49_20.png,,code: data_exploration; fixing so actually removing from food dataframe,"#Filter dataframe from food classes
df_non_food = df[~df[""class_name""].isin(flat_food_list)]
df_food = df[df[""class_name""].isin(flat_food_list)]
df_food = df_food[~df[""class_name""].isin(not_food_list)] # remove even more not food items
len(df_non_food), len(df_food)

len(df_food)

list(df_food.class_name)[:5]
",138;306;813;412
1143,2,https://www.youtube.com/watch?t=12325&v=W5XNOmyJr6I,12325,screencapture-localhost-2222-2022-04-29-12_52_05.png,,code: data_exploration; he's got the command below and is trying to figure out how many images per class to get.,"!mkdir data/non_food_images/


len(food_class_id_list) 

!python ImageNet-Datasets-Downloader/downloader.py \
   -data_root data/food_images \
   -use_class_list=True \
   ~class_list $food_class_id_string \
   -images_per_class 100
",430;334;524;414
1144,2,https://www.youtube.com/watch?t=14769&v=W5XNOmyJr6I,14769,screencapture-localhost-2222-2022-04-29-12_54_18.png,,code: model_building; trying to use set differencing to get the test set.,"train_split = int(0.8 * len(aircraft_images))

train_image_list = random.sample(aircraft_images, train_split)
test_image_list = set([train_image_list]).difference(set([aircraft_images]))
test_image_list
",425;288;698;130
1145,2,https://www.youtube.com/watch?t=14944&v=W5XNOmyJr6I,14944,screencapture-localhost-2222-2022-04-29-13_09_11.png,,code: model_building; functionized the creation of test and train sets based on a passed directory which should make it easy to create sets for both aircraft and anvil,"import random

def create_train_test_list(target_dir):
   random.seed(42)
   image_list = os.listdir(target_dir)
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list
",438;306;685;185
1146,2,https://www.youtube.com/watch?t=14979&v=W5XNOmyJr6I,14979,screencapture-localhost-2222-2022-04-29-13_11_17.png,,code: model_building; trying out the function to create test/train data with airplane directory,"import random
def create_train_test_list(target_dir):
   random.seed(42)
   image_list = os.listdir(target_dir)
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list

train_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")
len(train_image_list), len(test_image_list)
",435;301;831;258
1147,2,https://www.youtube.com/watch?t=15307&v=W5XNOmyJr6I,15307,screencapture-localhost-2222-2022-04-29-13_12_54.png,,code: model_building; replace + with an os.join,"# Create a function to move images
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   print(image_dir)
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   len(train_image_list), len(test_image_list)
",433;286;876;160
1148,2,https://www.youtube.com/watch?t=15421&v=W5XNOmyJr6I,15421,screencapture-localhost-2222-2022-04-29-13_14_09.png,,code: model_building; making the dir name part of the image list,"import random
def create_train_test_list(target_dir):
   random.seed(42)
   image_list = (os.path.join(target_dir, img_path) for img_path in os.listdir(target_dir))
   train_split = int(0.8 * len(image_list))
   train_image_list = random.sample(image_list, train_split)
   test_image_list = list(set(image_list).difference(set(train_image_list)))
   return train_image_list, test_image_list

train_image_list, test_image_list = create_train_test_list(""data/model_test_images/aircraft"")
len(train_image_list), len(test_image_list)
",430;306;839;258
1149,2,https://www.youtube.com/watch?t=15532&v=W5XNOmyJr6I,15532,screencapture-localhost-2222-2022-04-29-14_01_40.png,,code: model_building; printing a destination directory to move the test/train images to,"# Create a function to move images
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   print(image_dir)
   print(os.path.join(data_dir, image_dir))
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   print(len(train_image_list), len(test_image_list))
   print(train_image_list[:5])
   for image_path in train_image_list[:]:
      dest_dir = os.path.join(target_dir, image_dir)
      print(dest_dir)
",435;306;869;278
1151,2,https://www.youtube.com/watch?t=15643&v=W5XNOmyJr6I,15643,screencapture-localhost-2222-2022-04-29-14_28_37.png,,code: model_building; replace train with test,"# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)
   print(dest_dir)
",455;268;695;147
1152,2,https://www.youtube.com/watch?t=15687&v=W5XNOmyJr6I,15687,screencapture-localhost-2222-2022-04-29-14_31_00.png,,code: model_building; same moving msg for test,"# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_dir = os.path.join(target_dir, ""test"", image_dir, image_file_name)
   print{(f""Moving: {image_path} to {dest_dir}"")]
",460;261;682;130
1153,2,https://www.youtube.com/watch?t=15866&v=W5XNOmyJr6I,15866,screencapture-localhost-2222-2022-04-29-14_32_57.png,,code: model_building; adding copy to train as well as test,"# Copy training images
for image_path in train_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(f""Copying: {image_path} to {dest_path}"")
   copy2(image_path, dest_path)

# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)
   print(f""Copying: \n{image_path} to \n{dest_path}"")
   copy2(image_path, dest_path)
",460;271;715;303
1154,2,https://www.youtube.com/watch?t=15954&v=W5XNOmyJr6I,15954,screencapture-localhost-2222-2022-04-29-14_35_25.png,,code: model_building; change to exist_ok,"for image_dir in os.listdir(data_dir):
   # Make target directory
   os.makedirs(os.path.join(target_dir, image_dir), exist_ok=True)
   # print(image_dir)
   # print(os.path.join(data_dir, image_dir))

   # Make training and test lists of target images
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   # print(len(train_image_list), len(test_image_list))

   # Copy training images
   for image_path in train_image_list[:5]:
      image_file_name = os.path.split(image_path) [-1]
      dest_path = os.path.join(target_dir, ""train"", image_dir, image_file_name)
      print(f""Copying: {image_path} to {dest_path}"")
      copy2(image_path, dest_path)

   # Copy testing images
",435;253;894;402
1155,2,https://www.youtube.com/watch?t=16412&v=W5XNOmyJr6I,16412,screencapture-localhost-2222-2022-04-29-14_37_23.png,,code: model_building; revising to use the new helper function,"# print(len(train_image_list), len(test_image_list))

# Copy training images
copy_images_to_file(img_path_list=train_image_list,
   target_dir=target_dir,
   train=True)

# Copy testing images
copy_images_to_file(img_path_list=train_image_list,
   target_dir=target_dir,
   train=True)

# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path)[-1]
   dest_path = os.path.join(target_dir, ""test"", image_dir, image_file_name)
   print(f""Copying \n{image_path} to \n{dest_path})
",468;271;705;386
1157,2,https://www.youtube.com/watch?t=16587&v=W5XNOmyJr6I,16587,screencapture-localhost-2222-2022-04-29-14_42_18.png,,code: model_building; printing image path list,,675;226;421;130
1158,2,https://www.youtube.com/watch?t=16752&v=W5XNOmyJr6I,16752,screencapture-localhost-2222-2022-04-29-14_46_41.png,,code: model_building; reversing order of directories in mkdir,"# Create a function to move images
from shutil import copy2
data_dir = ""data/model_test_images""
target_dir = “data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   # print(image_dir)
   # print(os.path.join(data_dir, image_dir))
   for split_dir in [""train"", ""test""]: 
      os.makedirs(os.path.join(target_dir, split_dir, jmage_dir), exist_ok=True)

   # Make training and test lists of target images
   train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
   # print(len(train_image_list), len(test_image_list))

   # Copy training images
   copy_images_to_file(img_path_list=train_image_list,
",430;299;869;361
1159,2,https://www.youtube.com/watch?t=16988&v=W5XNOmyJr6I,16988,screencapture-localhost-2222-2022-04-29-14_49_54.png,,code: model_building; remove the limitation to copy 5.,"# Copy images
for image_path in img_path_list:
   image_file_name = os.path.split(image_path)[-1]
   dest_path = os.path.join(target_dir, split_dir, image_dir, image_file_name)
   print(f""Copying: {image_path} to {dest_path}"")
   copy2(image_path, dest_path)

# Create a function to move images
from shutil import copy2
data_dir = ""data/model_test_images""
target_dir = ""data/model_test_images_split""
for image_dir in os.listdir(data_dir):
   for split_dir in [""train"", ""test""]:
      os.makedirs(os.path.join(target_dir, split_dir, image_dir), exist_ok=True)
",430;281;783;379
1160,2,https://www.youtube.com/watch?t=17642&v=W5XNOmyJr6I,17642,screencapture-localhost-2222-2022-04-29-14_52_13.png,,code: model_building; loading test and train data into keras,,675;226;421;130
1161,2,https://www.youtube.com/watch?t=17667&v=W5XNOmyJr6I,17667,screencapture-localhost-2222-2022-04-29-14_54_10.png,,code: model_building; set logger level to info (copied from his own code earlier in file),,675;226;421;130
1163,2,https://www.youtube.com/watch?t=18339&v=W5XNOmyJr6I,18339,screencapture-localhost-2222-2022-04-29-15_02_07.png,,"code: model_building; missed changing reference to input_layer variable when renamed, fixes that ref.
          ","base_model = tf.keras.applications.EfficientNetB@(include_top=False)

# Make model untrainable
base_model.trainable = False

# Build a functional model
input_layer = tf.keras.Input(shape=(224, 223, 3))
x = base_model(input)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
output_layer = tf.keras.layers.Dense(1)(x)

# Construct model
model_1 = tf.keras.Model(input_layer, output_layer)
model_1
",135;286;614;318
1164,2,https://www.youtube.com/watch?t=19531&v=W5XNOmyJr6I,19531,screencapture-localhost-2222-2022-04-29-15_04_49.png,,code: model_building; adding a model.compile call,"# Compile model
model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),
   optimizer=tf.keras.optimizers.Adam(),
   metrics=[""accuracy""]
}",120;382;567;117
1165,2,https://www.youtube.com/watch?t=19733&v=W5XNOmyJr6I,19733,screencapture-localhost-2222-2022-04-29-15_06_43.png,,code: model_building; code.evaluate - performing with perfect accuracy (on a very small dataset),"model_1.evaluate(test_data)
",123;437;436;54
1166,2,https://www.youtube.com/watch?t=36117&v=W5XNOmyJr6I,36117,screencapture-localhost-2222-2022-04-29-16_28_44.png,,code: cors-config; restricting origin to the vercel address,"{
   {
      ""origin"": [
         ""https://food-not-food.vercel.app/""
      ],
      ""responseHeader"": [
         ""*""
      ],
      ""method"": [
         ""GET"",
         ""POST"",
         ""HEAD""
      ],
      ""maxAgeSeconds"": 3600
   }
}
",120;231;433;356
1167,2,https://www.youtube.com/watch?t=35040&v=W5XNOmyJr6I,35040,screencapture-localhost-2222-2022-04-29-16_32_07.png,,code: script.js; updating to use the url for the model having not yet updated the cors to show what happens,"const classes = {
   0: ""food"",
   1: ""not_food""
};

const status = document.getElementById(""status"");

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfjs;
}

let model; // This is in global scope

const loadModel = async () => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         https://storage.googleapis. con/food-vision-model-playground/food_not_food_mod
         el vl.tflite
         // ""/food_not_food_model_v1.tflite""
         // ""/food_not_food_model_v3.tflite""
         ""https://storage.googleapis.
         con/food-vis ion-model-playground/food_not_food_model_v3.tflite""
      );
      model = tfliteModel; // assigning it to the global scope model as tfliteModel
      can only be used within this scope
      // console.log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }

// // Prepare input tensors
// const img = tf.browser.fromPixels(document.querySelector('img'));",675;226;421;130
1168,2,https://www.youtube.com/watch?t=34885&v=W5XNOmyJr6I,34885,screencapture-localhost-2222-2022-04-29-16_34_57.png,,code: script.js; different way to write text into html based on chat comment,"// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to be
   same as model inputs
   image = tf.expandDims(image);
   console.log(image) ;
   // console.log(model);

   // console.log(tflite.getDTypeFronTFLiteType(""uint8"")); // Gives int32 as output
   thus we cast int32 in below line
   // console.log(tflite.getDTypeFronTFLiteType(""uint8""));
   console. log(""converting image to different datatype..."");
   image = tf.cast(image, ""int32""); // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(""Arg max:"")
   // console.log(output);
   console.log(output_values);
   console.log(""Output:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes [output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementByTd(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

   // Get the data url from the image
   const reader = new FileReader();",675;226;421;130
1169,2,https://www.youtube.com/watch?t=34424&v=W5XNOmyJr6I,34424,screencapture-localhost-2222-2022-04-29-16_32_07.png,,code: script.js; updating class constants,"const classes = {
  0: ""food"",
  1: ""not_food""
};

const status = document.getElementById(""status”);

if (status) {
   status.innerText = ""Loaded TensorFlow.js - version:"" + tf.version.tfis;
}

let model; // This is in global scope

const loadModel = async() => {
   try {
      const tfliteModel = await tflite.loadTFLiteModel(
         //
         https://storage.googleapis.com/food-vision-model-playground/food_not_food_mod
         el_v1.tflite
         // ""/food_not_food_model_v1.tflite""
         // ""/food_not_food_model_v3.tflite""
         https://storage.googleapis. I
         com/food-vision-model-playground/food_not_food_model_v3.tflite
      }
      model = tfliteModel; // assigning it to the global scope model as tfliteModel
      can only be used within this scope
      // console.log(tfliteModel);

      // Check if model loaded
      if (tfliteModel) {
         model_status.innerText = ""Model loaded"";
      }
   } catch (error) {
      console.log(error);
   }
",334;311;607;623
1170,2,https://www.youtube.com/watch?t=33685&v=W5XNOmyJr6I,33685,screencapture-localhost-2222-2022-04-29-16_34_57.png,,code: script.js; output[0].arraysync.argmax; maybe?,"// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as
   output thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFliteType(""uint8""));
   console.log(""converting image to different datatype..."");
   image = tf.cast(image, ""int32"");  // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(""Arg max:"")
   // console.log(output);
   console.log(output_values);
   console.log(""Output:"")
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if(fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

   // Get the data url from the image
   const reader = new FileReader();",675;226;421;130
1171,2,https://www.youtube.com/watch?t=33503&v=W5XNOmyJr6I,33503,screencapture-localhost-2222-2022-04-29-16_38_25.png,,code: script.js; now output instead of output values,,675;226;421;130
1172,2,https://www.youtube.com/watch?t=33503&v=W5XNOmyJr6I,33503,screencapture-localhost-8000-2022-02-03-20_50_21.png,,,,
1174,2,https://www.youtube.com/watch?t=32912&v=W5XNOmyJr6I,32912,screencapture-localhost-2222-2022-04-29-17_00_47.png,,code: add_more_food_images; fixing test path,,675;226;421;130
1175,2,https://www.youtube.com/watch?t=32840&v=W5XNOmyJr6I,32840,screencapture-localhost-2222-2022-04-29-17_02_40.png,,code: add_more_food_images; adding an import for copy2 but writes copy3,"ist(set(image_list).difference(set(train_image_list)))
list, test_image_list
image_list = create_train_test_list(random_38K_food_image_paths)
len(test_image_list)

train_images, test_images = create_train_test_list(randon_38k_food_image_pa

# Training images
def copy_images_to_file(image_list, target_dir): 
   # target_dir = ""data/train/food_images/""
   os.makedirs(target_dir, exist_ok=True)
   for image_path in image_list:
      image_filename = os.path.split(image_path)[-1]
",115;263;703;417
1176,2,https://www.youtube.com/watch?t=32790&v=W5XNOmyJr6I,32790,screencapture-localhost-8000-2022-02-03-20_50_21.png,,code: add_more_food_images; copying in file copying code from data_splitting,,675;226;421;130
1177,2,https://www.youtube.com/watch?t=31320&v=W5XNOmyJr6I,31320,screencapture-localhost-2222-2022-04-29-17_04_31.png,,code: script.js; added msg about converting image to diff datatype,"   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as
   output thus we cast int32 in below line
   // console.log(tflite.getDTypeFromTFliteType(""uint8""));
   console.log(""converting image to different datatype..."");
   image = tf.cast(image, ""uint32"");  // Model requires uint8
   console.log(""model about to predict..."");
   const output = model.predict(image);
   // const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

",675;226;421;130
1178,2,https://www.youtube.com/watch?t=30727&v=W5XNOmyJr6I,30727,screencapture-localhost-2222-2022-05-02-12_43_05.png,,code: script.js; brings back the cast to int32,"   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image);
   console.log(image);
   // console.log(model);

   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFliteType(""uint8""));
   image = tf.cast(image, ""int32"");  // Model requires uint8
   const output = model.predict(image);
   // const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if(fileInput.files[0]) throw new Error(""Image not found"");",675;226;421;130
1179,2,https://www.youtube.com/watch?t=30585&v=W5XNOmyJr6I,30585,screencapture-localhost-2222-2022-05-02-12_45_02.png,,code: model_building; pastes in the no signature scenario example code,"import numpy as np
import tensorflow as tf

# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""food_not_food_model_v1.tflite"")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter. invoke()
",123;296;753;376
1180,2,https://www.youtube.com/watch?t=30126&v=W5XNOmyJr6I,30126,screencapture-localhost-2222-2022-05-02-12_49_44.png,,"code: script.js; uncomments the resize to 224, 224.","   // // Prepare input tensors
   // const img = tf.browser.fromPixels(document.querySelector('img'));
   // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 3);

   // // Run inference and get output tensors.
   // let outputTensor = tfliteModel.predict(input);
   // console.log(outputTensor.dataSync());
};
loadModel();

// function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   // image = tf.expandDims(image);
   console.log(image);

   // console.log(tflite.getDTypeFromTfLiteType(""uint8"")) // Gives int32 as
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFliteType(""uint8""));
   // image = tf.cast(image, ""int32""); // Model requires uint8
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output.arraySync());
   console.log(output.arraySync()[0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementById(""file-input"");
const image = document.getElementById(""image"");

function getImage() {",675;226;421;130
1181,2,https://www.youtube.com/watch?t=29704&v=W5XNOmyJr6I,29704,screencapture-localhost-2222-2022-05-02-12_51_31.png,,code: script.js; changes the int32 cast to float32 instead,,675;226;421;130
1182,2,https://www.youtube.com/watch?t=29589&v=W5XNOmyJr6I,29589,screencapture-localhost-2222-2022-05-02-12_56_53.png,,code: script.js; bring back console log of image,"
};
loadModel();

// Function to classify image
function classifyImage(model, image) {
   // Preprocess image
   image = tf.image.resizeBilinear(image, [224, 224]); // image size needs to 
   be same as model inputs
   image = tf.expandDims(image); 
   console.log(image);

   // console.log(tflite.getDTypeFromTFLiteType(""uint8"")); // Gives int32 as 
   output thus we cast int32 in below line
   console.log(tflite.getDTypeFromTFLiteType(""uint8""));
   // image = tf.cast(image, ""int32""); // Model requires uint8
   const output = model.predict(image);
   const output_values = tf.softmax(output.arraySync()[0]);
   console.log(output.arraySync());
   console.log(output.arraySync() [0]); // arraySync() Returns an array to use

   // Update HTML
   predicted_class.innerText = classes[output_values.argMax().arraySync()];
   predicted_prob.innerText = output_values.max().arraySync() * 100 + ""%"";
}

// Image uploading
const fileInput = document.getElementByTd(""file-input"");
const image = document.getElementById(""image"");

function getImage() {
   if (!fileInput.files[0]) throw new Error(""Image not found"");
   const file = fileInput.files[0];

 ",675;226;421;130
1183,2,https://www.youtube.com/watch?t=28466&v=W5XNOmyJr6I,28466,screencapture-localhost-2222-2022-05-02-12_59_58.png,,code: index.html; he's kind of giving a tour of pre-created code. He's changed the title and text in here to be about food/not food but no changes beyond that.,,675;226;421;130
1184,2,https://www.youtube.com/watch?t=31200&v=W5XNOmyJr6I,31200,screencapture-localhost-2222-2022-05-02-15_08_44.png,,code: small_model_building; change it to predict the top two class (there are only 2) instead of the top 5,"# Load image
image = tf.keras.utils.load_img(""chicken_wings.jpeg"")
input_arr = tf.keras.utils.img_to_array(image)
input_arr = np.array([input_arr]) # Convert single image 
input_arr = tf.image.resize(input_arr, size=(224, 224)) / 2
preds = model.predict_top_k{input_arr, k=2 batch_size=1)|
preds[0]
",425;356;539;172
1185,2,https://www.youtube.com/watch?t=31174&v=W5XNOmyJr6I,31174,screencapture-localhost-2222-2022-05-02-15_11_11.png,,code: small_model_building; import tensorflow,"train_data = Dataloader.from_folder(train_data_path)
test_data = Dataloader.from_folder(test_data_path)

train_data, test_data

# Create model
model = image_classifier.create(train_data)
",433;266;478;233
1186,2,https://www.youtube.com/watch?t=26880&v=W5XNOmyJr6I,26880,screencapture-localhost-2222-2022-05-02-13_58_29.png,,code: classes.js; he's putting in the potential classes - food/not food,"export const classes = {
   1: ""food"",
   2: ""not_food""
};
",392;306;206;87
1187,2,https://www.youtube.com/watch?t=26728&v=W5XNOmyJr6I,26728,screencapture-localhost-2222-2022-05-02-14_05_40.png,,code: model_building; he copies in code from the tflite conversion page,"# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()

# Save the model
with open('model.tflite', 'wb') as f:
   f.write(tflite_model)
",128;389;627;175
1188,2,https://www.youtube.com/watch?t=25739&v=W5XNOmyJr6I,25739,screencapture-localhost-2222-2022-05-02-15_18_40.png,,code: data_splitting; now repeating the process of test/train split for the non-food images,"train_images, test_images = create_train_test_list(non_food_image_filepaths)

copy_images_to_file(image_list=train_images, target dir=""data/train/non_food_images/"")
copy_images_to_file(image_list=test_images, target_dir=""data/test/non_food_images/"")
",433;372;803;117
1190,2,https://www.youtube.com/watch?t=25523&v=W5XNOmyJr6I,25523,screencapture-localhost-2222-2022-05-02-15_20_35.png,,code: data_splitting; corrected calls to copy images function,"train_images, test_images = create_train_test_list(food_image_filepaths)

# Training images
def copy_images_to_file(image_list, target_dir):
   # target dir = ""data/train/food_images/""
   os.makedirs(target_dir, exist_ok=True)
   for image_path in image_list:
      image_filename = os.path.split(image_path)[-1]
      # print(image filename
      dest_path = os.path.join(target_dir, image_filename)
      print(f""Copying {image_path} to {dest_path}"")
      copy2(image_path, dest_path)

copy_images_to_file(image_list=train_images, target_dir=""data/train/food_images/""):
copy_images_to_file(image_list=test_images, target_dir=""data/train/food_images/""):
",433;294;763;354
1191,2,https://www.youtube.com/watch?t=21979&v=W5XNOmyJr6I,21979,screencapture-localhost-2222-2022-04-29-16_02_21.png,,"code: data_splitting; adding imports, changing directory of images to walk","import os
from shutil import copy2
import random
for dirs, sub_dirs, files in os.walk(""data/imagenet_images""):
   print(dirs)
   print(sub_dirs)
   print(files)
",435;261;642;172
1192,2,https://www.youtube.com/watch?t=21407&v=W5XNOmyJr6I,21407,screencapture-localhost-2222-2022-04-29-16_00_24.png,,code: model_building; nested loops to count images,"import os
image_files = []
for dirs, sub_dirs, files in os.walk(""data/imagenet_images/imagenet_images/""):
   for item in files:
      image_files.append(files)|
len(image_files)

image_files
",423;258;710;298
1193,2,https://www.youtube.com/watch?t=21163&v=W5XNOmyJr6I,21163,screencapture-localhost-2222-2022-04-29-15_55_58.png,,code: model_building; commenting out downloader command (since data is downloaded),"import wandb
wandb.tensorboard.patch(root_logdir=""logs"")
wandb.init(project=""100k-livestream-video"")

import tensorflow as tf
tf.get_logger().setLevel('INFO')
",430;351;410;205
1194,2,https://www.youtube.com/watch?t=21274&v=W5XNOmyJr6I,21274,screencapture-localhost-8000-2022-02-03-20_50_21.png,,code: model_building; also removes the / after logs,"len(image_files)
image_files",675;226;421;130
1195,2,https://www.youtube.com/watch?t=20180&v=W5XNOmyJr6I,20180,screencapture-localhost-2222-2022-04-29-15_52_16.png,,"code: model_building; model fit is missing a ,","# fit model
history 1 = model_1,fit(train_data
   epochs=50,
   validation_data=test_data,
   callbacks=[early_stopping
      create_tensorboard_callback(""logs"", model_1.name)])

model_1.evaluate(test_data)
",433;281;776;250
1196,2,https://www.youtube.com/watch?t=20105&v=W5XNOmyJr6I,20105,screencapture-localhost-2222-2022-04-29-15_48_54.png,,code: model_building; adding callback for tensorboard in the model.fit call,"   monitor=""val_loss"" 
}

history_1 = model_1.fit(train_data,
   epochs=50,
   validation_data=test_data,
   callbacks=[early_stopping,
      create_tensorboard_callback(""logs"")])
",408;271;672;276
1197,2,https://www.youtube.com/watch?t=18320&v=W5XNOmyJr6I,18320,screencapture-localhost-2222-2022-04-29-15_00_29.png,,code: model_building; removes input from the path to Input,"base_model = tf.keras.applications.EfficientNetB0(include_top=False)

# Make model untrainable
base_model.trainable = False

# Build a functional model
input_layer = tf.keras.layers.Input(shape=(224, 223, 3))
x = base_model(input)
x = tf.keras. layers.GlobalAveragePooling2D()(x)
output_layer = tf.keras.layers.Dense(1)(x)

# Construct model
model_1 = tf.keras.Model(input_layer, output_layer)
model_1
",130;306;589;323
1198,2,https://www.youtube.com/watch?t=16422&v=W5XNOmyJr6I,16422,screencapture-localhost-2222-2022-04-29-14_39_22.png,,code: model_building; fixing for test examples,"# Copy training images
copy_images_to_file(img_path_list=train_image_list,
   target_dir=target_dir,
   train=True)

# Copy testing images
copy_images_to_file(img_path_list=test_image_list,
   target_dir=target_dir,
   train=False)
",460;258;504;210
1199,2,https://www.youtube.com/watch?t=15635&v=W5XNOmyJr6I,15635,screencapture-localhost-2222-2022-04-29-14_04_39.png,,code: model_building; do the same for model test - except forgets to replace train with test in the dest path,"print(os.path.join(data_dir, image_dir))
train_image_list, test_image_list = create_train_test_list(os.path.join(data_dir, image_dir))
print(len(train_image_list), len(test_image_list))
print(train_image_list[:5])

# Copy training images
for image_path in train_image_list[:5]:
   image_file_name = os.path.split(image_path) [-1]
   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(dest_dir)

# Copy testing images
for image_path in test_image_list[:5]:
   image_file_name = os.path.split(image_path) [-1]
   dest_dir = os.path.join(target_dir, ""train"", image_dir, image_file_name)
   print(dest_dir)
",458;263;854;366
